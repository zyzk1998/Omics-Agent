#!/usr/bin/env python3
"""
RNAåˆ†æå…¨æµç¨‹è‡ªæµ‹ç¨‹åº

æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯RNAåˆ†æå…¨æµç¨‹ï¼ˆä»10xæ•°æ®åˆ°æœ€ç»ˆæŠ¥å‘Šï¼‰
2. ææ¸…æ¥šæ•°æ®è¯Šæ–­æŠ¥å‘Šç”ŸæˆæˆåŠŸçš„é€»è¾‘
3. ä¸ºä»£è°¢ç»„åˆ†ææµç¨‹æ•°æ®è¯Šæ–­è¿‡ç¨‹å¤±è´¥åšå¥½å……è¶³å‡†å¤‡

æµ‹è¯•æ•°æ®ï¼štest_dataæ–‡ä»¶å¤¹å†…çš„10xæ•°æ®æ–‡ä»¶
"""
import os
import sys
import asyncio
import logging
from pathlib import Path
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from gibh_agent.core.file_inspector import FileInspector
from gibh_agent.core.prompt_manager import PromptManager
from gibh_agent.core.tool_retriever import ToolRetriever
from gibh_agent.agents.specialists.rna_agent import RNAAgent
from gibh_agent.core.orchestrator import Orchestrator
from gibh_agent.core.llm_client import LLMClientFactory

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('test_rna_workflow.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


async def test_data_diagnosis():
    """æµ‹è¯•1: æ•°æ®è¯Šæ–­æŠ¥å‘Šç”Ÿæˆ"""
    logger.info("=" * 80)
    logger.info("æµ‹è¯•1: æ•°æ®è¯Šæ–­æŠ¥å‘Šç”Ÿæˆ")
    logger.info("=" * 80)
    
    # æŸ¥æ‰¾test_dataä¸­çš„10xæ•°æ®æ–‡ä»¶
    test_data_dir = project_root / "test_data"
    h5ad_file = test_data_dir / "pbmc_1k_v3_filtered.h5ad"
    
    if not h5ad_file.exists():
        logger.error(f"âŒ æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {h5ad_file}")
        return False
    
    logger.info(f"ğŸ“ ä½¿ç”¨æµ‹è¯•æ•°æ®: {h5ad_file}")
    
    # åˆå§‹åŒ–ç»„ä»¶
    upload_dir = str(test_data_dir)
    prompt_manager = PromptManager()
    tool_retriever = ToolRetriever()
    
    # åˆå§‹åŒ–FileInspector
    file_inspector = FileInspector(upload_dir)
    
    # åˆå§‹åŒ–RNAAgent
    llm_client = LLMClientFactory.create_default()
    rna_agent = RNAAgent(
        prompt_manager=prompt_manager,
        tool_retriever=tool_retriever,
        upload_dir=upload_dir,
        llm_client=llm_client
    )
    
    # æ‰§è¡Œæ•°æ®è¯Šæ–­
    logger.info("ğŸ” å¼€å§‹æ•°æ®è¯Šæ–­...")
    try:
        file_metadata = file_inspector.inspect_file(str(h5ad_file))
        logger.info(f"âœ… æ–‡ä»¶æ£€æŸ¥å®Œæˆ: {file_metadata.get('status')}")
        
        # è°ƒç”¨æ•°æ®è¯Šæ–­
        diagnosis = await rna_agent._perform_data_diagnosis(
            file_metadata=file_metadata,
            user_query="rnaåˆ†æ"
        )
        
        if diagnosis:
            logger.info(f"âœ… æ•°æ®è¯Šæ–­æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(diagnosis)}")
            logger.info(f"ğŸ“ è¯Šæ–­æŠ¥å‘Šé¢„è§ˆ:\n{diagnosis[:500]}...")
            return True
        else:
            logger.error("âŒ æ•°æ®è¯Šæ–­æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼ˆè¿”å›Noneï¼‰")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æ•°æ®è¯Šæ–­å¤±è´¥: {e}", exc_info=True)
        return False


async def test_full_workflow():
    """æµ‹è¯•2: å®Œæ•´å·¥ä½œæµæ‰§è¡Œ"""
    logger.info("=" * 80)
    logger.info("æµ‹è¯•2: å®Œæ•´å·¥ä½œæµæ‰§è¡Œ")
    logger.info("=" * 80)
    
    # æŸ¥æ‰¾test_dataä¸­çš„10xæ•°æ®æ–‡ä»¶
    test_data_dir = project_root / "test_data"
    h5ad_file = test_data_dir / "pbmc_1k_v3_filtered.h5ad"
    
    if not h5ad_file.exists():
        logger.error(f"âŒ æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {h5ad_file}")
        return False
    
    logger.info(f"ğŸ“ ä½¿ç”¨æµ‹è¯•æ•°æ®: {h5ad_file}")
    
    # åˆå§‹åŒ–ç»„ä»¶
    upload_dir = str(test_data_dir)
    prompt_manager = PromptManager()
    tool_retriever = ToolRetriever()
    llm_client = LLMClientFactory.create_default()
    
    # åˆå§‹åŒ–RNAAgent
    rna_agent = RNAAgent(
        prompt_manager=prompt_manager,
        tool_retriever=tool_retriever,
        upload_dir=upload_dir,
        llm_client=llm_client
    )
    
    # åˆå§‹åŒ–Orchestrator
    orchestrator = Orchestrator(rna_agent)
    
    # æ„å»ºå·¥ä½œæµé…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼Œåªæµ‹è¯•å…³é”®æ­¥éª¤ï¼‰
    workflow_config = {
        "workflow_name": "RNAåˆ†ææµ‹è¯•æµç¨‹",
        "workflow_data": {
            "steps": [
                {
                    "step_id": "rna_qc_filter",
                    "tool_id": "rna_qc_filter",
                    "name": "è´¨é‡æ§åˆ¶è¿‡æ»¤",
                    "params": {
                        "adata_path": str(h5ad_file),
                        "min_genes": 200,
                        "max_mt": 20
                    }
                },
                {
                    "step_id": "rna_normalize",
                    "tool_id": "rna_normalize",
                    "name": "æ•°æ®æ ‡å‡†åŒ–",
                    "params": {
                        "adata_path": "<rna_qc_filter_output>",
                        "target_sum": 10000
                    }
                },
                {
                    "step_id": "rna_pca",
                    "tool_id": "rna_pca",
                    "name": "ä¸»æˆåˆ†åˆ†æ",
                    "params": {
                        "adata_path": "<rna_normalize_output>",
                        "n_comps": 50
                    }
                }
            ]
        },
        "file_paths": [str(h5ad_file)]
    }
    
    logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
    try:
        # æ‰§è¡Œå·¥ä½œæµï¼ˆä½¿ç”¨å¼‚æ­¥ç”Ÿæˆå™¨ï¼‰
        results = None
        async for event in orchestrator.execute_workflow_stream(workflow_config):
            event_type = event.get("type", "")
            event_data = event.get("data", {})
            
            if event_type == "status":
                logger.info(f"ğŸ“Š çŠ¶æ€æ›´æ–°: {event_data.get('content', '')}")
            elif event_type == "step_result":
                logger.info(f"âœ… æ­¥éª¤ç»“æœ: {event_data.get('step_name', '')}")
            elif event_type == "diagnosis":
                logger.info(f"ğŸ’¡ AIä¸“å®¶æŠ¥å‘Šç”Ÿæˆ: {len(event_data.get('report_data', {}).get('summary', ''))} å­—ç¬¦")
            elif event_type == "result":
                results = event_data
                logger.info("âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        
        if results:
            logger.info(f"âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼Œå…± {len(results.get('steps_details', []))} ä¸ªæ­¥éª¤")
            return True
        else:
            logger.error("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥ï¼ˆæœªè¿”å›ç»“æœï¼‰")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return False


async def test_ai_report_generation():
    """æµ‹è¯•3: AIä¸“å®¶åˆ†ææŠ¥å‘Šç”Ÿæˆ"""
    logger.info("=" * 80)
    logger.info("æµ‹è¯•3: AIä¸“å®¶åˆ†ææŠ¥å‘Šç”Ÿæˆ")
    logger.info("=" * 80)
    
    # åˆå§‹åŒ–ç»„ä»¶
    upload_dir = str(project_root / "test_data")
    prompt_manager = PromptManager()
    tool_retriever = ToolRetriever()
    llm_client = LLMClientFactory.create_default()
    
    # åˆå§‹åŒ–RNAAgent
    rna_agent = RNAAgent(
        prompt_manager=prompt_manager,
        tool_retriever=tool_retriever,
        upload_dir=upload_dir,
        llm_client=llm_client
    )
    
    # æ¨¡æ‹Ÿæ‰§è¡Œç»“æœ
    steps_results = [
        {
            "step_name": "è´¨é‡æ§åˆ¶è¿‡æ»¤",
            "status": "success",
            "data": {
                "n_cells": 1000,
                "n_genes": 2000,
                "summary": "è´¨é‡æ§åˆ¶å®Œæˆ"
            }
        },
        {
            "step_name": "æ•°æ®æ ‡å‡†åŒ–",
            "status": "success",
            "data": {
                "summary": "æ ‡å‡†åŒ–å®Œæˆ"
            }
        },
        {
            "step_name": "ä¸»æˆåˆ†åˆ†æ",
            "status": "success",
            "data": {
                "n_components": 50,
                "variance_explained": [0.3, 0.2, 0.1],
                "summary": "PCAåˆ†æå®Œæˆ"
            }
        }
    ]
    
    logger.info("ğŸ“ å¼€å§‹ç”ŸæˆAIä¸“å®¶åˆ†ææŠ¥å‘Š...")
    try:
        summary = await rna_agent._generate_analysis_summary(
            steps_results=steps_results,
            omics_type="scRNA",
            workflow_name="RNAåˆ†ææµ‹è¯•",
            summary_context={
                "has_failures": False,
                "has_warnings": False,
                "failed_steps": [],
                "warning_steps": [],
                "successful_steps": steps_results
            }
        )
        
        if summary:
            logger.info(f"âœ… AIä¸“å®¶åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(summary)}")
            logger.info(f"ğŸ“ æŠ¥å‘Šé¢„è§ˆ:\n{summary[:500]}...")
            
            # æ£€æŸ¥æŠ¥å‘Šè´¨é‡
            has_biology = "ç”Ÿç‰©" in summary or "biology" in summary.lower() or "æœºåˆ¶" in summary
            has_analysis = "åˆ†æ" in summary or "analysis" in summary.lower()
            is_programmer_log = "é”™è¯¯" in summary or "error" in summary.lower() or "å¤±è´¥" in summary or "failed" in summary.lower()
            
            logger.info(f"  - åŒ…å«ç”Ÿç‰©å­¦å†…å®¹: {has_biology}")
            logger.info(f"  - åŒ…å«åˆ†æå†…å®¹: {has_analysis}")
            logger.info(f"  - æ˜¯å¦ä¸ºç¨‹åºå‘˜æ—¥å¿—: {is_programmer_log}")
            
            if has_biology and has_analysis and not is_programmer_log:
                logger.info("âœ… æŠ¥å‘Šè´¨é‡æ£€æŸ¥é€šè¿‡ï¼šåŒ…å«ç”Ÿç‰©å­¦åˆ†æï¼Œéç¨‹åºå‘˜æ—¥å¿—")
                return True
            else:
                logger.warning("âš ï¸ æŠ¥å‘Šè´¨é‡å¯èƒ½ä¸è¶³ï¼šç¼ºå°‘ç”Ÿç‰©å­¦åˆ†ææˆ–åŒ…å«ç¨‹åºå‘˜æ—¥å¿—")
                return False
        else:
            logger.error("âŒ AIä¸“å®¶åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼ˆè¿”å›Noneï¼‰")
            return False
            
    except Exception as e:
        logger.error(f"âŒ AIä¸“å®¶åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("RNAåˆ†æå…¨æµç¨‹è‡ªæµ‹ç¨‹åº")
    logger.info("=" * 80)
    
    results = {
        "æ•°æ®è¯Šæ–­": False,
        "å®Œæ•´å·¥ä½œæµ": False,
        "AIä¸“å®¶æŠ¥å‘Š": False
    }
    
    # æµ‹è¯•1: æ•°æ®è¯Šæ–­
    try:
        results["æ•°æ®è¯Šæ–­"] = await test_data_diagnosis()
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•1å¤±è´¥: {e}", exc_info=True)
    
    # æµ‹è¯•2: å®Œæ•´å·¥ä½œæµ
    try:
        results["å®Œæ•´å·¥ä½œæµ"] = await test_full_workflow()
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•2å¤±è´¥: {e}", exc_info=True)
    
    # æµ‹è¯•3: AIä¸“å®¶æŠ¥å‘Š
    try:
        results["AIä¸“å®¶æŠ¥å‘Š"] = await test_ai_report_generation()
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•3å¤±è´¥: {e}", exc_info=True)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    logger.info("=" * 80)
    logger.info("æµ‹è¯•ç»“æœæ±‡æ€»")
    logger.info("=" * 80)
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")
    
    total_passed = sum(1 for r in results.values() if r)
    logger.info(f"\næ€»è®¡: {total_passed}/{len(results)} æµ‹è¯•é€šè¿‡")
    
    return all(results.values())


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
