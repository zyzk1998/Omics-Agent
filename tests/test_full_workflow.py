#!/usr/bin/env python3
"""
å®Œæ•´å·¥ä½œæµæµ‹è¯•è„šæœ¬
æµ‹è¯•æµç¨‹ï¼š
1. æ— æ–‡ä»¶é¢„è§ˆï¼ˆPlan-Firstæ¨¡å¼ï¼‰
2. ä¸Šä¼ æ–‡ä»¶è§„åˆ’ï¼ˆExecutionæ¨¡å¼ï¼‰
3. æ‰§è¡Œå·¥ä½œæµ
4. éªŒè¯è¾“å‡ºç»“æœ
"""

import asyncio
import sys
import os
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from gibh_agent.core.orchestrator import AgentOrchestrator
from gibh_agent.core.file_inspector import FileInspector
from gibh_agent.core.planner import SOPPlanner
from gibh_agent.core.tool_retriever import ToolRetriever
from gibh_agent.core.executor import WorkflowExecutor
from gibh_agent.llm_client import LLMClient


async def test_full_workflow():
    """æµ‹è¯•å®Œæ•´å·¥ä½œæµ"""
    print("=" * 80)
    print("ğŸ§ª å®Œæ•´å·¥ä½œæµæµ‹è¯•")
    print("=" * 80)
    print()
    
    # åˆå§‹åŒ–ç»„ä»¶
    print("ğŸ“¦ åˆå§‹åŒ–ç»„ä»¶...")
    try:
        llm_client = LLMClient()
        file_inspector = FileInspector()
        tool_retriever = ToolRetriever()
        planner = SOPPlanner(tool_retriever, llm_client)
        orchestrator = AgentOrchestrator(
            agent=None,  # æš‚æ—¶ä¸ä½¿ç”¨agent
            file_inspector=file_inspector
        )
        print("âœ… ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print()
    
    # Step 1: æ— æ–‡ä»¶é¢„è§ˆï¼ˆPlan-Firstæ¨¡å¼ï¼‰
    print("=" * 80)
    print("Step 1: æ— æ–‡ä»¶é¢„è§ˆï¼ˆPlan-Firstæ¨¡å¼ï¼‰")
    print("=" * 80)
    try:
        query = "ä»£è°¢ç»„å­¦åˆ†æ"
        print(f"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {query}")
        print("ğŸ“¤ å‘é€è¯·æ±‚ï¼ˆæ— æ–‡ä»¶ï¼‰...")
        
        events = []
        async for event in orchestrator.stream_process(query=query, files=None):
            events.append(event)
            # è§£æSSEäº‹ä»¶
            if event.startswith("event:"):
                event_type = event.split("event:")[1].split("\n")[0].strip()
                if "data:" in event:
                    data_str = event.split("data:")[1].strip()
                    try:
                        data = json.loads(data_str)
                        if event_type == "workflow":
                            print(f"âœ… æ”¶åˆ°workflowäº‹ä»¶: {len(data.get('workflow_config', {}).get('workflow_data', {}).get('steps', []))} ä¸ªæ­¥éª¤")
                        elif event_type == "status":
                            print(f"ğŸ“Š çŠ¶æ€: {data.get('content', '')}")
                    except:
                        pass
        
        print(f"âœ… Step 1å®Œæˆ: æ”¶åˆ° {len(events)} ä¸ªäº‹ä»¶")
        print()
    except Exception as e:
        print(f"âŒ Step 1å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Step 2: ä¸Šä¼ æ–‡ä»¶è§„åˆ’ï¼ˆExecutionæ¨¡å¼ï¼‰
    print("=" * 80)
    print("Step 2: ä¸Šä¼ æ–‡ä»¶è§„åˆ’ï¼ˆExecutionæ¨¡å¼ï¼‰")
    print("=" * 80)
    
    # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
    test_file = None
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith('.csv') and 'test' in file.lower():
                test_file = os.path.join(root, file)
                break
        if test_file:
            break
    
    if not test_file:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•CSVæ–‡ä»¶")
        return False
    
    print(f"ğŸ“ ä½¿ç”¨æµ‹è¯•æ–‡ä»¶: {test_file}")
    
    try:
        # æ£€æŸ¥æ–‡ä»¶
        file_metadata = file_inspector.inspect_file(test_file)
        if file_metadata.get("status") != "success":
            print(f"âŒ æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {file_metadata.get('error')}")
            return False
        
        print(f"âœ… æ–‡ä»¶æ£€æŸ¥æˆåŠŸ:")
        print(f"   - æ ·æœ¬æ•°: {file_metadata.get('n_samples', 'N/A')}")
        print(f"   - ç‰¹å¾æ•°: {file_metadata.get('n_features', 'N/A')}")
        print(f"   - åˆ—æ•°: {len(file_metadata.get('columns', []))}")
        
        # è§„åˆ’å·¥ä½œæµ
        query = "åˆ†æè¿™ä¸ªä»£è°¢ç»„å­¦æ•°æ®"
        files = [{"path": test_file, "name": os.path.basename(test_file)}]
        
        print(f"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {query}")
        print("ğŸ“¤ å‘é€è¯·æ±‚ï¼ˆæœ‰æ–‡ä»¶ï¼‰...")
        
        events = []
        diagnosis_received = False
        workflow_received = False
        
        async for event in orchestrator.stream_process(query=query, files=files):
            events.append(event)
            # è§£æSSEäº‹ä»¶
            if event.startswith("event:"):
                event_type = event.split("event:")[1].split("\n")[0].strip()
                if "data:" in event:
                    data_str = event.split("data:")[1].strip()
                    try:
                        data = json.loads(data_str)
                        if event_type == "diagnosis":
                            diagnosis_received = True
                            print(f"âœ… æ”¶åˆ°diagnosisäº‹ä»¶")
                            print(f"   - æ¶ˆæ¯: {data.get('message', '')[:100]}...")
                        elif event_type == "workflow":
                            workflow_received = True
                            steps = data.get('workflow_config', {}).get('workflow_data', {}).get('steps', [])
                            print(f"âœ… æ”¶åˆ°workflowäº‹ä»¶: {len(steps)} ä¸ªæ­¥éª¤")
                            for i, step in enumerate(steps[:3], 1):
                                print(f"   {i}. {step.get('name', step.get('id', 'Unknown'))}")
                        elif event_type == "status":
                            content = data.get('content', '')
                            if 'æ‰§è¡Œ' in content or 'ç”Ÿæˆ' in content:
                                print(f"ğŸ“Š çŠ¶æ€: {content}")
                    except Exception as e:
                        pass
        
        if diagnosis_received and workflow_received:
            print(f"âœ… Step 2å®Œæˆ: æ”¶åˆ° {len(events)} ä¸ªäº‹ä»¶")
            print(f"   - è¯Šæ–­äº‹ä»¶: âœ…")
            print(f"   - å·¥ä½œæµäº‹ä»¶: âœ…")
        else:
            print(f"âš ï¸ Step 2éƒ¨åˆ†å®Œæˆ: è¯Šæ–­={diagnosis_received}, å·¥ä½œæµ={workflow_received}")
        print()
    except Exception as e:
        print(f"âŒ Step 2å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Step 3: æ‰§è¡Œå·¥ä½œæµ
    print("=" * 80)
    print("Step 3: æ‰§è¡Œå·¥ä½œæµ")
    print("=" * 80)
    
    try:
        # ç”Ÿæˆå·¥ä½œæµé…ç½®
        result = await planner.generate_plan(
            user_query=query,
            file_metadata=file_metadata,
            is_template=False
        )
        
        if result.get("type") != "workflow_config":
            print(f"âŒ è§„åˆ’å¤±è´¥: {result.get('error', 'Unknown error')}")
            return False
        
        workflow_config = result.get("workflow_data", {})
        steps = workflow_config.get("steps", [])
        
        print(f"ğŸ“‹ å·¥ä½œæµé…ç½®ç”ŸæˆæˆåŠŸ: {len(steps)} ä¸ªæ­¥éª¤")
        
        # æ‰§è¡Œå·¥ä½œæµ
        executor = WorkflowExecutor()
        execution_results = executor.execute_workflow(
            workflow_data=workflow_config,
            file_paths=[test_file]
        )
        
        status = execution_results.get("status", "unknown")
        steps_details = execution_results.get("steps_details", [])
        
        print(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ:")
        print(f"   - çŠ¶æ€: {status}")
        print(f"   - æ­¥éª¤æ•°: {len(steps_details)}")
        
        success_count = sum(1 for s in steps_details if s.get("status") == "success")
        print(f"   - æˆåŠŸæ­¥éª¤: {success_count}/{len(steps_details)}")
        
        for step in steps_details[:3]:
            step_name = step.get("step_name", step.get("step_id", "Unknown"))
            step_status = step.get("status", "unknown")
            print(f"   - {step_name}: {step_status}")
        
        print()
    except Exception as e:
        print(f"âŒ Step 3å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Step 4: éªŒè¯è¾“å‡ºç»“æœ
    print("=" * 80)
    print("Step 4: éªŒè¯è¾“å‡ºç»“æœ")
    print("=" * 80)
    
    try:
        output_dir = executor.output_dir if hasattr(executor, 'output_dir') else None
        
        if output_dir and os.path.exists(output_dir):
            print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
            
            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
            csv_files = list(Path(output_dir).glob("*.csv"))
            png_files = list(Path(output_dir).glob("*.png"))
            
            print(f"âœ… ç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"   - CSVæ–‡ä»¶: {len(csv_files)} ä¸ª")
            for f in csv_files[:3]:
                print(f"     * {f.name}")
            print(f"   - PNGå›¾ç‰‡: {len(png_files)} ä¸ª")
            for f in png_files[:3]:
                print(f"     * {f.name}")
        else:
            print("âš ï¸ è¾“å‡ºç›®å½•ä¸å­˜åœ¨æˆ–æœªè®¾ç½®")
        
        print()
        print("=" * 80)
        print("âœ… å®Œæ•´å·¥ä½œæµæµ‹è¯•é€šè¿‡ï¼")
        print("=" * 80)
        return True
        
    except Exception as e:
        print(f"âŒ Step 4å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(test_full_workflow())
    sys.exit(0 if success else 1)
