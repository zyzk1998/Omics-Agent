#!/usr/bin/env python3
"""
ä¸“ä¸šè°ƒè¯•æ—¥å¿—æ”¶é›†å™¨

æ•è·ä»¥ä¸‹å…³é”®è¿‡ç¨‹çš„è¯¦ç»†æ—¥å¿—ï¼š
1. æœ‰æ–‡ä»¶æ¨¡å¼ä¸‹è§„åˆ’é˜¶æ®µçš„LLMæ•°æ®è¯Šæ–­è¿‡ç¨‹
2. ä»£è°¢ç»„åˆ†æè¿‡ç¨‹æ‰€æœ‰å·¥å…·çš„å‚æ•°ã€è¾“å…¥è¾“å‡º
3. æ‰§è¡Œç»“æœå›æ»šLLMç”Ÿæˆåˆ†ææŠ¥å‘Šçš„å…¨éƒ¨è¿‡ç¨‹

ä½¿ç”¨æ–¹æ³•ï¼š
    python3 scripts/debug_log_collector.py
"""

import os
import sys
import json
import logging
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional
from contextlib import contextmanager

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

from gibh_agent.core.file_inspector import FileInspector
from gibh_agent.core.orchestrator import AgentOrchestrator
from gibh_agent.core.executor import WorkflowExecutor
from gibh_agent.core.llm_client import LLMClient
from gibh_agent.core.prompt_manager import PromptManager, create_default_prompt_manager
from gibh_agent.agents.specialists.metabolomics_agent import MetabolomicsAgent


# ============================================
# è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨
# ============================================

class CategoryFilter(logging.Filter):
    """æŒ‰ç±»åˆ«è¿‡æ»¤æ—¥å¿—"""
    
    def __init__(self, category: str, allowed_modules: List[str]):
        super().__init__()
        self.category = category
        self.allowed_modules = allowed_modules
    
    def filter(self, record):
        """æ£€æŸ¥æ—¥å¿—è®°å½•æ˜¯å¦å±äºæ­¤ç±»åˆ«"""
        module_name = record.name
        
        # æ£€æŸ¥æ¨¡å—æ˜¯å¦åŒ¹é…
        for allowed in self.allowed_modules:
            if module_name.startswith(allowed):
                return True
        
        return False


class DetailedFileHandler(logging.Handler):
    """è¯¦ç»†çš„æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨ï¼Œè®°å½•å‡½æ•°è°ƒç”¨ã€å‚æ•°ã€è¿”å›å€¼ç­‰"""
    
    def __init__(self, log_file: str, category: str):
        super().__init__()
        self.log_file = log_file
        self.category = category
        self.log_dir = project_root / "debug_logs"
        self.log_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        file_path = self.log_dir / log_file
        self.file_handler = logging.FileHandler(file_path, encoding='utf-8')
        self.file_handler.setLevel(logging.DEBUG)
        
        # è¯¦ç»†æ ¼å¼
        formatter = logging.Formatter(
            '%(asctime)s | %(levelname)-8s | %(name)-40s | %(funcName)s:%(lineno)d | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S.%f'
        )
        self.file_handler.setFormatter(formatter)
    
    def emit(self, record):
        """å‘é€æ—¥å¿—è®°å½•åˆ°æ–‡ä»¶"""
        try:
            self.file_handler.emit(record)
        except Exception:
            self.handleError(record)
    
    def close(self):
        """å…³é—­æ–‡ä»¶å¤„ç†å™¨"""
        self.file_handler.close()
        super().close()


class LogCollector:
    """æ—¥å¿—æ”¶é›†å™¨ï¼Œç®¡ç†å¤šä¸ªæ—¥å¿—å¤„ç†å™¨"""
    
    def __init__(self):
        self.log_dir = project_root / "debug_logs"
        self.log_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.timestamp = timestamp
        
        # ä¸‰ä¸ªæ—¥å¿—æ–‡ä»¶
        self.log_files = {
            "diagnosis": f"01_diagnosis_planning_{timestamp}.log",
            "execution": f"02_tool_execution_{timestamp}.log",
            "report": f"03_llm_report_generation_{timestamp}.log"
        }
        
        # æ—¥å¿—å¤„ç†å™¨å­—å…¸
        self.handlers: Dict[str, DetailedFileHandler] = {}
        
        # æ ¹æ—¥å¿—è®°å½•å™¨
        self.root_logger = logging.getLogger()
        self.original_level = self.root_logger.level
        
    def setup(self):
        """è®¾ç½®æ—¥å¿—æ”¶é›†"""
        print("=" * 80)
        print("ğŸ” è®¾ç½®ä¸“ä¸šè°ƒè¯•æ—¥å¿—æ”¶é›†å™¨")
        print("=" * 80)
        
        # è®¾ç½®æ ¹æ—¥å¿—çº§åˆ«ä¸ºDEBUG
        self.root_logger.setLevel(logging.DEBUG)
        
        # åˆ›å»ºä¸‰ä¸ªä¸“é—¨çš„æ—¥å¿—å¤„ç†å™¨
        for category, log_file in self.log_files.items():
            handler = DetailedFileHandler(log_file, category)
            handler.setLevel(logging.DEBUG)
            self.handlers[category] = handler
            self.root_logger.addHandler(handler)
            print(f"âœ… å·²åˆ›å»ºæ—¥å¿—å¤„ç†å™¨: {category} -> {log_file}")
        
        # æ·»åŠ æ§åˆ¶å°è¾“å‡ºï¼ˆINFOçº§åˆ«ï¼‰
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s')
        console_handler.setFormatter(console_formatter)
        self.root_logger.addHandler(console_handler)
        
        print(f"\nğŸ“ æ—¥å¿—æ–‡ä»¶å°†ä¿å­˜åˆ°: {self.log_dir}")
        print("=" * 80)
    
    def add_module_filter(self, module_names: List[str], category: str):
        """ä¸ºç‰¹å®šæ¨¡å—æ·»åŠ è¿‡æ»¤å™¨"""
        if category not in self.handlers:
            return
        
        handler = self.handlers[category]
        filter_obj = CategoryFilter(category, module_names)
        handler.addFilter(filter_obj)
        print(f"âœ… å·²ä¸ºç±»åˆ« '{category}' æ·»åŠ æ¨¡å—è¿‡æ»¤å™¨: {module_names}")
    
    def cleanup(self):
        """æ¸…ç†æ—¥å¿—å¤„ç†å™¨"""
        for handler in self.handlers.values():
            handler.close()
            self.root_logger.removeHandler(handler)
        
        # æ¢å¤åŸå§‹æ—¥å¿—çº§åˆ«
        self.root_logger.setLevel(self.original_level)
        
        print("\n" + "=" * 80)
        print("âœ… æ—¥å¿—æ”¶é›†å®Œæˆ")
        print("=" * 80)
        print(f"\nğŸ“ æ—¥å¿—æ–‡ä»¶ä½ç½®:")
        for category, log_file in self.log_files.items():
            file_path = self.log_dir / log_file
            if file_path.exists():
                size = file_path.stat().st_size
                print(f"   {category:12s}: {file_path} ({size:,} bytes)")
        print("=" * 80)


# ============================================
# å‡½æ•°åŒ…è£…å™¨ï¼ˆç”¨äºæ•è·å‚æ•°å’Œè¿”å›å€¼ï¼‰
# ============================================

def log_function_call(logger_name: str, category: str):
    """è£…é¥°å™¨ï¼šè®°å½•å‡½æ•°è°ƒç”¨ã€å‚æ•°å’Œè¿”å›å€¼"""
    def decorator(func):
        async def async_wrapper(*args, **kwargs):
            logger = logging.getLogger(logger_name)
            
            # è®°å½•å‡½æ•°è°ƒç”¨
            logger.info(f"ğŸ”µ [CALL] {func.__name__}()")
            logger.debug(f"   ğŸ“¥ Args: {args}")
            logger.debug(f"   ğŸ“¥ Kwargs: {kwargs}")
            
            try:
                # æ‰§è¡Œå‡½æ•°
                result = await func(*args, **kwargs)
                
                # è®°å½•è¿”å›å€¼
                if isinstance(result, (str, dict, list)):
                    result_str = json.dumps(result, ensure_ascii=False, indent=2) if isinstance(result, dict) else str(result)
                    if len(result_str) > 1000:
                        result_str = result_str[:1000] + "... (truncated)"
                    logger.debug(f"   ğŸ“¤ Return: {result_str}")
                else:
                    logger.debug(f"   ğŸ“¤ Return: {type(result).__name__}")
                
                logger.info(f"âœ… [SUCCESS] {func.__name__}()")
                return result
            except Exception as e:
                logger.error(f"âŒ [ERROR] {func.__name__}(): {e}", exc_info=True)
                raise
        
        def sync_wrapper(*args, **kwargs):
            logger = logging.getLogger(logger_name)
            
            # è®°å½•å‡½æ•°è°ƒç”¨
            logger.info(f"ğŸ”µ [CALL] {func.__name__}()")
            logger.debug(f"   ğŸ“¥ Args: {args}")
            logger.debug(f"   ğŸ“¥ Kwargs: {kwargs}")
            
            try:
                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)
                
                # è®°å½•è¿”å›å€¼
                if isinstance(result, (str, dict, list)):
                    result_str = json.dumps(result, ensure_ascii=False, indent=2) if isinstance(result, dict) else str(result)
                    if len(result_str) > 1000:
                        result_str = result_str[:1000] + "... (truncated)"
                    logger.debug(f"   ğŸ“¤ Return: {result_str}")
                else:
                    logger.debug(f"   ğŸ“¤ Return: {type(result).__name__}")
                
                logger.info(f"âœ… [SUCCESS] {func.__name__}()")
                return result
            except Exception as e:
                logger.error(f"âŒ [ERROR] {func.__name__}(): {e}", exc_info=True)
                raise
        
        if asyncio.iscoroutinefunction(func):
            return async_wrapper
        else:
            return sync_wrapper
    
    return decorator


# ============================================
# æµ‹è¯•å·¥ä½œæµ
# ============================================

async def test_metabolomics_workflow(log_collector: LogCollector):
    """æµ‹è¯•ä»£è°¢ç»„å­¦å·¥ä½œæµï¼Œæ”¶é›†æ‰€æœ‰æ—¥å¿—"""
    
    print("\n" + "=" * 80)
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ä»£è°¢ç»„å­¦å·¥ä½œæµ")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–ç»„ä»¶
    print("\nğŸ“‹ Step 1: åˆå§‹åŒ–ç»„ä»¶...")
    
    # LLMå®¢æˆ·ç«¯
    base_url = os.getenv("LLM_BASE_URL", "http://localhost:8000/v1")
    api_key = os.getenv("LLM_API_KEY", "sk-test")
    llm_client = LLMClient(base_url=base_url, api_key=api_key)
    
    # Prompt Manager
    prompt_manager = create_default_prompt_manager()
    
    # Agent
    agent = MetabolomicsAgent(
        llm_client=llm_client,
        prompt_manager=prompt_manager
    )
    
    # File Inspector
    upload_dir = project_root / "test_data"
    upload_dir.mkdir(exist_ok=True)
    file_inspector = FileInspector(upload_dir=str(upload_dir))
    
    # Orchestrator
    orchestrator = AgentOrchestrator(agent=agent, upload_dir=str(upload_dir))
    
    # Executor
    executor = WorkflowExecutor(upload_dir=str(upload_dir))
    
    # 2. æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
    print("\nğŸ“‹ Step 2: æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶...")
    test_files = list(upload_dir.glob("*.csv"))
    if not test_files:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶ï¼Œè¯·å°†CSVæ–‡ä»¶æ”¾å…¥ test_data/ ç›®å½•")
        print("   æç¤º: å¯ä»¥ä½¿ç”¨ç¤ºä¾‹æ•°æ®æˆ–åˆ›å»ºæµ‹è¯•æ–‡ä»¶")
        return
    
    test_file = test_files[0]
    print(f"âœ… æ‰¾åˆ°æµ‹è¯•æ–‡ä»¶: {test_file}")
    
    # è®°å½•æ–‡ä»¶ä¿¡æ¯
    diagnosis_logger = logging.getLogger("gibh_agent.core.file_inspector")
    diagnosis_logger.info(f"ğŸ“ æµ‹è¯•æ–‡ä»¶è·¯å¾„: {test_file}")
    diagnosis_logger.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {test_file.stat().st_size:,} bytes")
    
    # 3. æ–‡ä»¶æ£€æŸ¥å’Œè¯Šæ–­ï¼ˆè§„åˆ’é˜¶æ®µï¼‰
    print("\n" + "=" * 80)
    print("ğŸ“Š Phase 1: æ–‡ä»¶æ£€æŸ¥å’ŒLLMæ•°æ®è¯Šæ–­ï¼ˆè§„åˆ’é˜¶æ®µï¼‰")
    print("=" * 80)
    
    diagnosis_logger = logging.getLogger("gibh_agent.core.file_inspector")
    diagnosis_logger.info("=" * 80)
    diagnosis_logger.info("PHASE 1: æ–‡ä»¶æ£€æŸ¥å’ŒLLMæ•°æ®è¯Šæ–­ï¼ˆè§„åˆ’é˜¶æ®µï¼‰")
    diagnosis_logger.info("=" * 80)
    
    file_metadata = None
    diagnosis = None
    
    try:
        # æ–‡ä»¶æ£€æŸ¥
        diagnosis_logger.info(f"ğŸ” å¼€å§‹æ–‡ä»¶æ£€æŸ¥: {test_file}")
        file_metadata = file_inspector.inspect_file(str(test_file))
        diagnosis_logger.info(f"âœ… æ–‡ä»¶æ£€æŸ¥å®Œæˆ: {file_metadata.get('status', 'unknown')}")
        
        # è¯¦ç»†è®°å½•æ–‡ä»¶å…ƒæ•°æ®
        if file_metadata:
            diagnosis_logger.info("ğŸ“Š æ–‡ä»¶å…ƒæ•°æ®æ‘˜è¦:")
            diagnosis_logger.info(f"   - çŠ¶æ€: {file_metadata.get('status')}")
            diagnosis_logger.info(f"   - æ–‡ä»¶ç±»å‹: {file_metadata.get('file_type')}")
            diagnosis_logger.info(f"   - è¡Œæ•°: {file_metadata.get('shape', {}).get('rows', 'N/A')}")
            diagnosis_logger.info(f"   - åˆ—æ•°: {file_metadata.get('shape', {}).get('cols', 'N/A')}")
            diagnosis_logger.info(f"   - ç¼ºå¤±ç‡: {file_metadata.get('missing_rate', 'N/A')}%")
            
            # å®Œæ•´å…ƒæ•°æ®ï¼ˆDEBUGçº§åˆ«ï¼‰
            diagnosis_logger.debug(f"ğŸ“‹ å®Œæ•´æ–‡ä»¶å…ƒæ•°æ®:\n{json.dumps(file_metadata, ensure_ascii=False, indent=2)}")
        
        # LLMè¯Šæ–­
        if file_metadata and file_metadata.get("status") == "success":
            diagnosis_logger = logging.getLogger("gibh_agent.agents.base_agent")
            diagnosis_logger.info("=" * 80)
            diagnosis_logger.info("ğŸ” å¼€å§‹LLMæ•°æ®è¯Šæ–­...")
            diagnosis_logger.info("=" * 80)
            
            # åŠ è½½æ•°æ®é¢„è§ˆ
            import pandas as pd
            df = pd.read_csv(test_file, nrows=100)
            diagnosis_logger.info(f"ğŸ“Š æ•°æ®é¢„è§ˆåŠ è½½å®Œæˆ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
            
            # è®°å½•LLMè°ƒç”¨å‚æ•°
            diagnosis_logger.info("ğŸ“ LLMè°ƒç”¨å‚æ•°:")
            diagnosis_logger.info(f"   - omics_type: Metabolomics")
            diagnosis_logger.info(f"   - file_metadata: {json.dumps(file_metadata, ensure_ascii=False)[:500]}...")
            
            diagnosis = await agent._perform_data_diagnosis(
                file_metadata=file_metadata,
                omics_type="Metabolomics",
                dataframe=df,
                system_instruction=None
            )
            
            diagnosis_logger.info(f"âœ… LLMè¯Šæ–­å®Œæˆï¼Œé•¿åº¦: {len(diagnosis) if diagnosis else 0}")
            if diagnosis:
                diagnosis_logger.info("ğŸ“ è¯Šæ–­æŠ¥å‘Šé¢„è§ˆ:")
                diagnosis_logger.info(f"{diagnosis[:1000]}...")
                # å®Œæ•´æŠ¥å‘Šï¼ˆDEBUGçº§åˆ«ï¼‰
                diagnosis_logger.debug(f"ğŸ“ å®Œæ•´è¯Šæ–­æŠ¥å‘Š:\n{diagnosis}")
    
    except Exception as e:
        diagnosis_logger.error(f"âŒ Phase 1 å¤±è´¥: {e}", exc_info=True)
        import traceback
        diagnosis_logger.error(f"âŒ å®Œæ•´é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
    
    # 4. å·¥ä½œæµæ‰§è¡Œï¼ˆå·¥å…·è°ƒç”¨ï¼‰
    print("\n" + "=" * 80)
    print("ğŸ”§ Phase 2: å·¥ä½œæµæ‰§è¡Œï¼ˆå·¥å…·å‚æ•°å’Œè¾“å…¥è¾“å‡ºï¼‰")
    print("=" * 80)
    
    execution_logger = logging.getLogger("gibh_agent.core.executor")
    execution_logger.info("=" * 80)
    execution_logger.info("PHASE 2: å·¥ä½œæµæ‰§è¡Œï¼ˆå·¥å…·å‚æ•°å’Œè¾“å…¥è¾“å‡ºï¼‰")
    execution_logger.info("=" * 80)
    
    results = None
    
    try:
        # åˆ›å»ºç®€å•çš„å·¥ä½œæµé…ç½®
        workflow_config = {
            "workflow_name": "ä»£è°¢ç»„å­¦åˆ†ææµ‹è¯•",
            "steps": [
                {
                    "id": "preprocess",
                    "name": "æ•°æ®é¢„å¤„ç†",
                    "tool_id": "metabolomics_preprocess_data",
                    "parameters": {
                        "file_path": str(test_file),
                        "log_transform": True,
                        "standardize": True
                    }
                }
            ]
        }
        
        execution_logger.info("ğŸ“‹ å·¥ä½œæµé…ç½®:")
        execution_logger.info(f"{json.dumps(workflow_config, ensure_ascii=False, indent=2)}")
        
        # æ‰§è¡Œå·¥ä½œæµï¼ˆåŒæ­¥æ–¹æ³•ï¼‰
        execution_logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
        results = executor.execute_workflow(
            workflow_data=workflow_config,
            file_paths=[str(test_file)],
            output_dir=None,
            agent=agent
        )
        
        execution_logger.info(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        
        # è¯¦ç»†è®°å½•æ‰§è¡Œç»“æœ
        if results:
            execution_logger.info("ğŸ“Š æ‰§è¡Œç»“æœæ‘˜è¦:")
            execution_logger.info(f"   - çŠ¶æ€: {results.get('status', 'unknown')}")
            execution_logger.info(f"   - æ­¥éª¤æ•°: {len(results.get('steps_details', []))}")
            
            # è®°å½•æ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯
            steps_details = results.get('steps_details', [])
            for i, step_detail in enumerate(steps_details, 1):
                execution_logger.info(f"\nğŸ“‹ æ­¥éª¤ {i}:")
                execution_logger.info(f"   - ID: {step_detail.get('step_id', 'N/A')}")
                execution_logger.info(f"   - åç§°: {step_detail.get('step_name', 'N/A')}")
                execution_logger.info(f"   - çŠ¶æ€: {step_detail.get('status', 'N/A')}")
                
                # è®°å½•å·¥å…·è°ƒç”¨å‚æ•°
                step_result = step_detail.get('step_result', {})
                if step_result:
                    execution_logger.info(f"   - å·¥å…·è¾“å‡ºçŠ¶æ€: {step_result.get('status', 'N/A')}")
                    execution_logger.debug(f"   - å®Œæ•´æ­¥éª¤ç»“æœ:\n{json.dumps(step_result, ensure_ascii=False, indent=6)}")
            
            # å®Œæ•´ç»“æœï¼ˆDEBUGçº§åˆ«ï¼‰
            execution_logger.debug(f"ğŸ“‹ å®Œæ•´æ‰§è¡Œç»“æœ:\n{json.dumps(results, ensure_ascii=False, indent=2)}")
    
    except Exception as e:
        execution_logger.error(f"âŒ Phase 2 å¤±è´¥: {e}", exc_info=True)
        import traceback
        execution_logger.error(f"âŒ å®Œæ•´é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
    
    # 5. LLMç”Ÿæˆåˆ†ææŠ¥å‘Š
    print("\n" + "=" * 80)
    print("ğŸ“ Phase 3: LLMç”Ÿæˆåˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    report_logger = logging.getLogger("gibh_agent.agents.base_agent")
    report_logger.info("=" * 80)
    report_logger.info("PHASE 3: LLMç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆæ‰§è¡Œç»“æœå›æ»šï¼‰")
    report_logger.info("=" * 80)
    
    summary = None
    
    try:
        # ä»æ‰§è¡Œç»“æœä¸­æå–æ­¥éª¤ç»“æœ
        steps_results = []
        if results and results.get('steps_details'):
            for step_detail in results.get('steps_details', []):
                step_result = step_detail.get('step_result', {})
                if step_result:
                    steps_results.append({
                        "step_name": step_detail.get('step_name', 'Unknown'),
                        "status": step_result.get('status', 'unknown'),
                        "data": step_result.get('data', {})
                    })
        
        # å¦‚æœæ²¡æœ‰æ‰§è¡Œç»“æœï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        if not steps_results:
            report_logger.warning("âš ï¸ æœªæ‰¾åˆ°æ‰§è¡Œç»“æœï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            steps_results = [
                {
                    "step_name": "æ•°æ®é¢„å¤„ç†",
                    "status": "success",
                    "data": {
                        "summary": {
                            "n_samples": 10,
                            "n_features": 50
                        }
                    }
                }
            ]
        
        report_logger.info(f"ğŸ“Š æ­¥éª¤ç»“æœæ•°é‡: {len(steps_results)}")
        report_logger.debug(f"ğŸ“Š æ­¥éª¤ç»“æœè¯¦æƒ…:\n{json.dumps(steps_results, ensure_ascii=False, indent=2)}")
        
        # è®°å½•LLMè°ƒç”¨å‚æ•°
        report_logger.info("ğŸ“ LLMè°ƒç”¨å‚æ•°:")
        report_logger.info(f"   - omics_type: Metabolomics")
        report_logger.info(f"   - workflow_name: ä»£è°¢ç»„å­¦åˆ†ææµ‹è¯•")
        report_logger.info(f"   - steps_resultsæ•°é‡: {len(steps_results)}")
        
        # ç”ŸæˆæŠ¥å‘Š
        report_logger.info("ğŸš€ å¼€å§‹è°ƒç”¨LLMç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        summary = await agent._generate_analysis_summary(
            steps_results=steps_results,
            omics_type="Metabolomics",
            workflow_name="ä»£è°¢ç»„å­¦åˆ†ææµ‹è¯•",
            summary_context=None,
            output_dir=None
        )
        
        report_logger.info(f"âœ… LLMæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(summary) if summary else 0}")
        if summary:
            report_logger.info("ğŸ“ æŠ¥å‘Šé¢„è§ˆ:")
            report_logger.info(f"{summary[:1000]}...")
            # å®Œæ•´æŠ¥å‘Šï¼ˆDEBUGçº§åˆ«ï¼‰
            report_logger.debug(f"ğŸ“ å®Œæ•´æŠ¥å‘Š:\n{summary}")
        else:
            report_logger.warning("âš ï¸ LLMæŠ¥å‘Šä¸ºç©º")
    
    except Exception as e:
        report_logger.error(f"âŒ Phase 3 å¤±è´¥: {e}", exc_info=True)
        import traceback
        report_logger.error(f"âŒ å®Œæ•´é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)


async def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºæ—¥å¿—æ”¶é›†å™¨
    log_collector = LogCollector()
    log_collector.setup()
    
    # æ·»åŠ æ¨¡å—è¿‡æ»¤å™¨
    log_collector.add_module_filter([
        "gibh_agent.agents.base_agent",
        "gibh_agent.core.file_inspector",
        "gibh_agent.core.orchestrator",
        "gibh_agent.core.llm_client"
    ], "diagnosis")
    
    log_collector.add_module_filter([
        "gibh_agent.core.executor",
        "gibh_agent.tools",
        "gibh_agent.core.tool_registry"
    ], "execution")
    
    log_collector.add_module_filter([
        "gibh_agent.agents.base_agent",
        "gibh_agent.core.llm_client"
    ], "report")
    
    try:
        # è¿è¡Œæµ‹è¯•
        await test_metabolomics_workflow(log_collector)
    
    finally:
        # æ¸…ç†
        log_collector.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
