#!/usr/bin/env python3
"""
æµ‹è¯•RNAåˆ†æAIä¸“å®¶åˆ†ææŠ¥å‘Šç”ŸæˆåŠŸèƒ½
æ¨¡æ‹Ÿå®Œæ•´çš„LLMè°ƒç”¨æµç¨‹
"""

import asyncio
import json
import sys
import os
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from gibh_agent.agents.specialists.rna_agent import RNAAgent
from gibh_agent.core.llm_client import LLMClientFactory
from gibh_agent.core.prompt_manager import PromptManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_rna_ai_report_generation():
    """æµ‹è¯•RNAåˆ†æAIä¸“å®¶åˆ†ææŠ¥å‘Šç”Ÿæˆ"""
    
    # 1. åˆ›å»ºRNAAgentå®ä¾‹
    logger.info("=" * 80)
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•RNAåˆ†æAIä¸“å®¶åˆ†ææŠ¥å‘Šç”Ÿæˆ")
    logger.info("=" * 80)
    
    try:
        # åˆ›å»ºLLMå®¢æˆ·ç«¯å’ŒPromptç®¡ç†å™¨
        llm_client = LLMClientFactory.create_default()
        prompt_manager = PromptManager()
        
        agent = RNAAgent(llm_client=llm_client, prompt_manager=prompt_manager)
        logger.info(f"âœ… RNAAgentåˆ›å»ºæˆåŠŸ")
        logger.info(f"   - LLM Client: {agent.llm_client.__class__.__name__ if agent.llm_client else 'None'}")
        logger.info(f"   - Base URL: {agent.llm_client.base_url if agent.llm_client and hasattr(agent.llm_client, 'base_url') else 'N/A'}")
        logger.info(f"   - æ˜¯å¦æœ‰_generate_analysis_summaryæ–¹æ³•: {hasattr(agent, '_generate_analysis_summary')}")
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºRNAAgentå¤±è´¥: {e}", exc_info=True)
        return
    
    # 2. æ„å»ºæ¨¡æ‹Ÿçš„æ‰§è¡Œç»“æœæ•°æ®ï¼ˆåŸºäºRNAåˆ†ææµç¨‹ï¼‰
    mock_results = {
        "workflow_name": "scRNA-seq æ ‡å‡†åˆ†ææµç¨‹",
        "status": "success",
        "steps_results": [
            {
                "step_name": "æ•°æ®æ£€æŸ¥",
                "status": "success",
                "data": {
                    "n_cells": 2000,
                    "n_genes": 3000,
                    "mitochondrial_percentage": 5.2,
                    "summary": "æ£€æµ‹åˆ° 2000 ä¸ªç»†èƒï¼Œ3000 ä¸ªåŸºå› "  # summaryæ˜¯å­—ç¬¦ä¸²
                }
            },
            {
                "step_name": "è´¨é‡æ§åˆ¶",
                "status": "success",
                "data": {
                    "n_obs_before": 2000,
                    "n_obs_after": 1800,
                    "n_vars_before": 3000,
                    "n_vars_after": 2800,
                    "summary": "è¿‡æ»¤åå‰©ä½™ 1800 ä¸ªç»†èƒï¼Œ2800 ä¸ªåŸºå› "  # summaryæ˜¯å­—ç¬¦ä¸²
                }
            },
            {
                "step_name": "æ ‡å‡†åŒ–",
                "status": "success",
                "data": {
                    "summary": {
                        "normalization_method": "log_normalize",
                        "target_sum": 10000
                    }
                }
            },
            {
                "step_name": "PCAåˆ†æ",
                "status": "success",
                "data": {
                    "n_comps": 50,
                    "explained_variance": {
                        "PC1": 0.15,
                        "PC2": 0.10,
                        "PC3": 0.08,
                        "PC4": 0.06,
                        "PC5": 0.05
                    },
                    "summary": "PCA é™ç»´å®Œæˆ"  # summaryæ˜¯å­—ç¬¦ä¸²
                }
            },
            {
                "step_name": "UMAPé™ç»´",
                "status": "success",
                "data": {
                    "n_neighbors": 15,
                    "min_dist": 0.5,
                    "summary": "UMAP ç”Ÿæˆå®Œæ¯•"  # summaryæ˜¯å­—ç¬¦ä¸²
                }
            },
            {
                "step_name": "Leiden èšç±»",
                "status": "success",
                "data": {
                    "algorithm": "leiden",
                    "resolution": 0.5,
                    "n_clusters": 8,
                    "summary": "Leiden èšç±» (Res=0.5): 8 ä¸ªç°‡"  # summaryæ˜¯å­—ç¬¦ä¸²
                }
            },
            {
                "step_name": "æ ‡è®°åŸºå› è¯†åˆ«",
                "status": "success",
                "data": {
                    "method": "t-test",
                    "n_clusters": 8,
                    "n_genes_per_cluster": 5,
                    "markers_table": [
                        {
                            "0_names": "CD3D",
                            "0_pvals": 0.0,
                            "1_names": "CD79A",
                            "1_pvals": 1e-100,
                            "2_names": "MS4A1",
                            "2_pvals": 1e-80
                        }
                    ],
                    "summary": "Marker åŸºå› é‰´å®šå®Œæˆ"  # summaryæ˜¯å­—ç¬¦ä¸²
                }
            }
        ]
    }
    
    # 3. è°ƒç”¨_generate_analysis_summary
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“ å¼€å§‹è°ƒç”¨_generate_analysis_summary")
    logger.info("=" * 80)
    
    try:
        summary = await agent._generate_analysis_summary(
            steps_results=mock_results["steps_results"],
            omics_type="scRNA",  # RNAåˆ†æç±»å‹
            workflow_name=mock_results["workflow_name"],
            summary_context={
                "has_failures": False,
                "has_warnings": False,
                "failed_steps": [],
                "warning_steps": [],
                "successful_steps": mock_results["steps_results"],
                "workflow_status": "success"
            },
            output_dir=None
        )
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š ç”Ÿæˆç»“æœ")
        logger.info("=" * 80)
        
        if summary:
            logger.info(f"âœ… ç”ŸæˆæˆåŠŸï¼")
            logger.info(f"   - é•¿åº¦: {len(summary)} å­—ç¬¦")
            logger.info(f"   - å‰300å­—ç¬¦é¢„è§ˆ:")
            logger.info(f"   {summary[:300]}...")
            logger.info(f"\n   - å®Œæ•´å†…å®¹:")
            logger.info(f"   {summary}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¿åº•å†…å®¹
            if "æœ¬æ¬¡åˆ†æå®Œæˆäº†" in summary and "è¯·æŸ¥çœ‹ä¸Šæ–¹çš„è¯¦ç»†å›¾è¡¨" in summary:
                logger.warning("âš ï¸ æ£€æµ‹åˆ°ä¿åº•å†…å®¹ï¼å¯èƒ½æ˜¯LLMè°ƒç”¨å¤±è´¥æˆ–è¿”å›å†…å®¹è¿‡çŸ­")
            elif "âš ï¸" in summary or "AIä¸“å®¶åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥" in summary:
                logger.warning("âš ï¸ æ£€æµ‹åˆ°é”™è¯¯ä¿¡æ¯ï¼LLMè°ƒç”¨å¯èƒ½å¤±è´¥")
            else:
                logger.info("âœ… å†…å®¹çœ‹èµ·æ¥æ˜¯çœŸæ­£çš„ç”Ÿä¿¡åˆ†ææŠ¥å‘Š")
                
            # æ£€æŸ¥æ˜¯å¦åŒ…å«RNAç›¸å…³æœ¯è¯­
            rna_keywords = ["ç»†èƒ", "åŸºå› ", "è½¬å½•", "RNA", "scRNA", "è¡¨è¾¾", "cluster", "cluster", "UMAP", "PCA"]
            has_rna_content = any(keyword in summary for keyword in rna_keywords)
            logger.info(f"   - åŒ…å«RNAåˆ†æç›¸å…³å†…å®¹: {has_rna_content}")
        else:
            logger.error("âŒ è¿”å›Noneï¼LLMè°ƒç”¨å¯èƒ½å¤±è´¥")
            
    except Exception as e:
        logger.error(f"âŒ è°ƒç”¨_generate_analysis_summaryå¤±è´¥: {e}", exc_info=True)
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_rna_ai_report_generation())
