#!/usr/bin/env python3
"""
æµ‹è¯•å·¥å…·æ£€ç´¢å™¨

æµ‹è¯•è„šæœ¬ï¼šéªŒè¯ Tool Retriever çš„è¯­ä¹‰æœç´¢åŠŸèƒ½
"""
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_tool_retrieval():
    """æµ‹è¯•å·¥å…·æ£€ç´¢åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•å·¥å…·æ£€ç´¢å™¨")
    print("=" * 60)
    
    try:
        # 1. å¯¼å…¥å·¥å…·å®šä¹‰ï¼ˆè§¦å‘æ³¨å†Œï¼‰
        print("\n1ï¸âƒ£ å¯¼å…¥å·¥å…·å®šä¹‰...")
        from gibh_agent.tools.definitions import *
        from gibh_agent.core.tool_registry import registry
        
        tools = registry.list_tools()
        print(f"   âœ… å·²æ³¨å†Œ {len(tools)} ä¸ªå·¥å…·: {tools}")
        
        # 2. åˆå§‹åŒ–å·¥å…·æ£€ç´¢å™¨
        print("\n2ï¸âƒ£ åˆå§‹åŒ–å·¥å…·æ£€ç´¢å™¨...")
        from gibh_agent.core.tool_retriever import ToolRetriever
        
        chroma_dir = "./data/chroma_tools_test"
        embedding_model = os.getenv("OLLAMA_EMBEDDING_MODEL", "nomic-embed-text")
        ollama_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        
        print(f"   ChromaDB ç›®å½•: {chroma_dir}")
        print(f"   Embedding æ¨¡å‹: {embedding_model}")
        print(f"   Ollama URL: {ollama_url}")
        
        retriever = ToolRetriever(
            persist_directory=chroma_dir,
            embedding_model=embedding_model,
            ollama_base_url=ollama_url
        )
        print("   âœ… å·¥å…·æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # 3. åŒæ­¥å·¥å…·åˆ° ChromaDB
        print("\n3ï¸âƒ£ åŒæ­¥å·¥å…·åˆ° ChromaDB...")
        synced_count = retriever.sync_tools(clear_existing=True)
        print(f"   âœ… æˆåŠŸåŒæ­¥ {synced_count} ä¸ªå·¥å…·")
        
        # 4. æµ‹è¯•è¯­ä¹‰æœç´¢
        print("\n4ï¸âƒ£ æµ‹è¯•è¯­ä¹‰æœç´¢...")
        test_queries = [
            "I want to reduce dimensions",
            "perform differential analysis",
            "preprocess metabolite data",
            "inspect a file"
        ]
        
        for query in test_queries:
            print(f"\n   ğŸ” æŸ¥è¯¢: '{query}'")
            results = retriever.retrieve(query=query, top_k=3)
            
            if results:
                print(f"   âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³å·¥å…·:")
                for i, tool in enumerate(results, 1):
                    print(f"      {i}. {tool['name']} (ç›¸ä¼¼åº¦: {tool['similarity_score']:.4f})")
                    print(f"         æè¿°: {tool['description'][:60]}...")
            else:
                print("   âš ï¸ æœªæ‰¾åˆ°ç›¸å…³å·¥å…·")
        
        # 5. æµ‹è¯•æŒ‰åç§°è·å–å·¥å…·
        print("\n5ï¸âƒ£ æµ‹è¯•æŒ‰åç§°è·å–å·¥å…·...")
        tool_name = "metabolomics_pca"
        tool_schema = retriever.get_tool_by_name(tool_name)
        
        if tool_schema:
            print(f"   âœ… æ‰¾åˆ°å·¥å…·: {tool_schema['name']}")
            print(f"      ç±»åˆ«: {tool_schema['category']}")
            print(f"      å‚æ•°: {list(tool_schema['args_schema'].get('properties', {}).keys())}")
        else:
            print(f"   âŒ æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
        
        print("\n" + "=" * 60)
        print("âœ… æµ‹è¯•å®Œæˆï¼")
        
    except ImportError as e:
        print(f"\nâŒ å¯¼å…¥å¤±è´¥: {e}")
        print("\nè¯·å®‰è£…ä¾èµ–:")
        print("  pip install langchain-chroma langchain-ollama langchain-core")
        print("\nç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ:")
        print("  ollama serve")
        print("  ollama pull nomic-embed-text")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    test_tool_retrieval()

