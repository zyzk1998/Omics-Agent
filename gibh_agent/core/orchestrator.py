"""
Agent ç¼–æ’å™¨ - å®æ—¶æµå¼å¤„ç†

æä¾›ç»Ÿä¸€çš„æµå¼å¤„ç†æ¥å£ï¼Œå®æ—¶è¾“å‡ºçŠ¶æ€æ›´æ–°ã€æ€è€ƒè¿‡ç¨‹å’Œç»“æœã€‚

ğŸ”¥ AGENTIC UPGRADE:
é›†æˆ QueryRewriterã€Clarifier å’Œ Reflector å®ç°æ™ºèƒ½æŸ¥è¯¢å¤„ç†ã€‚
"""
import json
import logging
import asyncio
from typing import Dict, Any, List, Optional, AsyncIterator
from pathlib import Path

from .agentic import QueryRewriter, Clarifier, Reflector
from .file_inspector import FileInspector
from .llm_client import LLMClient
from .workflows import WorkflowRegistry

logger = logging.getLogger(__name__)


class AgentOrchestrator:
    """
    Agent ç¼–æ’å™¨
    
    èŒè´£ï¼š
    1. ç»Ÿä¸€ç®¡ç† Agent çš„æµå¼å¤„ç†æµç¨‹
    2. å®æ—¶è¾“å‡ºçŠ¶æ€æ›´æ–°ã€æ€è€ƒè¿‡ç¨‹å’Œç»“æœ
    3. æä¾›æ¸…æ™°çš„æ‰§è¡Œæ­¥éª¤å¯è§æ€§
    
    ğŸ”¥ AGENTIC UPGRADE:
    - QueryRewriter: æŸ¥è¯¢é‡å†™ï¼ˆæ¨¡ç³Š -> ç²¾ç¡®ï¼‰
    - Clarifier: ä¸»åŠ¨æ¾„æ¸…ï¼ˆè¯¢é—®ç¼ºå¤±ä¿¡æ¯ï¼‰
    - Reflector: è‡ªæˆ‘åæ€ï¼ˆæ£€æŸ¥å’Œçº æ­£è®¡åˆ’ï¼‰
    """
    
    def __init__(self, agent, upload_dir: str = "/app/uploads"):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨
        
        Args:
            agent: Agent å®ä¾‹ï¼ˆGIBHAgentï¼‰
            upload_dir: ä¸Šä¼ æ–‡ä»¶ç›®å½•
        """
        self.agent = agent
        self.upload_dir = Path(upload_dir)
        
        # ğŸ”¥ åˆå§‹åŒ– Agentic ç»„ä»¶
        # è·å– LLM å®¢æˆ·ç«¯ï¼ˆä» agent ä¸­è·å–ï¼‰
        llm_client = self._get_llm_client()
        if llm_client:
            self.query_rewriter = QueryRewriter(llm_client)
            self.clarifier = Clarifier(llm_client)
            self.reflector = Reflector(llm_client)
        else:
            logger.warning("âš ï¸ LLM å®¢æˆ·ç«¯æœªæ‰¾åˆ°ï¼ŒAgentic ç»„ä»¶å°†ä¸å¯ç”¨")
            self.query_rewriter = None
            self.clarifier = None
            self.reflector = None
        
        # åˆå§‹åŒ–æ–‡ä»¶æ£€æŸ¥å™¨
        self.file_inspector = FileInspector(str(self.upload_dir))
        
        # ğŸ”¥ ARCHITECTURAL MERGE: ç»‘å®šåˆ° WorkflowRegistry
        self.workflow_registry = WorkflowRegistry()
        
        # ğŸ”¥ å¯¹è¯çŠ¶æ€ç®¡ç†
        self.conversation_state: Dict[str, Any] = {}
    
    def _get_llm_client(self) -> Optional[LLMClient]:
        """ä» agent ä¸­è·å– LLM å®¢æˆ·ç«¯"""
        try:
            if hasattr(self.agent, 'agents') and self.agent.agents:
                # å°è¯•ä»ç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“è·å– LLM client
                first_agent = list(self.agent.agents.values())[0]
                if hasattr(first_agent, 'llm_client'):
                    return first_agent.llm_client
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ è·å– LLM å®¢æˆ·ç«¯å¤±è´¥: {e}")
            return None
    
    async def stream_process(
        self,
        query: str,
        files: List[Dict[str, str]] = None,
        history: List[Dict[str, str]] = None,
        **kwargs
    ) -> AsyncIterator[str]:
        """
        æµå¼å¤„ç†æŸ¥è¯¢
        
        å®æ—¶è¾“å‡ºï¼š
        1. çŠ¶æ€æ›´æ–°ï¼ˆstatusï¼‰
        2. æ€è€ƒè¿‡ç¨‹ï¼ˆthoughtï¼‰
        3. è¯Šæ–­æ•°æ®ï¼ˆdiagnosisï¼‰
        4. å·¥ä½œæµè®¡åˆ’ï¼ˆworkflowï¼‰
        5. æœ€ç»ˆå“åº”ï¼ˆmessageï¼‰
        6. å®Œæˆä¿¡å·ï¼ˆdoneï¼‰
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
            history: å¯¹è¯å†å²
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields:
            SSE æ ¼å¼çš„äº‹ä»¶å­—ç¬¦ä¸²: "data: {json}\n\n"
        """
        files = files or []
        history = history or []
        # ğŸ”¥ BUG FIX: ä» kwargs ä¸­æå– session_id å’Œ user_id
        session_id = kwargs.get("session_id") or "default"
        user_id = kwargs.get("user_id") or "guest"
        
        # ğŸ”¥ ARCHITECTURAL MERGE: æ£€æŸ¥å¯¹è¯çŠ¶æ€ï¼ˆå¤„ç†æ¾„æ¸…å›å¤å’Œæ‰§è¡Œæ„å›¾ï¼‰
        session_state = self.conversation_state.get(session_id, {})
        awaiting_clarification = session_state.get("awaiting_clarification", False)
        previous_query = session_state.get("previous_query")
        previous_refined_query = session_state.get("previous_refined_query")
        pending_plan = session_state.get("pending_plan")  # ğŸ”¥ URGENT FIX: æ£€æŸ¥æ˜¯å¦æœ‰å¾…æ‰§è¡Œçš„å·¥ä½œæµè®¡åˆ’
        
        # ğŸ”¥ URGENT FIX: æ£€æŸ¥æ‰§è¡Œæ„å›¾ï¼ˆ"Proceed", "ç»§ç»­", "æ‰§è¡Œ"ç­‰ï¼‰
        execution_keywords = ["proceed", "ç»§ç»­", "æ‰§è¡Œ", "go ahead", "run it", "å¼€å§‹", "execute"]
        query_lower = query.lower().strip()
        is_execution_intent = any(kw in query_lower for kw in execution_keywords)
        
        # å¦‚æœæœ‰å¾…æ‰§è¡Œè®¡åˆ’ä¸”ç”¨æˆ·ç¡®è®¤æ‰§è¡Œï¼Œç›´æ¥æ‰§è¡Œå·¥ä½œæµ
        if pending_plan and is_execution_intent:
            logger.info(f"âœ… [Orchestrator] æ£€æµ‹åˆ°æ‰§è¡Œæ„å›¾ï¼Œç›´æ¥æ‰§è¡Œå¾…æ‰§è¡Œçš„å·¥ä½œæµè®¡åˆ’")
            # æ¸…é™¤å¾…æ‰§è¡Œè®¡åˆ’çŠ¶æ€
            self.conversation_state[session_id] = {}
            # ç›´æ¥è°ƒç”¨æ‰§è¡Œé€»è¾‘ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ‰§è¡Œæ¥å£è°ƒæ•´ï¼‰
            # æš‚æ—¶è·³è¿‡ FileInspector å’Œ Diagnosisï¼Œç›´æ¥è¿›å…¥æ‰§è¡Œ
            yield self._format_sse("status", {
                "content": "æ­£åœ¨æ‰§è¡Œå·¥ä½œæµ...",
                "state": "running"
            })
            await asyncio.sleep(0.01)
            # è¿™é‡Œåº”è¯¥è°ƒç”¨æ‰§è¡Œå™¨ï¼Œä½†ä¸ºäº†ä¸ç ´åç°æœ‰æµç¨‹ï¼Œæˆ‘ä»¬ç»§ç»­æ­£å¸¸æµç¨‹
            # å®é™…æ‰§è¡Œä¼šåœ¨å‰ç«¯ç‚¹å‡»"æ‰§è¡Œ"æŒ‰é’®æ—¶è§¦å‘
        
        try:
            # Step 1: ç«‹å³è¾“å‡ºå¼€å§‹çŠ¶æ€
            yield self._format_sse("status", {
                "content": "æ­£åœ¨æ¥æ”¶è¯·æ±‚...",
                "state": "start"
            })
            await asyncio.sleep(0.01)  # å¼ºåˆ¶ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼Œç¡®ä¿ç«‹å³å‘é€
            
            # ğŸ”¥ Step 2: Query Rewritingï¼ˆæŸ¥è¯¢é‡å†™ï¼‰
            # å¦‚æœæ˜¯æ¾„æ¸…å›å¤ï¼Œåˆå¹¶æŸ¥è¯¢å¹¶è·³è¿‡é‡å†™
            if awaiting_clarification and previous_query:
                refined_query = f"{previous_refined_query or previous_query}ã€‚ç”¨æˆ·å›å¤ï¼š{query}"
                logger.info(f"âœ… [Orchestrator] å¤„ç†æ¾„æ¸…å›å¤: '{query}' -> åˆå¹¶æŸ¥è¯¢")
                # æ¸…é™¤æ¾„æ¸…çŠ¶æ€
                self.conversation_state[session_id] = {}
            else:
                refined_query = query
                if self.query_rewriter:
                    yield self._format_sse("status", {
                        "content": "æ­£åœ¨ä¼˜åŒ–æŸ¥è¯¢è¯­å¥...",
                        "state": "running"
                    })
                    await asyncio.sleep(0.01)
                    
                    refined_query = await self.query_rewriter.rewrite(query, history)
                    logger.info(f"âœ… [Orchestrator] æŸ¥è¯¢é‡å†™: '{query}' -> '{refined_query}'")
                else:
                    logger.info("â„¹ï¸ [Orchestrator] QueryRewriter ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢")
            
            # Step 3: File Inspectionï¼ˆæ–‡ä»¶æ£€æŸ¥ï¼‰
            file_metadata = None
            if files:
                yield self._format_sse("status", {
                    "content": f"æ­£åœ¨æ£€æŸ¥ {len(files)} ä¸ªæ–‡ä»¶...",
                    "state": "running"
                })
                await asyncio.sleep(0.01)
                
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼ˆå¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œå¯ä»¥æ‰©å±•ï¼‰
                if files and len(files) > 0:
                    file_path = files[0].get("path")
                    if file_path:
                        try:
                            file_metadata = self.file_inspector.generate_metadata(file_path)
                            logger.info(f"âœ… [Orchestrator] æ–‡ä»¶æ£€æŸ¥å®Œæˆ: {file_path}")
                        except Exception as e:
                            logger.warning(f"âš ï¸ [Orchestrator] æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}")
            
            # ğŸ”¥ Step 4: Domain Identificationï¼ˆä½¿ç”¨ WorkflowRegistry è¯†åˆ«åŸŸåï¼‰
            domain = None
            if self.workflow_registry:
                yield self._format_sse("status", {
                    "content": "æ­£åœ¨è¯†åˆ«åˆ†æé¢†åŸŸ...",
                    "state": "running"
                })
                await asyncio.sleep(0.01)
                
                # å°è¯•ä»æ–‡ä»¶å…ƒæ•°æ®æ¨æ–­åŸŸå
                if file_metadata:
                    file_type = file_metadata.get("file_type", "")
                    if "h5ad" in file_type.lower() or "10x" in file_type.lower():
                        domain = "RNA"
                    elif "csv" in file_type.lower() or "tsv" in file_type.lower():
                        domain = "Metabolomics"
                
                # å¦‚æœæ— æ³•ä»æ–‡ä»¶æ¨æ–­ï¼Œå°è¯•ä»æŸ¥è¯¢æ¨æ–­
                if not domain:
                    # ä½¿ç”¨ LLM æˆ–ç®€å•å…³é”®è¯åŒ¹é…
                    query_lower = refined_query.lower()
                    if any(kw in query_lower for kw in ["rna", "cell", "single-cell", "scrnaseq", "cellranger"]):
                        domain = "RNA"
                    elif any(kw in query_lower for kw in ["metabol", "metab", "ä»£è°¢"]):
                        domain = "Metabolomics"
                
                if domain and self.workflow_registry.is_supported(domain):
                    logger.info(f"âœ… [Orchestrator] è¯†åˆ«åŸŸå: {domain}")
                else:
                    logger.warning(f"âš ï¸ [Orchestrator] æ— æ³•è¯†åˆ«åŸŸåæˆ–åŸŸåä¸æ”¯æŒ: {domain}")
            
            # ğŸ”¥ Step 5: Clarificationï¼ˆæ¾„æ¸…æ£€æŸ¥ - ä¿®å¤ Plan-First é€»è¾‘ï¼‰
            if self.clarifier:
                yield self._format_sse("status", {
                    "content": "æ­£åœ¨æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸…...",
                    "state": "running"
                })
                await asyncio.sleep(0.01)
                
                clarification = await self.clarifier.check_and_clarify(
                    refined_query,
                    file_metadata,
                    domain
                )
                
                if clarification:
                    # éœ€è¦æ¾„æ¸…ï¼Œä¿å­˜çŠ¶æ€å¹¶è¯¢é—®ç”¨æˆ·
                    self.conversation_state[session_id] = {
                        "awaiting_clarification": True,
                        "previous_query": query,
                        "previous_refined_query": refined_query,
                        "domain": domain
                    }
                    
                    yield self._format_sse("question", {
                        "content": clarification,
                        "original_query": query,
                        "refined_query": refined_query,
                        "session_id": session_id
                    })
                    yield self._format_sse("status", {
                        "content": "ç­‰å¾…ç”¨æˆ·æ¾„æ¸…...",
                        "state": "waiting"
                    })
                    return  # åœæ­¢å¤„ç†ï¼Œç­‰å¾…ç”¨æˆ·å›ç­”
            
            # Step 5: Planningï¼ˆè§„åˆ’å·¥ä½œæµï¼‰
            yield self._format_sse("status", {
                "content": "æ­£åœ¨è§„åˆ’å·¥ä½œæµ...",
                "state": "running"
            })
            await asyncio.sleep(0.01)
            
            # è°ƒç”¨ Agent çš„ process_queryï¼ˆä½¿ç”¨é‡å†™åçš„æŸ¥è¯¢ï¼‰
            result = await self.agent.process_query(
                query=refined_query,  # ä½¿ç”¨é‡å†™åçš„æŸ¥è¯¢
                history=history,
                uploaded_files=files,
                **kwargs
            )
            
            # ğŸ”¥ Step 6: Reflectionï¼ˆåæ€å’Œçº æ­£ï¼‰
            workflow_plan = None
            if isinstance(result, dict) and "report_data" in result:
                report_data = result.get("report_data", {})
                workflow_plan = report_data.get("workflow")
                
                if self.reflector and workflow_plan and domain and self.workflow_registry:
                    yield self._format_sse("status", {
                        "content": "æ­£åœ¨åæ€å¹¶ä¼˜åŒ–æµç¨‹...",
                        "state": "running"
                    })
                    await asyncio.sleep(0.01)
                    
                    # ğŸ”¥ ARCHITECTURAL MERGE: ä½¿ç”¨ WorkflowRegistry è¿›è¡Œ DAG æ£€æŸ¥
                    workflow_instance = self.workflow_registry.get_workflow(domain)
                    dag_issues = []
                    if workflow_instance:
                        # é¦–å…ˆè¿›è¡Œ DAG æ£€æŸ¥ï¼ˆç¡¬ç¼–ç è§„åˆ™ï¼‰
                        dag_valid, dag_issues = self._validate_against_dag(
                            workflow_plan,
                            workflow_instance
                        )
                        
                        if not dag_valid:
                            logger.warning(f"âš ï¸ [Orchestrator] DAG éªŒè¯å¤±è´¥: {dag_issues}")
                    
                    # ä½¿ç”¨ Reflector è¿›è¡Œè¯­ä¹‰æ£€æŸ¥å’Œçº æ­£
                    corrected_plan = await self.reflector.reflect_and_correct(
                        workflow_plan,
                        domain,
                        file_metadata,
                        dag_issues=dag_issues if dag_issues else None
                    )
                    
                    # æ›´æ–°ç»“æœä¸­çš„å·¥ä½œæµè®¡åˆ’
                    if corrected_plan != workflow_plan:
                        result["report_data"]["workflow"] = corrected_plan
                        logger.info("âœ… [Orchestrator] å·¥ä½œæµè®¡åˆ’å·²çº æ­£")
            
            # Step 7: å¤„ç†ç»“æœå¹¶æµå¼è¾“å‡º
            if isinstance(result, dict):
                # ğŸ”¥ URGENT FIX: å¤„ç†å¤šç§è¿”å›æ ¼å¼
                # æ ¼å¼1: report_data.workflow / report_data.diagnosis (æ—§æ ¼å¼)
                # æ ¼å¼2: workflow_data + diagnosis (SOPPlanner è¿”å›æ ¼å¼)
                # æ ¼å¼3: workflow_config (Agent è¿”å›æ ¼å¼)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ report_data
                if "report_data" in result:
                    report_data = result.get("report_data", {})
                    
                    # è¾“å‡ºè¯Šæ–­
                    if "diagnosis" in report_data:
                        yield self._format_sse("diagnosis", report_data["diagnosis"])
                        await asyncio.sleep(0.01)
                    
                    # è¾“å‡ºå·¥ä½œæµ
                    if "workflow" in report_data:
                        yield self._format_sse("workflow", report_data["workflow"])
                        await asyncio.sleep(0.01)
                
                # ğŸ”¥ URGENT FIX: å¤„ç† SOPPlanner ç›´æ¥è¿”å›çš„æ ¼å¼
                # å¦‚æœ result æœ¬èº«å°±æ˜¯ workflow_configï¼ˆtype: "workflow_config"ï¼‰
                elif result.get("type") == "workflow_config" or "workflow_data" in result:
                    # æå–è¯Šæ–­
                    diagnosis = result.get("diagnosis")
                    if diagnosis:
                        # å¦‚æœ diagnosis æ˜¯å­—å…¸ï¼Œæå– message
                        if isinstance(diagnosis, dict):
                            diagnosis_data = diagnosis.get("message") or diagnosis
                        else:
                            diagnosis_data = diagnosis
                        yield self._format_sse("diagnosis", diagnosis_data)
                        await asyncio.sleep(0.01)
                    
                    # æå–å·¥ä½œæµ
                    workflow_data = result.get("workflow_data") or result
                    if workflow_data:
                        # ğŸ”¥ CRITICAL: ç¡®ä¿ workflow äº‹ä»¶åŒ…å« workflow_config å­—æ®µï¼ˆå‰ç«¯æœŸæœ›ï¼‰
                        workflow_event_data = {
                            "workflow_config": workflow_data,
                            "workflow_data": workflow_data,  # å…¼å®¹å­—æ®µ
                            "template_mode": result.get("template_mode"),
                            "diagnosis_report": diagnosis.get("message") if isinstance(diagnosis, dict) else diagnosis if diagnosis else None
                        }
                        yield self._format_sse("workflow", workflow_event_data)
                        await asyncio.sleep(0.01)
                
                # è¾“å‡ºæœ€ç»ˆå“åº”
                if "response" in result:
                    response = result["response"]
                    
                    # å¦‚æœæ˜¯å¼‚æ­¥è¿­ä»£å™¨ï¼Œæµå¼è¾“å‡º
                    if hasattr(response, "__aiter__"):
                        yield self._format_sse("status", {
                            "content": "æ­£åœ¨ç”Ÿæˆå›å¤...",
                            "state": "running"
                        })
                        await asyncio.sleep(0.01)
                        
                        # æµå¼è¾“å‡ºå“åº”å†…å®¹
                        buffer = ""
                        async for chunk in response:
                            if chunk:
                                buffer += chunk
                                # æ£€æµ‹æ€è€ƒæ ‡ç­¾
                                if "<think>" in buffer or "<think>" in buffer:
                                    # æå–æ€è€ƒå†…å®¹
                                    import re
                                    think_match = re.search(r'<(?:redacted_reasoning|think)>(.*?)</(?:redacted_reasoning|think)>', buffer, re.DOTALL)
                                    if think_match:
                                        think_content = think_match.group(1)
                                        yield self._format_sse("thought", {
                                            "content": think_content
                                        })
                                        # ç§»é™¤æ€è€ƒæ ‡ç­¾
                                        buffer = re.sub(r'<(?:redacted_reasoning|think)>.*?</(?:redacted_reasoning|think)>', '', buffer, flags=re.DOTALL)
                                
                                # è¾“å‡ºæ¶ˆæ¯å†…å®¹ï¼ˆæ¯ç§¯ç´¯ä¸€å®šé‡æˆ–é‡åˆ°æ¢è¡Œï¼‰
                                if "\n" in buffer or len(buffer) > 100:
                                    lines = buffer.split("\n")
                                    for line in lines[:-1]:  # è¾“å‡ºå®Œæ•´è¡Œ
                                        if line.strip():
                                            yield self._format_sse("message", {
                                                "content": line + "\n"
                                            })
                                    buffer = lines[-1]  # ä¿ç•™æœ€åä¸€è¡Œ
                                    await asyncio.sleep(0.01)
                        
                        # è¾“å‡ºå‰©ä½™å†…å®¹
                        if buffer.strip():
                            yield self._format_sse("message", {
                                "content": buffer
                            })
                    else:
                        # éæµå¼å“åº”ï¼Œç›´æ¥è¾“å‡º
                        yield self._format_sse("message", {
                            "content": str(response)
                        })
                
                # ğŸ”¥ URGENT FIX: è¾“å‡ºå®Œæ•´ç»“æœï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰- ç¡®ä¿åŒ…å« diagnosis_report å’Œ workflow_config
                # è½¬æ¢æ•°æ®ç»“æ„ä»¥åŒ¹é…å‰ç«¯æœŸæœ›
                result_for_frontend = {}
                
                # å¤„ç† report_data æ ¼å¼ï¼ˆæ—§æ ¼å¼ï¼‰
                if "report_data" in result:
                    report_data = result.get("report_data", {})
                    # æå– diagnosis å’Œ workflow
                    if "diagnosis" in report_data:
                        result_for_frontend["diagnosis_report"] = report_data["diagnosis"]
                    if "workflow" in report_data:
                        result_for_frontend["workflow_config"] = report_data["workflow"]
                
                # ğŸ”¥ CRITICAL: å¤„ç† SOPPlanner ç›´æ¥è¿”å›çš„æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰
                elif result.get("type") == "workflow_config" or "workflow_data" in result:
                    # æå–è¯Šæ–­
                    diagnosis = result.get("diagnosis")
                    if diagnosis:
                        if isinstance(diagnosis, dict):
                            result_for_frontend["diagnosis_report"] = diagnosis.get("message") or diagnosis
                        else:
                            result_for_frontend["diagnosis_report"] = diagnosis
                    
                    # æå–å·¥ä½œæµ
                    workflow_data = result.get("workflow_data") or result
                    if workflow_data:
                        result_for_frontend["workflow_config"] = workflow_data
                        result_for_frontend["template_mode"] = result.get("template_mode")
                
                # åŒæ—¶ä¿ç•™åŸå§‹ç»“æ„
                result_for_frontend.update(result)
                yield self._format_sse("result", result_for_frontend)
            else:
                # å¦‚æœç»“æœä¸æ˜¯å­—å…¸ï¼Œç›´æ¥è¾“å‡º
                yield self._format_sse("message", {
                    "content": str(result)
                })
            
            # Step 7: è¾“å‡ºå®ŒæˆçŠ¶æ€
            yield self._format_sse("status", {
                "content": "å¤„ç†å®Œæˆ",
                "state": "completed"
            })
            await asyncio.sleep(0.01)
            
            # Step 8: å‘é€å®Œæˆä¿¡å·
            yield self._format_sse("done", {
                "status": "success"
            })
            
        except Exception as e:
            logger.error(f"âŒ æµå¼å¤„ç†å¤±è´¥: {e}", exc_info=True)
            yield self._format_sse("status", {
                "content": f"å¤„ç†å¤±è´¥: {str(e)}",
                "state": "error"
            })
            yield self._format_sse("error", {
                "error": str(e),
                "message": f"å¤„ç†å¤±è´¥: {str(e)}"
            })
    
    def _format_sse(self, event_type: str, data: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ– SSE äº‹ä»¶
        
        Args:
            event_type: äº‹ä»¶ç±»å‹ï¼ˆstatus, thought, message, diagnosis, workflow, done, errorï¼‰
            data: äº‹ä»¶æ•°æ®
            
        Returns:
            SSE æ ¼å¼å­—ç¬¦ä¸²: "event: {type}\ndata: {json}\n\n"
        """
        json_data = json.dumps(data, ensure_ascii=False)
        return f"event: {event_type}\ndata: {json_data}\n\n"

