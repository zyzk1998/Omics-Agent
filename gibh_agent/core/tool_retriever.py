"""
å·¥å…·æ£€ç´¢å™¨ - Vector Database Integration

å°† ToolRegistry ä¸­çš„å·¥å…·åŒæ­¥åˆ° ChromaDBï¼Œå¹¶æä¾›è¯­ä¹‰æœç´¢åŠŸèƒ½ã€‚
ä½¿ç”¨ LangChain ChromaDB å’Œ Ollama Embeddingsã€‚
"""
import os
import json
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path

try:
    from langchain_chroma import Chroma
    from langchain_ollama import OllamaEmbeddings
    from langchain_core.documents import Document
except ImportError as e:
    logging.warning(f"âš ï¸ LangChain ä¾èµ–æœªå®‰è£…: {e}")
    Chroma = None
    OllamaEmbeddings = None
    Document = None

from .tool_registry import registry

logger = logging.getLogger(__name__)


class ToolRetriever:
    """
    å·¥å…·æ£€ç´¢å™¨
    
    èŒè´£ï¼š
    1. å°† ToolRegistry ä¸­çš„å·¥å…·åŒæ­¥åˆ° ChromaDB
    2. æä¾›åŸºäºè¯­ä¹‰æœç´¢çš„å·¥å…·æ£€ç´¢åŠŸèƒ½
    """
    
    def __init__(
        self,
        persist_directory: str = "./data/chroma_tools",
        embedding_model: str = "nomic-embed-text",
        ollama_base_url: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–å·¥å…·æ£€ç´¢å™¨
        
        Args:
            persist_directory: ChromaDB æŒä¹…åŒ–ç›®å½•
            embedding_model: Ollama embedding æ¨¡å‹åç§°ï¼ˆé»˜è®¤ "nomic-embed-text"ï¼‰
            ollama_base_url: Ollama æœåŠ¡ URLï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–æˆ–ä½¿ç”¨ http://localhost:11434ï¼‰
        """
        if Chroma is None or OllamaEmbeddings is None:
            raise ImportError(
                "âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–ã€‚è¯·å®‰è£…: pip install langchain-chroma langchain-ollama"
            )
        
        self.persist_directory = Path(persist_directory)
        self.persist_directory.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ– Embeddings
        ollama_url = ollama_base_url or os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        logger.info(f"ğŸ”— åˆå§‹åŒ– Ollama Embeddings: {ollama_url}, æ¨¡å‹: {embedding_model}")
        
        try:
            self.embeddings = OllamaEmbeddings(
                model=embedding_model,
                base_url=ollama_url
            )
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ– Ollama Embeddings å¤±è´¥: {e}")
            logger.warning("âš ï¸ å°è¯•ä½¿ç”¨å¤‡ç”¨é…ç½®...")
            # å¤‡ç”¨ï¼šå°è¯•ä¸åŒçš„é…ç½®
            try:
                self.embeddings = OllamaEmbeddings(model=embedding_model)
            except Exception as e2:
                logger.error(f"âŒ å¤‡ç”¨é…ç½®ä¹Ÿå¤±è´¥: {e2}")
                raise
        
        # åˆå§‹åŒ– ChromaDB Vector Store
        collection_name = "tools"
        try:
            self.vector_store = Chroma(
                collection_name=collection_name,
                embedding_function=self.embeddings,
                persist_directory=str(self.persist_directory)
            )
            logger.info(f"âœ… ChromaDB åˆå§‹åŒ–æˆåŠŸ: {self.persist_directory}")
        except Exception as e:
            logger.error(f"âŒ ChromaDB åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
            raise
    
    def sync_tools(self, clear_existing: bool = True) -> int:
        """
        åŒæ­¥ ToolRegistry ä¸­çš„å·¥å…·åˆ° ChromaDB
        
        ğŸ”¥ å…³é”®åŠŸèƒ½ï¼šç¡®ä¿ VDB ä¸ä»£ç ä¸­çš„å·¥å…·å®šä¹‰ä¿æŒä¸€è‡´
        
        Args:
            clear_existing: æ˜¯å¦æ¸…é™¤ç°æœ‰é›†åˆï¼ˆé»˜è®¤ Trueï¼Œç¡®ä¿ä¸€è‡´æ€§ï¼‰
        
        Returns:
            åŒæ­¥çš„å·¥å…·æ•°é‡
        """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥å·¥å…·åˆ° ChromaDB...")
        
        # è·å–æ‰€æœ‰å·¥å…·
        tools_json = registry.get_all_tools_json()
        
        if not tools_json:
            logger.warning("âš ï¸ ToolRegistry ä¸­æ²¡æœ‰å·¥å…·ï¼Œè·³è¿‡åŒæ­¥")
            return 0
        
        logger.info(f"ğŸ“‹ å‘ç° {len(tools_json)} ä¸ªå·¥å…·éœ€è¦åŒæ­¥")
        
        # æ¸…é™¤ç°æœ‰é›†åˆï¼ˆå¦‚æœéœ€è¦ï¼‰
        if clear_existing:
            try:
                # åˆ é™¤ç°æœ‰é›†åˆå¹¶é‡æ–°åˆ›å»º
                # æ³¨æ„ï¼šChroma çš„ delete_collection æ–¹æ³•å¯èƒ½ä¸å­˜åœ¨ï¼Œæˆ‘ä»¬é€šè¿‡åˆ é™¤å¹¶é‡å»ºæ¥å®ç°
                logger.info("ğŸ—‘ï¸  æ¸…é™¤ç°æœ‰å·¥å…·é›†åˆ...")
                # åˆ›å»ºä¸€ä¸ªæ–°çš„é›†åˆï¼ˆä¼šè‡ªåŠ¨è¦†ç›–ï¼‰
                self.vector_store = Chroma(
                    collection_name="tools",
                    embedding_function=self.embeddings,
                    persist_directory=str(self.persist_directory)
                )
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…é™¤é›†åˆæ—¶å‡ºé”™ï¼ˆå¯èƒ½é›†åˆä¸å­˜åœ¨ï¼‰: {e}")
        
        # å‡†å¤‡æ–‡æ¡£
        documents = []
        metadatas = []
        
        for tool in tools_json:
            # page_content: ç”¨äºæœç´¢çš„æ–‡æœ¬ï¼ˆdescription + name + categoryï¼‰
            page_content = f"""
å·¥å…·åç§°: {tool['name']}
ç±»åˆ«: {tool['category']}
æè¿°: {tool['description']}
è¾“å‡ºç±»å‹: {tool['output_type']}
""".strip()
            
            # metadata: å®Œæ•´çš„å·¥å…· schemaï¼ˆç”¨äºåç»­ä¼ é€’ç»™ LLMï¼‰
            metadata = {
                "name": tool['name'],
                "category": tool['category'],
                "output_type": tool['output_type'],
                "description": tool['description'],
                "args_schema": json.dumps(tool['args_schema'], ensure_ascii=False)  # JSON å­—ç¬¦ä¸²
            }
            
            documents.append(Document(page_content=page_content, metadata=metadata))
            metadatas.append(metadata)
        
        # æ·»åŠ åˆ° ChromaDB
        try:
            # ä½¿ç”¨ add_documents æ–¹æ³•
            ids = [f"tool_{i}" for i in range(len(documents))]
            self.vector_store.add_documents(documents=documents, ids=ids)
            
            # æŒä¹…åŒ–
            self.vector_store.persist()
            
            logger.info(f"âœ… æˆåŠŸåŒæ­¥ {len(documents)} ä¸ªå·¥å…·åˆ° ChromaDB")
            return len(documents)
        
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥å·¥å…·å¤±è´¥: {e}", exc_info=True)
            raise
    
    def retrieve(
        self,
        query: str,
        top_k: int = 5,
        category_filter: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        æ£€ç´¢ç›¸å…³å·¥å…·
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
            top_k: è¿”å›å‰ k ä¸ªæœ€ç›¸å…³çš„å·¥å…·ï¼ˆé»˜è®¤ 5ï¼‰
            category_filter: å¯é€‰çš„ç±»åˆ«è¿‡æ»¤å™¨ï¼ˆå¦‚ "Metabolomics"ï¼‰
        
        Returns:
            å·¥å…· schema åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«å®Œæ•´çš„å·¥å…·ä¿¡æ¯ï¼ˆname, description, args_schema ç­‰ï¼‰
        """
        try:
            # æ„å»ºæœç´¢æŸ¥è¯¢
            search_kwargs = {"k": top_k}
            
            # å¦‚æœæŒ‡å®šäº†ç±»åˆ«è¿‡æ»¤ï¼Œæ·»åŠ åˆ° metadata è¿‡æ»¤ä¸­
            if category_filter:
                # ChromaDB æ”¯æŒ metadata è¿‡æ»¤
                search_kwargs["filter"] = {"category": category_filter}
            
            # æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            results = self.vector_store.similarity_search_with_score(
                query,
                k=top_k,
                **search_kwargs
            )
            
            # è½¬æ¢ä¸ºå·¥å…· schema æ ¼å¼
            tools = []
            for doc, score in results:
                metadata = doc.metadata
                
                # è§£æ args_schemaï¼ˆä» JSON å­—ç¬¦ä¸²ï¼‰
                try:
                    args_schema = json.loads(metadata.get("args_schema", "{}"))
                except Exception:
                    args_schema = {}
                
                tool_schema = {
                    "name": metadata.get("name"),
                    "description": metadata.get("description"),
                    "category": metadata.get("category"),
                    "output_type": metadata.get("output_type"),
                    "args_schema": args_schema,
                    "similarity_score": float(score)  # ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆè¶Šä½è¶Šç›¸ä¼¼ï¼‰
                }
                
                tools.append(tool_schema)
            
            logger.info(f"ğŸ” æ£€ç´¢åˆ° {len(tools)} ä¸ªç›¸å…³å·¥å…· (æŸ¥è¯¢: '{query}')")
            return tools
        
        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
            return []
    
    def get_tool_by_name(self, name: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®å·¥å…·åç§°è·å–å·¥å…· schema
        
        Args:
            name: å·¥å…·åç§°
        
        Returns:
            å·¥å…· schemaï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        try:
            # ä½¿ç”¨ç²¾ç¡®åŒ¹é…æœç´¢
            results = self.vector_store.similarity_search_with_score(
                f"å·¥å…·åç§°: {name}",
                k=1
            )
            
            if results:
                doc, score = results[0]
                metadata = doc.metadata
                
                if metadata.get("name") == name:
                    try:
                        args_schema = json.loads(metadata.get("args_schema", "{}"))
                    except Exception:
                        args_schema = {}
                    
                    return {
                        "name": metadata.get("name"),
                        "description": metadata.get("description"),
                        "category": metadata.get("category"),
                        "output_type": metadata.get("output_type"),
                        "args_schema": args_schema
                    }
            
            return None
        
        except Exception as e:
            logger.error(f"âŒ è·å–å·¥å…·å¤±è´¥: {e}", exc_info=True)
            return None
    
    def list_all_tools(self) -> List[str]:
        """
        åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…·åç§°
        
        Returns:
            å·¥å…·åç§°åˆ—è¡¨
        """
        return registry.list_tools()

