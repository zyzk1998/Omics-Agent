"""
åŠ¨æ€å·¥ä½œæµè§„åˆ’å™¨ - The Brain

ä½¿ç”¨ Tool-RAG æ¶æ„åŠ¨æ€ç”Ÿæˆå¯æ‰§è¡Œçš„å·¥ä½œæµè®¡åˆ’ã€‚
ç»“åˆå·¥å…·æ£€ç´¢å’Œ LLM æ¨ç†ï¼Œç”Ÿæˆç¬¦åˆå‰ç«¯æ ¼å¼çš„å·¥ä½œæµé…ç½®ã€‚
"""
import json
import logging
from typing import Dict, Any, List, Optional
from pathlib import Path

from .tool_retriever import ToolRetriever
from .tool_registry import registry
from .llm_client import LLMClient

logger = logging.getLogger(__name__)


class WorkflowPlanner:
    """
    å·¥ä½œæµè§„åˆ’å™¨
    
    èŒè´£ï¼š
    1. ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æ£€ç´¢ç›¸å…³å·¥å…·
    2. ä½¿ç”¨ LLM ç”Ÿæˆå·¥ä½œæµè®¡åˆ’
    3. éªŒè¯å’Œè½¬æ¢è¾“å‡ºæ ¼å¼
    """
    
    def __init__(
        self,
        tool_retriever: ToolRetriever,
        llm_client: LLMClient
    ):
        """
        åˆå§‹åŒ–å·¥ä½œæµè§„åˆ’å™¨
        
        Args:
            tool_retriever: å·¥å…·æ£€ç´¢å™¨å®ä¾‹
            llm_client: LLM å®¢æˆ·ç«¯å®ä¾‹
        """
        self.tool_retriever = tool_retriever
        self.llm_client = llm_client
    
    async def plan(
        self,
        user_query: str,
        context_files: List[str] = None,
        category_filter: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå·¥ä½œæµè®¡åˆ’
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            context_files: å¯ç”¨çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            category_filter: å¯é€‰çš„ç±»åˆ«è¿‡æ»¤å™¨ï¼ˆå¦‚ "Metabolomics"ï¼‰
        
        Returns:
            å·¥ä½œæµé…ç½®å­—å…¸ï¼Œç¬¦åˆå‰ç«¯æ ¼å¼
        """
        try:
            logger.info(f"ğŸ§  å¼€å§‹è§„åˆ’å·¥ä½œæµ: '{user_query}'")
            
            # Step 1: æ£€ç´¢ç›¸å…³å·¥å…·
            logger.info("ğŸ” Step 1: æ£€ç´¢ç›¸å…³å·¥å…·...")
            retrieved_tools = self.tool_retriever.retrieve(
                query=user_query,
                top_k=10,
                category_filter=category_filter
            )
            
            if not retrieved_tools:
                logger.warning("âš ï¸ æœªæ£€ç´¢åˆ°ç›¸å…³å·¥å…·")
                return {
                    "type": "error",
                    "error": "æœªæ‰¾åˆ°ç›¸å…³å·¥å…·ï¼Œè¯·æ£€æŸ¥æŸ¥è¯¢æˆ–å·¥å…·æ³¨å†Œ",
                    "message": "æ— æ³•ç”Ÿæˆå·¥ä½œæµè®¡åˆ’"
                }
            
            logger.info(f"âœ… æ£€ç´¢åˆ° {len(retrieved_tools)} ä¸ªç›¸å…³å·¥å…·")
            for tool in retrieved_tools[:3]:  # åªæ‰“å°å‰3ä¸ª
                logger.info(f"   - {tool['name']} (ç›¸ä¼¼åº¦: {tool['similarity_score']:.4f})")
            
            # Step 2: æ„å»º LLM Prompt
            logger.info("ğŸ“ Step 2: æ„å»º LLM Prompt...")
            system_prompt = self._build_system_prompt()
            user_prompt = self._build_user_prompt(
                user_query=user_query,
                retrieved_tools=retrieved_tools,
                context_files=context_files or []
            )
            
            # Step 3: è°ƒç”¨ LLM ç”Ÿæˆè®¡åˆ’
            logger.info("ğŸ¤– Step 3: è°ƒç”¨ LLM ç”Ÿæˆè®¡åˆ’...")
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            # å°è¯•ä½¿ç”¨ JSON modeï¼ˆå¦‚æœæ”¯æŒï¼‰
            response = await self.llm_client.achat(
                messages=messages,
                temperature=0.1,  # ä½æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
                max_tokens=2048
            )
            
            # Step 4: è§£æ LLM å“åº”
            logger.info("ğŸ”§ Step 4: è§£æ LLM å“åº”...")
            workflow_plan = self._parse_llm_response(response)
            
            # Step 5: éªŒè¯å·¥å…·å­˜åœ¨æ€§
            logger.info("âœ… Step 5: éªŒè¯å·¥å…·...")
            validated_plan = self._validate_and_adapt(workflow_plan, context_files or [])
            
            logger.info(f"âœ… å·¥ä½œæµè§„åˆ’å®Œæˆ: {len(validated_plan.get('steps', []))} ä¸ªæ­¥éª¤")
            return validated_plan
        
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµè§„åˆ’å¤±è´¥: {e}", exc_info=True)
            return {
                "type": "error",
                "error": str(e),
                "message": f"å·¥ä½œæµè§„åˆ’å¤±è´¥: {str(e)}"
            }
    
    def _build_system_prompt(self) -> str:
        """
        æ„å»ºç³»ç»Ÿæç¤ºè¯
        
        Returns:
            ç³»ç»Ÿæç¤ºè¯æ–‡æœ¬
        """
        return """You are a Senior Bioinformatics Workflow Architect.

Your task is to generate executable workflow plans based on user queries and available tools.

**CRITICAL RULES:**
1. Output MUST be a valid JSON object (no markdown code blocks, no extra text).
2. Structure: {"workflow_name": "...", "steps": [{"id": "step1", "tool_name": "...", "params": {...}, "dependency": "..."}]}
3. **Data Flow**: The output of Step N must match the input of Step N+1 (e.g., file paths).
4. If a parameter is a file path, use placeholders like `<step1_output>` or match the uploaded filename.
5. Use tool names EXACTLY as provided in the tool schemas.
6. Only include parameters that exist in the tool's args_schema.
7. For file paths, prefer using the actual uploaded filename if available.

**Step Structure:**
- "id": Unique step identifier (e.g., "step1", "step2")
- "tool_name": The exact tool name from the retrieved tools
- "params": Dictionary of parameters matching the tool's args_schema
- "dependency": Optional, the step ID this step depends on (e.g., "step1")

**Example Output:**
{
  "workflow_name": "PCA Analysis Pipeline",
  "steps": [
    {
      "id": "step1",
      "tool_name": "metabolomics_pca",
      "params": {
        "file_path": "cow_diet.csv",
        "n_components": 2,
        "scale": true
      },
      "dependency": null
    }
  ]
}

Generate ONLY the JSON object, no additional text."""
    
    def _build_user_prompt(
        self,
        user_query: str,
        retrieved_tools: List[Dict[str, Any]],
        context_files: List[str]
    ) -> str:
        """
        æ„å»ºç”¨æˆ·æç¤ºè¯
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            retrieved_tools: æ£€ç´¢åˆ°çš„å·¥å…·åˆ—è¡¨
            context_files: å¯ç”¨æ–‡ä»¶åˆ—è¡¨
        
        Returns:
            ç”¨æˆ·æç¤ºè¯æ–‡æœ¬
        """
        # æ ¼å¼åŒ–å·¥å…·ä¿¡æ¯
        tools_text = []
        for i, tool in enumerate(retrieved_tools, 1):
            tool_info = f"""
Tool {i}: {tool['name']}
  Description: {tool['description']}
  Category: {tool['category']}
  Output Type: {tool['output_type']}
  Parameters Schema:
{json.dumps(tool['args_schema'], indent=2, ensure_ascii=False)}
"""
            tools_text.append(tool_info)
        
        # æ ¼å¼åŒ–æ–‡ä»¶ä¿¡æ¯
        files_text = ""
        if context_files:
            files_text = "\n**Available Files:**\n"
            for file_path in context_files:
                filename = Path(file_path).name
                files_text += f"- {filename} (path: {file_path})\n"
        else:
            files_text = "\n**Available Files:** None (user may upload files later)\n"
        
        prompt = f"""**User Query:**
{user_query}

**Retrieved Tools:**
{''.join(tools_text)}

{files_text}

**Task:**
Generate a workflow plan that fulfills the user's request. Use the retrieved tools and available files.

**Instructions:**
1. Select the most relevant tools from the retrieved list.
2. Arrange them in a logical order (data flow: output of step N â†’ input of step N+1).
3. Fill in parameters using:
   - Actual file names from "Available Files" if they match the query
   - Default values from the tool's args_schema
   - Placeholders like `<step1_output>` if a step depends on another step's output
4. Keep the workflow concise - only include necessary steps.

**Output Format:**
Return ONLY a valid JSON object with this structure:
{{
  "workflow_name": "Descriptive workflow name",
  "steps": [
    {{
      "id": "step1",
      "tool_name": "exact_tool_name",
      "params": {{"param1": "value1", "param2": "value2"}},
      "dependency": null
    }},
    {{
      "id": "step2",
      "tool_name": "another_tool_name",
      "params": {{"file_path": "<step1_output>", "other_param": "value"}},
      "dependency": "step1"
    }}
  ]
}}

Remember: Output ONLY the JSON object, no markdown, no code blocks, no explanations."""
        
        return prompt
    
    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """
        è§£æ LLM å“åº”
        
        Args:
            response: LLM è¿”å›çš„æ–‡æœ¬
        
        Returns:
            è§£æåçš„å·¥ä½œæµè®¡åˆ’å­—å…¸
        """
        # å°è¯•æå– JSONï¼ˆå¯èƒ½è¢« markdown ä»£ç å—åŒ…è£¹ï¼‰
        response = response.strip()
        
        # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
        if response.startswith("```json"):
            response = response[7:]
        elif response.startswith("```"):
            response = response[3:]
        
        if response.endswith("```"):
            response = response[:-3]
        
        response = response.strip()
        
        try:
            plan = json.loads(response)
            return plan
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON è§£æå¤±è´¥: {e}")
            logger.error(f"å“åº”å†…å®¹: {response[:500]}")
            
            # å°è¯•æå– JSON å¯¹è±¡ï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰
            import re
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', response, re.DOTALL)
            if json_match:
                try:
                    plan = json.loads(json_match.group())
                    logger.info("âœ… ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æˆåŠŸæå– JSON")
                    return plan
                except:
                    pass
            
            raise ValueError(f"æ— æ³•è§£æ LLM å“åº”ä¸º JSON: {e}")
    
    def _validate_and_adapt(
        self,
        workflow_plan: Dict[str, Any],
        context_files: List[str]
    ) -> Dict[str, Any]:
        """
        éªŒè¯å·¥ä½œæµè®¡åˆ’å¹¶é€‚é…ä¸ºå‰ç«¯æ ¼å¼
        
        Args:
            workflow_plan: LLM ç”Ÿæˆçš„åŸå§‹è®¡åˆ’
            context_files: å¯ç”¨æ–‡ä»¶åˆ—è¡¨
        
        Returns:
            éªŒè¯å’Œé€‚é…åçš„å·¥ä½œæµé…ç½®ï¼ˆç¬¦åˆå‰ç«¯æ ¼å¼ï¼‰
        """
        # éªŒè¯åŸºæœ¬ç»“æ„
        if "workflow_name" not in workflow_plan:
            workflow_plan["workflow_name"] = "Generated Workflow"
        
        if "steps" not in workflow_plan or not isinstance(workflow_plan["steps"], list):
            raise ValueError("å·¥ä½œæµè®¡åˆ’å¿…é¡»åŒ…å« 'steps' æ•°ç»„")
        
        # é€‚é…æ­¥éª¤æ ¼å¼
        adapted_steps = []
        for i, step in enumerate(workflow_plan["steps"], 1):
            # éªŒè¯å·¥å…·å­˜åœ¨æ€§
            tool_name = step.get("tool_name") or step.get("tool_id")
            if not tool_name:
                logger.warning(f"âš ï¸ æ­¥éª¤ {i} ç¼ºå°‘ tool_nameï¼Œè·³è¿‡")
                continue
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨æ³¨å†Œè¡¨ä¸­
            tool_metadata = registry.get_metadata(tool_name)
            if not tool_metadata:
                logger.warning(f"âš ï¸ å·¥å…· '{tool_name}' ä¸åœ¨æ³¨å†Œè¡¨ä¸­ï¼Œè·³è¿‡")
                continue
            
            # è·å–å·¥å…·æè¿°
            tool_desc = tool_metadata.description
            
            # å¤„ç†æ–‡ä»¶è·¯å¾„å‚æ•°
            params = step.get("params", {})
            adapted_params = {}
            
            for param_name, param_value in params.items():
                # å¦‚æœå‚æ•°å€¼æ˜¯æ–‡ä»¶è·¯å¾„å ä½ç¬¦ï¼Œå°è¯•åŒ¹é…å®é™…æ–‡ä»¶
                if isinstance(param_value, str) and param_value.startswith("<") and param_value.endswith(">"):
                    # å ä½ç¬¦ï¼Œä¿æŒåŸæ ·ï¼ˆæ‰§è¡Œæ—¶ä¼šå¤„ç†ï¼‰
                    adapted_params[param_name] = param_value
                elif param_name == "file_path" and context_files:
                    # å¦‚æœæ˜¯ file_path å‚æ•°ï¼Œå°è¯•åŒ¹é…ä¸Šä¼ çš„æ–‡ä»¶
                    if isinstance(param_value, str):
                        # å°è¯•åŒ¹é…æ–‡ä»¶å
                        matched_file = None
                        for file_path in context_files:
                            if param_value.lower() in Path(file_path).name.lower():
                                matched_file = file_path
                                break
                        
                        if matched_file:
                            adapted_params[param_name] = matched_file
                        else:
                            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºé»˜è®¤å€¼
                            adapted_params[param_name] = context_files[0]
                    else:
                        adapted_params[param_name] = param_value
                else:
                    adapted_params[param_name] = param_value
            
            # æ„å»ºé€‚é…åçš„æ­¥éª¤ï¼ˆç¬¦åˆå‰ç«¯æ ¼å¼ï¼‰
            adapted_step = {
                "step_id": step.get("id", f"step{i}"),
                "tool_id": tool_name,  # å‰ç«¯ä½¿ç”¨ tool_id
                "name": self._get_step_display_name(tool_name, tool_desc),
                "step_name": self._get_step_display_name(tool_name, tool_desc),  # å…¼å®¹å­—æ®µ
                "desc": tool_desc[:100] if tool_desc else "",  # æè¿°æˆªæ–­
                "params": adapted_params
            }
            
            adapted_steps.append(adapted_step)
        
        # æ„å»ºæœ€ç»ˆçš„å·¥ä½œæµé…ç½®ï¼ˆç¬¦åˆå‰ç«¯æ ¼å¼ï¼‰
        workflow_config = {
            "type": "workflow_config",
            "workflow_data": {
                "workflow_name": workflow_plan["workflow_name"],
                "steps": adapted_steps
            },
            "file_paths": context_files
        }
        
        return workflow_config
    
    def _get_step_display_name(self, tool_name: str, tool_desc: str) -> str:
        """
        è·å–æ­¥éª¤çš„æ˜¾ç¤ºåç§°
        
        Args:
            tool_name: å·¥å…·åç§°
            tool_desc: å·¥å…·æè¿°
        
        Returns:
            æ˜¾ç¤ºåç§°
        """
        # ç®€å•çš„åç§°æ˜ å°„
        name_mapping = {
            "metabolomics_pca": "ä¸»æˆåˆ†åˆ†æ (PCA)",
            "metabolomics_differential_analysis": "å·®å¼‚åˆ†æ",
            "metabolomics_preprocess": "æ•°æ®é¢„å¤„ç†",
            "file_inspect": "æ–‡ä»¶æ£€æŸ¥"
        }
        
        if tool_name in name_mapping:
            return name_mapping[tool_name]
        
        # ä»æè¿°ä¸­æå–ï¼ˆç®€å•å¯å‘å¼ï¼‰
        if "PCA" in tool_desc or "principal component" in tool_desc.lower():
            return "ä¸»æˆåˆ†åˆ†æ"
        elif "differential" in tool_desc.lower():
            return "å·®å¼‚åˆ†æ"
        elif "preprocess" in tool_desc.lower() or "é¢„å¤„ç†" in tool_desc:
            return "æ•°æ®é¢„å¤„ç†"
        elif "inspect" in tool_desc.lower() or "æ£€æŸ¥" in tool_desc:
            return "æ–‡ä»¶æ£€æŸ¥"
        
        # é»˜è®¤ï¼šä½¿ç”¨å·¥å…·åç§°ï¼ˆç¾åŒ–ï¼‰
        return tool_name.replace("_", " ").title()

