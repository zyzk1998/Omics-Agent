"""
Scanpy åˆ†æå·¥å…·
å‚è€ƒæ—§ç‰ˆæœ¬å®ç°ï¼Œç›´æ¥æ‰§è¡Œå•ç»†èƒè½¬å½•ç»„åˆ†ææµç¨‹
æ”¯æŒåæ­¥æ ‡å‡†æµç¨‹
"""
# ğŸ”§ ä¿®å¤ï¼šåœ¨å®¹å™¨ç¯å¢ƒä¸­è®¾ç½® Numba ç¼“å­˜ç›®å½•ï¼ˆé¿å…æƒé™é—®é¢˜ï¼‰
import os
# å¦‚æœ NUMBA_CACHE_DIR æœªè®¾ç½®ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•
if 'NUMBA_CACHE_DIR' not in os.environ:
    import tempfile
    cache_dir = tempfile.mkdtemp(prefix='numba_cache_')
    os.environ['NUMBA_CACHE_DIR'] = cache_dir
    os.makedirs(cache_dir, exist_ok=True)

# åœ¨å¯¼å…¥ scanpy ä¹‹å‰é…ç½® Numbaï¼ˆé¿å…ç¼“å­˜é”™è¯¯ï¼‰
try:
    import numba
    # è®¾ç½®ç¼“å­˜ç›®å½•
    if 'NUMBA_CACHE_DIR' in os.environ:
        numba.config.CACHE_DIR = os.environ['NUMBA_CACHE_DIR']
    # å¯ç”¨ç¼“å­˜è°ƒè¯•ï¼ˆå¸®åŠ©è¯Šæ–­é—®é¢˜ï¼‰
    numba.config.DEBUG_CACHE = 1
except (ImportError, AttributeError):
    # å¦‚æœ numba æœªå®‰è£…æˆ–æ²¡æœ‰è¯¥é…ç½®ï¼Œå¿½ç•¥
    pass

import scanpy as sc
import os
import matplotlib
# è®¾ç½®æ— å¤´æ¨¡å¼ï¼Œé˜²æ­¢æœåŠ¡å™¨æŠ¥é”™
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import pandas as pd
import time
import warnings
from typing import Dict, Any, List, Optional
from pathlib import Path

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

# å…¨å±€ç»˜å›¾è®¾ç½®
sc.settings.verbosity = 3
sc.settings.set_figure_params(
    dpi=300,
    facecolor='white',
    frameon=True,
    vector_friendly=True
)


class ScanpyTool:
    """
    Scanpy åˆ†æå·¥å…·
    
    æ ¸å¿ƒåŠŸèƒ½ï¼šç›´æ¥æ‰§è¡Œå•ç»†èƒè½¬å½•ç»„åˆ†ææµç¨‹
    å‚è€ƒæ—§ç‰ˆæœ¬ï¼š/home/ubuntu/GIBH-AGENT/services/api/src/scrna_analysis.py
    """
    
    def __init__(self, config: Dict[str, Any] = None, cellranger_tool=None):
        """
        åˆå§‹åŒ– Scanpy å·¥å…·
        
        Args:
            config: é…ç½®å­—å…¸
            cellranger_tool: CellRangerTool å®ä¾‹ï¼ˆå¯é€‰ï¼Œç”¨äºè¿è¡Œ Cell Rangerï¼‰
        """
        self.config = config or {}
        # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œé¿å…æƒé™é—®é¢˜
        default_output = os.path.join(os.getcwd(), "results")
        self.output_dir = self.config.get("output_dir", default_output)
        try:
            os.makedirs(self.output_dir, exist_ok=True)
        except PermissionError:
            # å¦‚æœæƒé™ä¸è¶³ï¼Œä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„ results
            self.output_dir = os.path.join(os.getcwd(), "results")
            os.makedirs(self.output_dir, exist_ok=True)
        
        # Cell Ranger å·¥å…·ï¼ˆå¯é€‰ï¼‰
        self.cellranger_tool = cellranger_tool
        
        # å·¥å…·æ˜ å°„è¡¨ï¼šå°† tool_id æ˜ å°„åˆ°å…·ä½“çš„å¤„ç†å‡½æ•°
        self.tool_map = {
            "inspect_file": self.inspect_file,  # æ•°æ®æ£€æŸ¥å·¥å…·
            "run_cellranger": self.run_cellranger,  # Cell Ranger è®¡æ•°
            "convert_cellranger_to_h5ad": self.convert_cellranger_to_h5ad,  # è½¬æ¢ Cell Ranger è¾“å‡º
            "local_qc": self.step_qc,
            "local_normalize": self.step_normalize,
            "local_hvg": self.step_hvg,
            "local_scale": self.step_scale,
            "local_pca": self.step_pca,
            "local_neighbors": self.step_neighbors,
            "local_cluster": self.step_cluster,
            "local_umap": self.step_umap,
            "local_tsne": self.step_tsne,
            "local_markers": self.step_markers,
            "local_annotate": self.step_annotate
        }
    
    def _save_plot(self, name_prefix: str) -> str:
        """ä¿å­˜å›¾ç‰‡å¹¶è¿”å›æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äº results ç›®å½•ï¼‰"""
        timestamp = int(time.time())
        filename = f"{name_prefix}_{timestamp}.png"
        save_path = os.path.join(self.output_dir, filename)
        plt.savefig(save_path, bbox_inches='tight', dpi=300)
        plt.close()
        
        # è¿”å›ç›¸å¯¹äº results ç›®å½•çš„è·¯å¾„
        # å¦‚æœ output_dir æ˜¯ results/run_xxxï¼Œè¿”å› run_xxx/filename
        if "results" in self.output_dir:
            # æå– run_xxx éƒ¨åˆ†
            parts = self.output_dir.split(os.sep)
            if "results" in parts:
                results_idx = parts.index("results")
                if results_idx + 1 < len(parts):
                    run_dir = parts[results_idx + 1]
                    return f"{run_dir}/{filename}".replace("\\", "/")
        
        # å¦‚æœæ— æ³•æå–ï¼Œè¿”å›å®Œæ•´ç›¸å¯¹è·¯å¾„
        if os.path.isabs(save_path):
            # å°è¯•æ‰¾åˆ° results ç›®å½•
            current = save_path
            while current != os.path.dirname(current):
                if os.path.basename(current) == "results":
                    rel_path = os.path.relpath(save_path, current)
                    return rel_path.replace("\\", "/")
                current = os.path.dirname(current)
        
        # æœ€åè¿”å›æ–‡ä»¶å
        return filename
    
    # ================= ğŸ“¦ æ•°æ®åŠ è½½ =================
    def load_data(self, data_input: str):
        """åŠ è½½å•ç»†èƒæ•°æ®"""
        print(f"ğŸ“‚ Loading data from: {data_input}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ FASTQ ç›®å½•ï¼ˆä¸åº”è¯¥ç›´æ¥åŠ è½½ï¼‰
        if os.path.isdir(data_input):
            fastq_files = [f for f in os.listdir(data_input) if f.endswith(('.fastq', '.fq', '.fastq.gz', '.fq.gz'))]
            if fastq_files:
                raise ValueError(
                    f"æ£€æµ‹åˆ° FASTQ ç›®å½•: {data_input}ã€‚"
                    f"FASTQ æ–‡ä»¶éœ€è¦å…ˆé€šè¿‡ Cell Ranger å¤„ç†ï¼Œä¸èƒ½ç›´æ¥åŠ è½½ã€‚"
                    f"è¯·å…ˆè¿è¡Œ Cell Ranger countï¼Œç„¶åè½¬æ¢è¾“å‡ºä¸º .h5ad æ ¼å¼ã€‚"
                )
        
        if os.path.isdir(data_input):
            try:
                adata = sc.read_10x_mtx(data_input, var_names='gene_symbols', cache=False)
            except FileNotFoundError:
                print("âš ï¸ read_10x_mtx failed, trying manual mtx load...")
                # æ‰‹åŠ¨åŠ è½½é€»è¾‘
                mtx_path = os.path.join(data_input, "matrix.mtx")
                if not os.path.exists(mtx_path):
                    mtx_path = os.path.join(data_input, "matrix.mtx.gz")
                if not os.path.exists(mtx_path):
                    raise FileNotFoundError(
                        f"æ— æ³•åœ¨ç›®å½• {data_input} ä¸­æ‰¾åˆ° matrix.mtx æ–‡ä»¶ã€‚"
                        f"è¿™å¯èƒ½æ˜¯ FASTQ ç›®å½•ï¼Œéœ€è¦å…ˆè¿è¡Œ Cell Rangerã€‚"
                    )
                adata = sc.read_mtx(mtx_path).T
                
                genes_path = os.path.join(data_input, "features.tsv")
                if not os.path.exists(genes_path):
                    genes_path = os.path.join(data_input, "genes.tsv")
                if not os.path.exists(genes_path):
                    raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ°åŸºå› æ–‡ä»¶: {genes_path}")
                genes = pd.read_csv(genes_path, header=None, sep='\t')
                adata.var_names = genes[1].values
                adata.var['gene_ids'] = genes[0].values
                
                barcodes_path = os.path.join(data_input, "barcodes.tsv")
                if not os.path.exists(barcodes_path):
                    raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° barcodes æ–‡ä»¶: {barcodes_path}")
                barcodes = pd.read_csv(barcodes_path, header=None, sep='\t')
                adata.obs_names = barcodes[0].values
            
            adata.var_names_make_unique()
        elif data_input.endswith('.h5ad'):
            adata = sc.read_h5ad(data_input)
        else:
            adata = sc.read(data_input)
        return adata
    
    # ================= ğŸ” æ•°æ®æ£€æŸ¥å·¥å…· =================
    
    def inspect_file(self, file_path: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ–‡ä»¶å†…å®¹ï¼Œè¿”å›æ•°æ®æ‘˜è¦
        
        è¿™æ˜¯ä¸€ä¸ªå¼ºåˆ¶æ€§çš„æ£€æŸ¥æ­¥éª¤ï¼Œå¿…é¡»åœ¨æ‰§è¡Œä»»ä½•åˆ†æä¹‹å‰è°ƒç”¨ã€‚
        
        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆ.h5ad æ–‡ä»¶æˆ– 10x ç›®å½•ï¼‰
        
        Returns:
            åŒ…å«æ•°æ®æ‘˜è¦çš„å­—å…¸ï¼š
            - n_obs: ç»†èƒæ•°é‡
            - n_vars: åŸºå› æ•°é‡
            - obs_keys: .obs ä¸­çš„åˆ—ååˆ—è¡¨
            - var_keys: .var ä¸­çš„åˆ—ååˆ—è¡¨
            - is_normalized: æ˜¯å¦å·²æ ‡å‡†åŒ–ï¼ˆåŸºäºæœ€å¤§å€¼çŒœæµ‹ï¼‰
            - max_value: æ•°æ®æœ€å¤§å€¼
            - min_value: æ•°æ®æœ€å°å€¼
            - preview: .obs çš„å‰5è¡Œé¢„è§ˆ
            - has_clusters: æ˜¯å¦å·²æœ‰èšç±»ç»“æœ
            - has_umap: æ˜¯å¦å·²æœ‰ UMAP åæ ‡
        """
        try:
            # é«˜æ•ˆåŠ è½½ï¼šä½¿ç”¨ backed='r' æ¨¡å¼åªè¯»å–å…ƒæ•°æ®ï¼Œä¸åŠ è½½å…¨éƒ¨æ•°æ®åˆ°å†…å­˜
            if file_path.endswith('.h5ad'):
                try:
                    # å°è¯•ä½¿ç”¨ backed æ¨¡å¼ï¼ˆåªè¯»æ¨¡å¼ï¼Œä¸åŠ è½½å…¨éƒ¨æ•°æ®ï¼‰
                    adata = sc.read_h5ad(file_path, backed='r')
                except:
                    # å¦‚æœ backed æ¨¡å¼å¤±è´¥ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼
                    adata = sc.read_h5ad(file_path)
            elif os.path.isdir(file_path):
                # 10x æ ¼å¼éœ€è¦å®Œæ•´åŠ è½½
                adata = self.load_data(file_path)
            else:
                adata = sc.read(file_path)
            
            # æå–åŸºæœ¬ä¿¡æ¯
            n_obs = adata.n_obs
            n_vars = adata.n_vars
            obs_keys = list(adata.obs.columns) if hasattr(adata.obs, 'columns') else []
            var_keys = list(adata.var.columns) if hasattr(adata.var, 'columns') else []
            
            # æ£€æŸ¥æ•°æ®å€¼èŒƒå›´ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦å·²æ ‡å‡†åŒ–ï¼‰
            # åªæ£€æŸ¥ä¸€ä¸ªå°æ ·æœ¬ä»¥æé«˜æ•ˆç‡
            import numpy as np
            sample_size = min(1000, adata.n_obs * adata.n_vars)
            if sample_size > 0:
                # éšæœºé‡‡æ ·æ£€æŸ¥
                if hasattr(adata.X, 'toarray'):
                    # ç¨€ç–çŸ©é˜µ
                    sample_data = adata.X[:min(100, adata.n_obs), :min(100, adata.n_vars)]
                    if hasattr(sample_data, 'toarray'):
                        sample_data = sample_data.toarray()
                    else:
                        sample_data = np.array(sample_data)
                else:
                    sample_data = np.array(adata.X[:min(100, adata.n_obs), :min(100, adata.n_vars)])
                
                max_value = float(np.nanmax(sample_data)) if sample_data.size > 0 else 0.0
                min_value = float(np.nanmin(sample_data)) if sample_data.size > 0 else 0.0
            else:
                max_value = 0.0
                min_value = 0.0
            
            # åˆ¤æ–­æ˜¯å¦å·²æ ‡å‡†åŒ–
            # ç»éªŒè§„åˆ™ï¼šå¦‚æœæœ€å¤§å€¼ < 20ï¼Œå¯èƒ½æ˜¯ log-transformedï¼›å¦‚æœæœ€å¤§å€¼å¾ˆå¤§ï¼ˆ>1000ï¼‰ï¼Œå¯èƒ½æ˜¯åŸå§‹ counts
            is_normalized = max_value < 20 if max_value > 0 else False
            
            # é¢„è§ˆ .obs çš„å‰5è¡Œ
            preview = None
            if n_obs > 0:
                try:
                    preview_df = adata.obs.head(5)
                    preview = preview_df.to_dict('records') if hasattr(preview_df, 'to_dict') else str(preview_df)
                except:
                    preview = "æ— æ³•ç”Ÿæˆé¢„è§ˆ"
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰åˆ†æç»“æœ
            has_clusters = 'leiden' in adata.obs.columns or 'louvain' in adata.obs.columns
            has_umap = 'X_umap' in adata.obsm_keys() if hasattr(adata, 'obsm_keys') else False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ QC æŒ‡æ ‡
            has_qc_metrics = any(key in obs_keys for key in ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'])
            
            result = {
                "n_obs": n_obs,
                "n_vars": n_vars,
                "obs_keys": obs_keys,
                "var_keys": var_keys,
                "is_normalized": is_normalized,
                "max_value": max_value,
                "min_value": min_value,
                "preview": preview,
                "has_clusters": has_clusters,
                "has_umap": has_umap,
                "has_qc_metrics": has_qc_metrics,
                "file_path": file_path
            }
            
            return result
            
        except Exception as e:
            return {
                "error": str(e),
                "file_path": file_path
            }
    
    # ================= ğŸ”§ åŸå­åŒ–å·¥å…·å‡½æ•° =================
    
    def step_qc(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤1: è´¨é‡æ§åˆ¶"""
        adata.var['mt'] = adata.var_names.str.startswith(('MT-', 'mt-'))
        sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], inplace=True)
        
        # ç»˜å›¾
        sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], 
                     jitter=0.4, multi_panel=True, show=False)
        plot_path = self._save_plot("qc_violin")
        
        # è¿‡æ»¤
        min_genes = int(params.get('min_genes', 200))
        max_mt = float(params.get('max_mt', 20))
        sc.pp.filter_cells(adata, min_genes=min_genes)
        adata = adata[adata.obs.pct_counts_mt < max_mt, :]
        sc.pp.filter_genes(adata, min_cells=3)
        
        return {
            "summary": f"è¿‡æ»¤åå‰©ä½™ {adata.n_obs} ç»†èƒ",
            "plot": plot_path
        }
    
    def step_normalize(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤2: æ ‡å‡†åŒ–"""
        sc.pp.normalize_total(adata, target_sum=1e4)
        sc.pp.log1p(adata)
        return {"summary": "LogNormalize å®Œæˆ"}
    
    def step_hvg(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤3: å¯»æ‰¾é«˜å˜åŸºå› """
        n_top_genes = int(params.get('n_top_genes', 2000))
        sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)
        sc.pl.highly_variable_genes(adata, show=False)
        plot_path = self._save_plot("hvg")
        # è¿‡æ»¤é«˜å˜åŸºå› 
        adata._inplace_subset_var(adata.var['highly_variable'])
        return {"summary": f"ç­›é€‰ {n_top_genes} é«˜å˜åŸºå› ", "plot": plot_path}
    
    def step_scale(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤4: æ•°æ®ç¼©æ”¾"""
        sc.pp.scale(adata, max_value=10)
        return {"summary": "æ•°æ®ç¼©æ”¾å®Œæˆ"}
    
    def step_pca(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤5: PCA é™ç»´"""
        sc.tl.pca(adata, svd_solver='arpack')
        sc.pl.pca_variance_ratio(adata, log=True, show=False)
        plot_path = self._save_plot("pca_variance")
        return {"summary": "PCA é™ç»´å®Œæˆ", "plot": plot_path}
    
    def step_neighbors(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤6: è®¡ç®—é‚»å±…"""
        n_neighbors = int(params.get('n_neighbors', 10))
        n_pcs = int(params.get('n_pcs', 40))
        sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=n_pcs)
        return {"summary": "é‚»æ¥å›¾æ„å»ºå®Œæˆ"}
    
    def step_cluster(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤7: Leiden èšç±»"""
        resolution = float(params.get('resolution', 0.5))
        sc.tl.leiden(adata, resolution=resolution)
        n_clusters = len(adata.obs['leiden'].unique())
        return {"summary": f"Leiden èšç±» (Res={resolution}): {n_clusters} ç°‡"}
    
    def step_umap(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤8: UMAP å¯è§†åŒ–"""
        sc.tl.umap(adata)
        fig, ax = plt.subplots(figsize=(8, 6))
        sc.pl.umap(adata, color=['leiden'], ax=ax, show=False, 
                   title="UMAP", legend_loc='on data', frameon=False)
        plot_path = self._save_plot("final_umap")
        return {"summary": "UMAP ç”Ÿæˆå®Œæ¯•", "plot": plot_path}
    
    def step_tsne(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤9: t-SNE å¯è§†åŒ–"""
        if adata.n_obs < 5000:
            sc.tl.tsne(adata)
            fig, ax = plt.subplots(figsize=(8, 6))
            sc.pl.tsne(adata, color=['leiden'], ax=ax, show=False, 
                       title="t-SNE", frameon=False)
            plot_path = self._save_plot("final_tsne")
            return {"summary": "t-SNE ç”Ÿæˆå®Œæ¯•", "plot": plot_path}
        else:
            return {"summary": "ç»†èƒæ•°è¿‡å¤šï¼Œè·³è¿‡ t-SNE"}
    
    def step_markers(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤10: å¯»æ‰¾ Marker åŸºå› """
        method = params.get('method', 't-test')
        sc.tl.rank_genes_groups(adata, 'leiden', method=method)
        result = adata.uns['rank_genes_groups']
        groups = result['names'].dtype.names
        
        # æ„å»º Marker åŸºå› è¡¨æ ¼
        markers_data = {}
        for group in groups:
            markers_data[f"{group}_names"] = result['names'][group][:5]
            markers_data[f"{group}_pvals"] = result['pvals'][group][:5]
        
        markers_df = pd.DataFrame(markers_data)
        return {
            "summary": "Marker åŸºå› é‰´å®šå®Œæˆ",
            "details": markers_df.to_html(classes="table table-sm", index=False)
        }
    
    def step_annotate(self, adata, params: Dict[str, Any]):
        """æ­¥éª¤11: ç»†èƒç±»å‹æ³¨é‡Š (CellTypist)"""
        try:
            import celltypist
            from celltypist import models
        except ImportError:
            return {
                "summary": "é”™è¯¯: æœªå®‰è£… celltypist",
                "error": "è¯·è¿è¡Œ: pip install celltypist"
            }
        
        # æ¨¡å‹ç¼“å­˜ç›®å½•
        cache_dir = Path(self.config.get("cache_dir", "test_data/cache"))
        cache_dir.mkdir(parents=True, exist_ok=True)
        model_name = "Immune_All_Low.pkl"
        model_path = cache_dir / model_name
        
        # ä¸‹è½½æˆ–åŠ è½½æ¨¡å‹
        try:
            if not model_path.exists():
                print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ CellTypist æ¨¡å‹: {model_name}")
                models.download_models(model=model_name, folder=str(cache_dir))
            
            # åŠ è½½æ¨¡å‹
            model = celltypist.models.Model.load(str(model_path))
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
            
            # è¿è¡Œæ³¨é‡Š
            print("ğŸ”¬ æ­£åœ¨è¿è¡Œ CellTypist æ³¨é‡Š...")
            predictions = celltypist.annotate(
                adata,
                model=model,
                majority_voting=True,
                mode='probabilities'
            )
            
            # ä¿å­˜é¢„æµ‹ç»“æœ
            adata.obs['predicted_labels'] = predictions.predicted_labels['majority_voting']
            if 'predicted_labels' in predictions.predicted_labels.columns:
                adata.obs['predicted_labels_prob'] = predictions.predicted_labels['predicted_labels']
            
            # ç»Ÿè®¡æ³¨é‡Šç»“æœ
            label_counts = adata.obs['predicted_labels'].value_counts()
            n_cell_types = len(label_counts)
            
            # ç”Ÿæˆ UMAP å›¾ï¼ˆæŒ‰é¢„æµ‹æ ‡ç­¾ç€è‰²ï¼‰
            if 'X_umap' in adata.obsm.keys():
                fig, ax = plt.subplots(figsize=(10, 8))
                sc.pl.umap(
                    adata,
                    color='predicted_labels',
                    ax=ax,
                    show=False,
                    title="UMAP: Cell Type Annotation",
                    legend_loc='right margin',
                    frameon=False,
                    legend_fontsize=8
                )
                plot_path = self._save_plot("umap_annotated")
                
                return {
                    "summary": f"ç»†èƒç±»å‹æ³¨é‡Šå®Œæˆ: è¯†åˆ«åˆ° {n_cell_types} ç§ç»†èƒç±»å‹",
                    "plot": plot_path,
                    "cell_types": label_counts.to_dict(),
                    "n_cell_types": n_cell_types
                }
            else:
                return {
                    "summary": f"ç»†èƒç±»å‹æ³¨é‡Šå®Œæˆ: è¯†åˆ«åˆ° {n_cell_types} ç§ç»†èƒç±»å‹ï¼ˆè¯·å…ˆè¿è¡Œ UMAPï¼‰",
                    "cell_types": label_counts.to_dict(),
                    "n_cell_types": n_cell_types
                }
                
        except Exception as e:
            import traceback
            error_msg = f"CellTypist æ³¨é‡Šå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            print(traceback.format_exc())
            return {
                "summary": error_msg,
                "error": str(e)
            }
    
    # ================= ğŸ”¬ Cell Ranger å·¥å…· =================
    
    def run_cellranger(
        self,
        fastq_dir: str,
        sample_id: str,
        output_dir: str,
        reference: Optional[str] = None,
        sample: Optional[str] = None,
        localcores: int = 8,
        localmem: int = 32,
        create_bam: bool = False,
        expect_cells: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        è¿è¡Œ Cell Ranger count
        
        Args:
            fastq_dir: FASTQ æ–‡ä»¶ç›®å½•è·¯å¾„
            sample_id: æ ·æœ¬ ID
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            reference: å‚è€ƒåŸºå› ç»„è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            sample: æ ·æœ¬åç§°ï¼ˆå¯é€‰ï¼‰
            localcores: CPU æ ¸å¿ƒæ•°
            localmem: å†…å­˜ï¼ˆGBï¼‰
            create_bam: æ˜¯å¦åˆ›å»º BAM æ–‡ä»¶
            expect_cells: é¢„æœŸç»†èƒæ•°ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        if not self.cellranger_tool:
            return {
                "status": "error",
                "error": "CellRangerTool not initialized. Please provide cellranger_tool in ScanpyTool.__init__()",
                "output_dir": None,
                "matrix_dir": None
            }
        
        return self.cellranger_tool.run_count(
            fastq_dir=fastq_dir,
            sample_id=sample_id,
            output_dir=output_dir,
            reference=reference,
            sample=sample,
            localcores=localcores,
            localmem=localmem,
            create_bam=create_bam,
            expect_cells=expect_cells
        )
    
    def convert_cellranger_to_h5ad(
        self,
        cellranger_matrix_dir: str,
        output_h5ad_path: str
    ) -> Dict[str, Any]:
        """
        å°† Cell Ranger è¾“å‡ºè½¬æ¢ä¸º .h5ad æ ¼å¼
        
        Args:
            cellranger_matrix_dir: Cell Ranger çŸ©é˜µç›®å½•è·¯å¾„ï¼ˆfiltered_feature_bc_matrixï¼‰
            output_h5ad_path: è¾“å‡ºçš„ .h5ad æ–‡ä»¶è·¯å¾„
        
        Returns:
            è½¬æ¢ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - status: "success" æˆ– "error"
            - output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            - n_obs: ç»†èƒæ•°
            - n_vars: åŸºå› æ•°
            - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        try:
            print(f"ğŸ“– è¯»å– Cell Ranger è¾“å‡º: {cellranger_matrix_dir}")
            
            # æ£€æŸ¥è¾“å…¥ç›®å½•
            if not os.path.exists(cellranger_matrix_dir):
                return {
                    "status": "error",
                    "error": f"Cell Ranger matrix directory does not exist: {cellranger_matrix_dir}",
                    "output_path": None,
                    "n_obs": None,
                    "n_vars": None
                }
            
            # è¯»å– 10x MTX æ•°æ®
            adata = sc.read_10x_mtx(
                cellranger_matrix_dir,
                var_names='gene_symbols',  # ä½¿ç”¨åŸºå› ç¬¦å·ä½œä¸ºå˜é‡å
                cache=True
            )
            
            # ç¡®ä¿åŸºå› åå”¯ä¸€
            adata.var_names_make_unique()
            
            # ä¿å­˜ä¸º .h5ad æ ¼å¼
            print(f"ğŸ’¾ ä¿å­˜ä¸º .h5ad æ ¼å¼: {output_h5ad_path}")
            os.makedirs(os.path.dirname(output_h5ad_path), exist_ok=True)
            adata.write(output_h5ad_path)
            
            file_size_mb = os.path.getsize(output_h5ad_path) / (1024 * 1024)
            
            return {
                "status": "success",
                "output_path": output_h5ad_path,
                "n_obs": adata.n_obs,
                "n_vars": adata.n_vars,
                "matrix_type": type(adata.X).__name__,
                "file_size_mb": round(file_size_mb, 2)
            }
        except Exception as e:
            return {
                "status": "error",
                "error": f"Failed to convert Cell Ranger output: {str(e)}",
                "output_path": None,
                "n_obs": None,
                "n_vars": None
        }
    
    # ================= ğŸš€ ä¸»è°ƒåº¦å™¨ =================
    def run_pipeline(
        self,
        data_input: str,
        steps_config: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„ Scanpy å·¥ä½œæµ
        
        Args:
            data_input: è¾“å…¥æ•°æ®è·¯å¾„ï¼ˆ.h5ad æ–‡ä»¶æˆ– 10x ç›®å½•ï¼‰
            steps_config: æ­¥éª¤é…ç½®åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å« tool_id å’Œ params
        
        Returns:
            åˆ†ææŠ¥å‘Šå­—å…¸
        """
        report = {
            "status": "running",
            "steps_details": [],
            "final_plot": None,
            "qc_metrics": {},
            "diagnosis": "",
            "error": None
        }
        
        try:
            # 1. åŠ è½½æ•°æ®
            adata = self.load_data(data_input)
            report["qc_metrics"]["raw_cells"] = adata.n_obs
            report["qc_metrics"]["raw_genes"] = adata.n_vars
            
            if not steps_config:
                print("âš ï¸ No steps provided, returning raw data stats.")
                report["status"] = "success"
                return report
            
            # 2. æŒ‰é¡ºåºæ‰§è¡Œæ­¥éª¤
            print(f"ğŸ“‹ Pipeline Plan: {[s['tool_id'] for s in steps_config]}")
            
            for step in steps_config:
                tool_id = step['tool_id']
                params = step.get('params', {})
                
                print(f"â–¶ï¸ Executing: {tool_id}")
                
                # ä»æ˜ å°„è¡¨ä¸­æ‰¾åˆ°å‡½æ•°å¹¶æ‰§è¡Œ
                if tool_id in self.tool_map:
                    func = self.tool_map[tool_id]
                    result = func(adata, params)
                    
                    # æ„é€ æ ‡å‡†è¿”å›æ ¼å¼
                    step_report = {
                        "name": tool_id,
                        "status": "success",
                        "plot": result.get("plot"),
                        "details": result.get("details", ""),
                        "summary": result.get("summary", "å®Œæˆ")
                    }
                    
                    # ç‰¹æ®Šå¤„ç†ï¼šæ›´æ–°å…¨å±€æŠ¥å‘ŠçŠ¶æ€
                    if tool_id == "local_qc":
                        report["qc_metrics"]["filtered_cells"] = adata.n_obs
                        report["qc_metrics"]["filtered_genes"] = adata.n_vars
                    if tool_id == "local_umap":
                        report["final_plot"] = result.get("plot")
                    
                    report["steps_details"].append(step_report)
                else:
                    print(f"âš ï¸ Unknown tool_id: {tool_id}, skipping...")
            
            # 3. ä¿å­˜å¤„ç†åçš„æ•°æ®
            output_file = os.path.join(self.output_dir, "processed.h5ad")
            adata.write(output_file)
            report["output_file"] = output_file
            
            # 4. ç”Ÿæˆè¯Šæ–­
            report["diagnosis"] = f"""
            ### âœ… åˆ†æå®Œæˆ
            - **æ‰§è¡Œæ­¥éª¤æ•°**: {len(report['steps_details'])}
            - **å‰©ä½™ç»†èƒ**: {adata.n_obs}
            - **å‰©ä½™åŸºå› **: {adata.n_vars}
            """
            
            report["status"] = "success"
            return report
        
        except Exception as e:
            print(f"âŒ Pipeline Error: {e}")
            import traceback
            traceback.print_exc()
            report["status"] = "failed"
            report["error"] = str(e)
            return report
    
    def generate_workflow_script(
        self,
        input_path: str,
        output_dir: str,
        steps: List[Dict[str, Any]],
        **kwargs
    ) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„ Scanpy å·¥ä½œæµè„šæœ¬ï¼ˆä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹æ—§æ¥å£ï¼‰
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆ.h5ad æˆ– 10x ç›®å½•ï¼‰
            output_dir: è¾“å‡ºç›®å½•
            steps: æ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å« tool_id å’Œ params
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            Python è„šæœ¬å†…å®¹
        """
        script_lines = [
            "#!/usr/bin/env python3",
            "# Scanpy Workflow Script",
            "# Generated by GIBH-Agent",
            "",
            "import scanpy as sc",
            "import pandas as pd",
            "import numpy as np",
            "import matplotlib",
            "matplotlib.use('Agg')",
            "import matplotlib.pyplot as plt",
            "from pathlib import Path",
            "import json",
            "import warnings",
            "warnings.filterwarnings('ignore')",
            "",
            "# é…ç½®",
            f"input_path = '{input_path}'",
            f"output_dir = Path('{output_dir}')",
            "output_dir.mkdir(parents=True, exist_ok=True)",
            "",
            "# åŠ è½½æ•°æ®",
            "print('Loading data...')",
            "if input_path.endswith('.h5ad'):",
            "    adata = sc.read_h5ad(input_path)",
            "elif os.path.isdir(input_path):",
            "    adata = sc.read_10x_mtx(input_path, var_names='gene_symbols', cache=False)",
            "else:",
            "    adata = sc.read(input_path)",
            "adata.var_names_make_unique()",
            "",
        ]
        
        # ç”Ÿæˆæ¯ä¸ªæ­¥éª¤çš„ä»£ç 
        for step in steps:
            tool_id = step.get("tool_id", "")
            params = step.get("params", {})
            
            step_code = self._generate_step_code(tool_id, params)
            script_lines.extend([
                f"# {step.get('name', tool_id)}",
                step_code,
                ""
            ])
        
        # ä¿å­˜ç»“æœ
        script_lines.extend([
            "# ä¿å­˜ç»“æœ",
            "output_file = output_dir / 'processed.h5ad'",
            "adata.write(output_file)",
            "print(f'Results saved to: {output_file}')",
            "",
            "print('Workflow completed successfully!')"
        ])
        
        return "\n".join(script_lines)
    
    def _generate_step_code(self, tool_id: str, params: Dict[str, Any]) -> str:
        """ç”Ÿæˆå•ä¸ªæ­¥éª¤çš„ä»£ç ï¼ˆç”¨äºè„šæœ¬ç”Ÿæˆï¼‰"""
        code_map = {
            "local_qc": self._qc_code(params),
            "local_normalize": self._normalize_code(),
            "local_hvg": self._hvg_code(params),
            "local_scale": self._scale_code(),
            "local_pca": self._pca_code(),
            "local_neighbors": self._neighbors_code(params),
            "local_cluster": self._cluster_code(params),
            "local_umap": self._umap_code(),
            "local_tsne": self._tsne_code(),
            "local_markers": self._markers_code(params)
        }
        
        return code_map.get(tool_id, f"# Unknown tool: {tool_id}")
    
    def _qc_code(self, params: Dict[str, Any]) -> str:
        """QC æ­¥éª¤ä»£ç """
        min_genes = params.get("min_genes", 200)
        max_mt = params.get("max_mt", 20)
        
        return f"""# è®¡ç®— QC æŒ‡æ ‡
adata.var['mt'] = adata.var_names.str.startswith(('MT-', 'mt-'))
sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], inplace=True)

# è¿‡æ»¤
sc.pp.filter_cells(adata, min_genes={min_genes})
adata = adata[adata.obs.pct_counts_mt < {max_mt}, :]
sc.pp.filter_genes(adata, min_cells=3)"""
    
    def _normalize_code(self) -> str:
        """æ ‡å‡†åŒ–æ­¥éª¤ä»£ç """
        return """# æ ‡å‡†åŒ–
sc.pp.normalize_total(adata, target_sum=1e4)
sc.pp.log1p(adata)"""
    
    def _hvg_code(self, params: Dict[str, Any]) -> str:
        """é«˜å˜åŸºå› æ­¥éª¤ä»£ç """
        n_top_genes = params.get("n_top_genes", 2000)
        return f"""# å¯»æ‰¾é«˜å˜åŸºå› 
sc.pp.highly_variable_genes(adata, n_top_genes={n_top_genes})
adata._inplace_subset_var(adata.var['highly_variable'])"""
    
    def _scale_code(self) -> str:
        """ç¼©æ”¾æ­¥éª¤ä»£ç """
        return """# ç¼©æ”¾
sc.pp.scale(adata, max_value=10)"""
    
    def _pca_code(self) -> str:
        """PCA æ­¥éª¤ä»£ç """
        return """# PCA
sc.tl.pca(adata, svd_solver='arpack')"""
    
    def _neighbors_code(self, params: Dict[str, Any]) -> str:
        """Neighbors æ­¥éª¤ä»£ç """
        n_neighbors = params.get("n_neighbors", 10)
        n_pcs = params.get("n_pcs", 40)
        return f"""# è®¡ç®—é‚»å±…
sc.pp.neighbors(adata, n_neighbors={n_neighbors}, n_pcs={n_pcs})"""
    
    def _cluster_code(self, params: Dict[str, Any]) -> str:
        """èšç±»æ­¥éª¤ä»£ç """
        resolution = params.get("resolution", 0.5)
        return f"""# Leiden èšç±»
sc.tl.leiden(adata, resolution={resolution})"""
    
    def _umap_code(self) -> str:
        """UMAP æ­¥éª¤ä»£ç """
        return """# UMAP
sc.tl.umap(adata)
fig, ax = plt.subplots(figsize=(8, 6))
sc.pl.umap(adata, color=['leiden'], ax=ax, show=False, title="UMAP", legend_loc='on data', frameon=False)
plt.savefig(output_dir / 'umap.png', bbox_inches='tight', dpi=300)
plt.close()"""
    
    def _tsne_code(self) -> str:
        """t-SNE æ­¥éª¤ä»£ç """
        return """# t-SNE
if adata.n_obs < 5000:
    sc.tl.tsne(adata)
    fig, ax = plt.subplots(figsize=(8, 6))
    sc.pl.tsne(adata, color=['leiden'], ax=ax, show=False, title="t-SNE", frameon=False)
    plt.savefig(output_dir / 'tsne.png', bbox_inches='tight', dpi=300)
    plt.close()"""
    
    def _markers_code(self, params: Dict[str, Any]) -> str:
        """Markers æ­¥éª¤ä»£ç """
        method = params.get("method", "t-test")
        return f"""# å¯»æ‰¾ Marker åŸºå› 
sc.tl.rank_genes_groups(adata, 'leiden', method='{method}')
result = adata.uns['rank_genes_groups']
groups = result['names'].dtype.names
markers_df = pd.DataFrame({{group + '_' + key: result[key][group][:5] 
                            for group in groups for key in ['names', 'pvals']}})
markers_df.to_csv(output_dir / 'markers.csv', index=False)"""
