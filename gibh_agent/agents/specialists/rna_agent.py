"""
è½¬å½•ç»„æ™ºèƒ½ä½“ï¼ˆRNA Agentï¼‰
å¤„ç†å•ç»†èƒè½¬å½•ç»„ï¼ˆscRNA-seqï¼‰å’Œ Bulk RNA-seq åˆ†æ
é‡æ„è‡ªç°æœ‰çš„ BioBlendAgent
"""
import json
import os
from pathlib import Path
from typing import Dict, Any, List, Optional, AsyncIterator
from ..base_agent import BaseAgent
from ...core.llm_client import LLMClient
from ...core.prompt_manager import PromptManager, RNA_REPORT_PROMPT, DATA_DIAGNOSIS_PROMPT
from ...core.utils import sanitize_for_json
from ...core.dispatcher import TaskDispatcher
from ...core.test_data_manager import TestDataManager
from ...tools.cellranger_tool import CellRangerTool
from ...tools.scanpy_tool import ScanpyTool
import logging

logger = logging.getLogger(__name__)


class RNAAgent(BaseAgent):
    """
    è½¬å½•ç»„æ™ºèƒ½ä½“
    
    èŒè´£ï¼š
    1. å¤„ç†å•ç»†èƒè½¬å½•ç»„åˆ†æï¼ˆscRNA-seqï¼‰
    2. å¤„ç† Bulk RNA-seq åˆ†æ
    3. ç”Ÿæˆå·¥ä½œæµè„šæœ¬
    4. é€šè¿‡ TaskDispatcher æäº¤ä»»åŠ¡
    """
    
    def __init__(
        self,
        llm_client: LLMClient,
        prompt_manager: PromptManager,
        dispatcher: Optional[TaskDispatcher] = None,
        cellranger_config: Optional[Dict[str, Any]] = None,
        scanpy_config: Optional[Dict[str, Any]] = None,
        test_data_dir: Optional[str] = None
    ):
        """åˆå§‹åŒ–è½¬å½•ç»„æ™ºèƒ½ä½“"""
        super().__init__(llm_client, prompt_manager, "rna_expert")
        
        self.dispatcher = dispatcher
        self.cellranger_config = cellranger_config or {}
        self.scanpy_config = scanpy_config or {}
        self.cellranger_tool = CellRangerTool(self.cellranger_config)
        # å°† cellranger_tool ä¼ é€’ç»™ scanpy_toolï¼Œä½¿å…¶å¯ä»¥ä½¿ç”¨ Cell Ranger åŠŸèƒ½
        self.scanpy_tool = ScanpyTool(self.scanpy_config, cellranger_tool=self.cellranger_tool)
        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®ç®¡ç†å™¨
        self.test_data_manager = TestDataManager(test_data_dir)
        
        # æ ‡å‡†å·¥ä½œæµæ­¥éª¤ï¼ˆåæ­¥æµç¨‹ï¼‰
        self.workflow_steps = [
            {"name": "1. Quality Control", "tool_id": "local_qc", "desc": "è¿‡æ»¤ä½è´¨é‡ç»†èƒå’ŒåŸºå› "},
            {"name": "2. Normalization", "tool_id": "local_normalize", "desc": "æ•°æ®æ ‡å‡†åŒ–"},
            {"name": "3. Find Variable Genes", "tool_id": "local_hvg", "desc": "ç­›é€‰é«˜å˜åŸºå› "},
            {"name": "4. Scale Data", "tool_id": "local_scale", "desc": "æ•°æ®ç¼©æ”¾"},
            {"name": "5. PCA", "tool_id": "local_pca", "desc": "ä¸»æˆåˆ†åˆ†æ"},
            {"name": "6. Compute Neighbors", "tool_id": "local_neighbors", "desc": "æ„å»ºé‚»æ¥å›¾"},
            {"name": "7. Clustering", "tool_id": "local_cluster", "desc": "Leiden èšç±»"},
            {"name": "8. UMAP Visualization", "tool_id": "local_umap", "desc": "UMAP å¯è§†åŒ–"},
            {"name": "9. t-SNE Visualization", "tool_id": "local_tsne", "desc": "t-SNE å¯è§†åŒ–"},
            {"name": "10. Find Markers", "tool_id": "local_markers", "desc": "å¯»æ‰¾ Marker åŸºå› "},
        ]
    
    async def process_query(
        self,
        query: str,
        history: List[Dict[str, str]] = None,
        uploaded_files: List[Dict[str, str]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Returns:
            å¤„ç†ç»“æœå­—å…¸ï¼Œå¯èƒ½åŒ…å«ï¼š
            - workflow_config: å·¥ä½œæµé…ç½®ï¼ˆJSONï¼‰
            - chat_response: èŠå¤©å“åº”ï¼ˆæµå¼ï¼‰
            - task_submitted: ä»»åŠ¡æäº¤ä¿¡æ¯
            - test_data_selection: æµ‹è¯•æ•°æ®é€‰æ‹©è¯·æ±‚
        """
        query_lower = query.lower().strip()
        file_paths = self.get_file_paths(uploaded_files or [])
        
        # ğŸ”¥ Task 1: LLM é©±åŠ¨çš„æ„å›¾æ£€æµ‹ï¼ˆåœ¨ç”Ÿæˆå·¥ä½œæµä¹‹å‰ï¼‰
        # ğŸ”’ å®‰å…¨åŒ…è£…ï¼šå¦‚æœæ„å›¾æ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹é€»è¾‘
        intent = "chat"  # é»˜è®¤å€¼
        intent_result = None
        try:
            intent_result = await self._detect_intent_with_llm(query, file_paths, uploaded_files)
            intent = intent_result.get("intent", "chat")
            reasoning = intent_result.get("reasoning", "")
            logger.info(f"ğŸ¯ æ„å›¾æ£€æµ‹ç»“æœ: {intent} (æ¨ç†: {reasoning})")
        except Exception as e:
            logger.warning(f"âš ï¸ æ„å›¾æ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹é€»è¾‘: {e}", exc_info=True)
            # å›é€€åˆ°åŸå§‹çš„å·¥ä½œæµæ£€æµ‹é€»è¾‘
            intent = None  # æ ‡è®°ä¸ºæœªæ£€æµ‹ï¼Œä½¿ç”¨å›é€€é€»è¾‘
        
        # å¦‚æœæ„å›¾æ£€æµ‹æˆåŠŸä¸”ä¸º explain_fileï¼Œå¤„ç†æ–‡ä»¶è§£é‡Š
        if intent == "explain_file":
            # è§£é‡Šæ–‡ä»¶ï¼šæ£€æŸ¥æ–‡ä»¶å¹¶ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Š
            if not file_paths:
                return {
                    "type": "chat",
                    "response": self._stream_string_response("æ²¡æœ‰æ£€æµ‹åˆ°ä¸Šä¼ çš„æ–‡ä»¶ã€‚è¯·å…ˆä¸Šä¼ æ–‡ä»¶åå†è¯¢é—®ã€‚")
                }
            
            # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨æœ€æ–°ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆåˆ—è¡¨æœ€åä¸€ä¸ªï¼‰ï¼Œè€Œä¸æ˜¯ç¬¬ä¸€ä¸ª
            # æ£€æŸ¥æœ€æ–°ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯ h5adï¼Œä½¿ç”¨ scanpy å·¥å…·ï¼‰
            input_path = file_paths[-1] if file_paths else None
            if not input_path:
                return {
                    "type": "chat",
                    "response": self._stream_string_response("æ²¡æœ‰æ£€æµ‹åˆ°ä¸Šä¼ çš„æ–‡ä»¶ã€‚è¯·å…ˆä¸Šä¼ æ–‡ä»¶åå†è¯¢é—®ã€‚")
                }
            try:
                # ä½¿ç”¨ scanpy å·¥å…·æ£€æŸ¥æ–‡ä»¶
                if input_path.endswith('.h5ad'):
                    adata = self.scanpy_tool.load_data(input_path)
                    summary = f"""
æ–‡ä»¶ç±»å‹: H5AD (AnnData)
- ç»†èƒæ•°: {adata.n_obs}
- åŸºå› æ•°: {adata.n_vars}
- è§‚å¯Ÿå˜é‡: {list(adata.obs.columns) if hasattr(adata, 'obs') else 'None'}
- å˜é‡å˜é‡: {list(adata.var.columns) if hasattr(adata, 'var') else 'None'}
"""
                    explanation = await self._explain_file_with_llm(query, summary, input_path)
                    return {
                        "type": "chat",
                        "response": self._stream_string_response(explanation)
                    }
                else:
                    # å…¶ä»–æ–‡ä»¶ç±»å‹ï¼Œè¯»å–æ–‡ä»¶å†…å®¹å¹¶ä½¿ç”¨ LLM è§£é‡Š
                    try:
                        # ä½¿ç”¨ file_inspector è¯»å–æ–‡ä»¶å…ƒæ•°æ®å’Œå†…å®¹
                        from ..core.file_inspector import FileInspector
                        import os
                        
                        # è·å–ä¸Šä¼ ç›®å½•
                        upload_dir = os.getenv("UPLOAD_DIR", "/app/uploads")
                        file_inspector = FileInspector(upload_dir)
                        
                        # è·å–æ–‡ä»¶å…ƒæ•°æ®
                        file_name = os.path.basename(input_path)
                        metadata = file_inspector.generate_metadata(file_name)
                        
                        # è¯»å–æ–‡ä»¶å‰å‡ è¡Œä½œä¸ºå†…å®¹é¢„è§ˆ
                        file_path_obj = Path(input_path)
                        if not file_path_obj.is_absolute():
                            file_path_obj = Path(upload_dir) / file_name
                        
                        file_summary = f"æ–‡ä»¶è·¯å¾„: {input_path}\næ–‡ä»¶ç±»å‹: {os.path.splitext(input_path)[1]}\n"
                        
                        if metadata:
                            file_summary += f"æ–‡ä»¶å¤§å°: {metadata.get('size_mb', 'unknown')} MB\n"
                            if metadata.get('estimated_cells'):
                                file_summary += f"ä¼°ç®—ç»†èƒæ•°: {metadata.get('estimated_cells')}\n"
                            if metadata.get('estimated_genes'):
                                file_summary += f"ä¼°ç®—åŸºå› æ•°: {metadata.get('estimated_genes')}\n"
                        
                        # è¯»å–æ–‡ä»¶å‰å‡ è¡Œ
                        try:
                            if file_path_obj.exists() and file_path_obj.is_file():
                                head_lines = file_inspector._read_head(file_path_obj, 10)
                                if head_lines:
                                    file_summary += f"\næ–‡ä»¶å†…å®¹é¢„è§ˆï¼ˆå‰10è¡Œï¼‰ï¼š\n"
                                    for i, line in enumerate(head_lines[:10], 1):
                                        file_summary += f"{i}: {line[:200]}\n"  # é™åˆ¶æ¯è¡Œé•¿åº¦
                        except Exception as e:
                            logger.warning(f"âš ï¸ è¯»å–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
                            file_summary += "\nï¼ˆæ— æ³•è¯»å–æ–‡ä»¶å†…å®¹ï¼‰\n"
                        
                        # ä½¿ç”¨ LLM ç”Ÿæˆæ–‡ä»¶è§£é‡Š
                        explanation = await self._explain_file_with_llm(query, file_summary, input_path)
                        return {
                            "type": "chat",
                            "response": self._stream_string_response(explanation)
                        }
                    except Exception as e:
                        logger.error(f"âŒ æ–‡ä»¶è§£é‡Šå¤±è´¥: {e}", exc_info=True)
                        # å›é€€åˆ°åŸºæœ¬ä¿¡æ¯
                        return {
                            "type": "chat",
                            "response": self._stream_string_response(f"æ–‡ä»¶è·¯å¾„: {input_path}\næ–‡ä»¶ç±»å‹: {os.path.splitext(input_path)[1]}\n\nï¼ˆæ–‡ä»¶å†…å®¹è¯»å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼‰")
                        }
            except Exception as e:
                logger.error(f"âŒ æ–‡ä»¶è§£é‡Šå¤±è´¥: {e}", exc_info=True)
                return {
                    "type": "chat",
                    "response": self._stream_string_response(f"æ–‡ä»¶æ£€æŸ¥æ—¶å‡ºé”™: {str(e)}")
                }
        
        # æ™ºèƒ½æ•°æ®æ£€æµ‹ï¼šå¦‚æœéœ€è¦ Cell Ranger ä½†æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ï¼Œæä¾›æµ‹è¯•æ•°æ®é€‰æ‹©
        needs_cellranger = self._needs_cellranger(query_lower)
        if needs_cellranger and not file_paths:
            # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ•°æ®å¯ç”¨
            test_datasets = self.test_data_manager.scan_test_datasets()
            if test_datasets:
                # è¿”å›æµ‹è¯•æ•°æ®é€‰æ‹©è¯·æ±‚
                return {
                    "type": "test_data_selection",
                    "message": "æ£€æµ‹åˆ°æ‚¨æ²¡æœ‰ä¸Šä¼ ç›¸å…³æ•°æ®ã€‚è¯·é€‰æ‹©ï¼š",
                    "options": [
                        "1. ä½¿ç”¨æœ¬åœ°æµ‹è¯•æ•°æ®é›†",
                        "2. ä¸Šä¼ æ‚¨è‡ªå·±çš„æ•°æ®"
                    ],
                    "datasets": test_datasets,
                    "datasets_json": self.test_data_manager.format_datasets_for_selection(test_datasets),
                    "datasets_display": self.test_data_manager.format_datasets_for_display(test_datasets)
                }
            else:
                # æ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œæç¤ºç”¨æˆ·ä¸Šä¼ 
                return {
                    "type": "chat",
                    "response": self._stream_string_response(
                        "æ£€æµ‹åˆ°æ‚¨æ²¡æœ‰ä¸Šä¼ ç›¸å…³æ•°æ®ï¼Œä¸”æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•æ•°æ®é›†ã€‚\n"
                        "è¯·ä¸Šä¼  FASTQ æ–‡ä»¶æˆ– .h5ad æ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚"
                    )
                }
        
        # å¤„ç†æµ‹è¯•æ•°æ®é€‰æ‹©ï¼ˆç”¨æˆ·é€šè¿‡ JSON é€‰æ‹©ï¼‰
        if "test_dataset_id" in kwargs:
            dataset_id = kwargs["test_dataset_id"]
            dataset = self.test_data_manager.get_dataset_by_id(dataset_id)
            if dataset:
                # ä½¿ç”¨é€‰å®šçš„æµ‹è¯•æ•°æ®
                if dataset.get("fastq_dir") and dataset.get("reference"):
                    # æœ‰ FASTQ å’Œå‚è€ƒåŸºå› ç»„ï¼Œä½¿ç”¨å®ƒä»¬
                    file_paths = [dataset["fastq_dir"]]
                    # å°†å‚è€ƒåŸºå› ç»„è·¯å¾„æ·»åŠ åˆ°é…ç½®ä¸­
                    self.cellranger_config["reference"] = dataset["reference"]
                elif dataset.get("h5ad_file"):
                    # åªæœ‰ .h5ad æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
                    file_paths = [dataset["h5ad_file"]]
                else:
                    return {
                        "type": "chat",
                        "response": self._stream_string_response(
                            f"æµ‹è¯•æ•°æ®é›† {dataset['name']} ä¸å¯ç”¨ã€‚"
                        )
                    }
        
        # ğŸ”’ å›é€€é€»è¾‘ï¼šå¦‚æœæ„å›¾æ£€æµ‹å¤±è´¥æˆ–æ„å›¾ä¸æ˜ç¡®ï¼Œä½¿ç”¨åŸå§‹é€»è¾‘
        if intent is None or intent == "chat":
            # ä½¿ç”¨åŸå§‹çš„å·¥ä½œæµæ£€æµ‹é€»è¾‘ä½œä¸ºå›é€€
            is_workflow_request = self._is_workflow_request(query_lower, file_paths)
            if is_workflow_request:
                return await self._generate_workflow_config(query, file_paths)
            else:
                # æ™®é€šèŠå¤©
                return {
                    "type": "chat",
                    "response": self._stream_chat_response(query, file_paths)
                }
        
        # å¦‚æœæ„å›¾æ˜ç¡®ä¸º run_workflowï¼Œç›´æ¥ç”Ÿæˆå·¥ä½œæµé…ç½®
        elif intent == "run_workflow":
            return await self._generate_workflow_config(query, file_paths)
        
        # é»˜è®¤ï¼šæ™®é€šèŠå¤©
        else:
            return {
                "type": "chat",
                "response": self._stream_chat_response(query, file_paths)
            }
    
    async def _detect_intent_with_llm(
        self,
        query: str,
        file_paths: List[str],
        uploaded_files: List[Dict[str, str]] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM æ£€æµ‹ç”¨æˆ·æ„å›¾
        
        Returns:
            {
                "intent": "explain_file" | "run_workflow" | "chat",
                "reasoning": "..."
            }
        """
        import json
        import os
        
        # æå–æ–‡ä»¶å
        file_names = []
        if uploaded_files:
            for f in uploaded_files:
                name = f.get("name") or f.get("file_name", "")
                if name:
                    file_names.append(name)
        elif file_paths:
            for path in file_paths:
                file_names.append(os.path.basename(path))
        
        file_names_str = ", ".join(file_names) if file_names else "None"
        
        prompt = f"""åˆ†æç”¨æˆ·è¾“å…¥ï¼Œåˆ¤æ–­ç”¨æˆ·æ„å›¾ã€‚

User Input: {query}
Uploaded Files: {file_names_str}

è¯·å°†æ„å›¾åˆ†ç±»ä¸ºä»¥ä¸‹ä¸‰ç§ä¹‹ä¸€ï¼š
1. "explain_file" - ç”¨æˆ·æƒ³è¦äº†è§£æ–‡ä»¶å†…å®¹ã€ç»“æ„æˆ–å«ä¹‰ï¼ˆä¾‹å¦‚ï¼š"è¿™æ˜¯ä»€ä¹ˆæ–‡ä»¶ï¼Ÿ"ã€"æ–‡ä»¶é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"ã€"è§£é‡Šä¸€ä¸‹è¿™ä¸ªæ•°æ®"ï¼‰
2. "run_workflow" - ç”¨æˆ·æƒ³è¦æ‰§è¡Œåˆ†æå·¥ä½œæµï¼ˆä¾‹å¦‚ï¼š"åˆ†æä¸€ä¸‹"ã€"è¿è¡Œå·¥ä½œæµ"ã€"åšä¸€ä¸‹åˆ†æ"ã€"å¤„ç†è¿™ä¸ªæ–‡ä»¶"ï¼‰
3. "chat" - æ™®é€šå¯¹è¯æˆ–è¯¢é—®ï¼ˆä¾‹å¦‚ï¼š"ä½ å¥½"ã€"å¦‚ä½•ä½¿ç”¨"ã€"ä»‹ç»åŠŸèƒ½"ï¼‰

è¿”å› JSON æ ¼å¼ï¼š
{{
    "intent": "explain_file" | "run_workflow" | "chat",
    "reasoning": "ç®€è¦è¯´æ˜åˆ¤æ–­ç†ç”±"
}}"""
        
        messages = [
            {"role": "system", "content": "You are an intent classification assistant. Return JSON only."},
            {"role": "user", "content": prompt}
        ]
        
        try:
            completion = await self.llm_client.achat(messages, temperature=0.1, max_tokens=128)
            think_content, response = self.llm_client.extract_think_and_content(completion)
            
            # è§£æ JSON
            json_str = response.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            elif "```" in json_str:
                json_str = json_str.split("```")[1].split("```")[0].strip()
            
            result = json.loads(json_str)
            
            # éªŒè¯æ„å›¾å€¼
            valid_intents = ["explain_file", "run_workflow", "chat"]
            if result.get("intent") not in valid_intents:
                logger.warning(f"âš ï¸ LLM è¿”å›äº†æ— æ•ˆæ„å›¾: {result.get('intent')}, ä½¿ç”¨é»˜è®¤å€¼ 'chat'")
                result["intent"] = "chat"
            
            return result
        except Exception as e:
            logger.error(f"âŒ æ„å›¾æ£€æµ‹å¤±è´¥: {e}", exc_info=True)
            # é»˜è®¤è¿”å› chat
            return {
                "intent": "chat",
                "reasoning": f"Intent detection failed: {str(e)}"
            }
    
    async def _explain_file_with_llm(
        self,
        query: str,
        file_summary: str,
        file_path: str
    ) -> str:
        """
        ä½¿ç”¨ LLM ç”Ÿæˆæ–‡ä»¶è§£é‡Š
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            file_summary: æ–‡ä»¶æ‘˜è¦ä¿¡æ¯
            file_path: æ–‡ä»¶è·¯å¾„
        
        Returns:
            è‡ªç„¶è¯­è¨€çš„æ–‡ä»¶è§£é‡Š
        """
        prompt = f"""ç”¨æˆ·è¯¢é—®å…³äºæ–‡ä»¶çš„é—®é¢˜ã€‚

User Query: {query}
File Path: {file_path}

æ–‡ä»¶æ‘˜è¦ä¿¡æ¯ï¼š
{file_summary}

è¯·ç”¨è‡ªç„¶è¯­è¨€è§£é‡Šè¿™ä¸ªæ–‡ä»¶çš„å†…å®¹ã€ç»“æ„å’Œç‰¹ç‚¹ã€‚å›ç­”åº”è¯¥ï¼š
1. ç®€æ´æ˜äº†ï¼Œæ˜“äºç†è§£
2. åŒ…å«å…³é”®ä¿¡æ¯ï¼ˆç»†èƒæ•°ã€åŸºå› æ•°ç­‰ï¼‰
3. å¦‚æœç”¨æˆ·æœ‰ç‰¹å®šé—®é¢˜ï¼Œé’ˆå¯¹æ€§åœ°å›ç­”
4. ä½¿ç”¨ä¸­æ–‡å›ç­”

å›ç­”ï¼š"""
        
        messages = [
            {"role": "system", "content": "You are a bioinformatics data expert. Explain file contents in natural language."},
            {"role": "user", "content": prompt}
        ]
        
        try:
            completion = await self.llm_client.achat(messages, temperature=0.3, max_tokens=800)
            think_content, response = self.llm_client.extract_think_and_content(completion)
            return response
        except Exception as e:
            logger.error(f"âŒ æ–‡ä»¶è§£é‡Šç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            return f"æ–‡ä»¶è§£é‡Šç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _stream_string_response(self, text: str) -> AsyncIterator[str]:
        """å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå¼‚æ­¥ç”Ÿæˆå™¨ï¼ˆç”¨äºæµå¼å“åº”ï¼‰"""
        async def _generator():
            yield text
        return _generator()
    
    def _is_workflow_request(self, query: str, file_paths: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯å·¥ä½œæµè¯·æ±‚"""
        workflow_keywords = [
            "è§„åˆ’", "æµç¨‹", "workflow", "pipeline", "åˆ†æ", "run",
            "æ‰§è¡Œ", "plan", "åšä¸€ä¸‹", "è·‘ä¸€ä¸‹", "åˆ†æä¸€ä¸‹"
        ]
        
        bio_keywords = [
            "pca", "umap", "tsne", "qc", "è´¨æ§", "èšç±»", "cluster"
        ]
        
        if any(kw in query for kw in workflow_keywords):
            return True
        
        if file_paths and any(kw in query for kw in bio_keywords):
            return True
        
        if file_paths and (not query or len(query) < 5):
            return True
        
        return False
    
    def _needs_cellranger(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ Cell Rangerï¼ˆåŸºäºæŸ¥è¯¢å…³é”®è¯ï¼‰"""
        cellranger_keywords = [
            "cellranger", "cell ranger", "fastq", "fq", "æµ‹åº",
            "ç¬¬ä¸€æ­¥", "å…¨æµç¨‹", "å®Œæ•´æµç¨‹", "ä»fastq", "ä»æµ‹åº"
        ]
        return any(kw in query for kw in cellranger_keywords)
    
    async def _generate_workflow_config(
        self,
        query: str,
        file_paths: List[str]
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå·¥ä½œæµé…ç½®
        
        å¼ºåˆ¶æµç¨‹ï¼š
        1. å…ˆæ£€æŸ¥æ–‡ä»¶ï¼ˆinspect_fileï¼‰
        2. åŸºäºæ£€æŸ¥ç»“æœæå–å‚æ•°
        3. ç”Ÿæˆå·¥ä½œæµé…ç½®
        """
        # å¼ºåˆ¶æ£€æŸ¥ï¼šå¦‚æœæœ‰æ–‡ä»¶ï¼Œå…ˆæ£€æŸ¥
        inspection_result = None
        diagnosis_report = None
        if file_paths:
            input_path = file_paths[0]
            try:
                inspection_result = self.scanpy_tool.inspect_file(input_path)
                if "error" in inspection_result:
                    # æ£€æŸ¥å¤±è´¥ï¼Œä½†ä»ç„¶ç»§ç»­ï¼ˆå¯èƒ½æ˜¯æ–‡ä»¶è·¯å¾„é—®é¢˜ï¼‰
                    import logging
                    logger = logging.getLogger(__name__)
                    logger.warning(f"File inspection failed: {inspection_result.get('error')}")
                else:
                    # ğŸ”¥ ç”Ÿæˆæ•°æ®è¯Šæ–­å’Œå‚æ•°æ¨è
                    diagnosis_report = await self._generate_diagnosis_and_recommendation(inspection_result)
            except Exception as e:
                import logging
                logger = logging.getLogger(__name__)
                logger.error(f"Error inspecting file: {e}", exc_info=True)
        
        # ä½¿ç”¨ LLM æå–å‚æ•°ï¼ˆä¼ å…¥æ£€æŸ¥ç»“æœå’Œè¯Šæ–­æŠ¥å‘Šï¼‰
        extracted_params = await self._extract_workflow_params(query, file_paths, inspection_result, diagnosis_report)
        
        # æ„å»ºå·¥ä½œæµé…ç½®
        workflow_config = {
            "workflow_name": "Standard Single-Cell Pipeline",
            "steps": []
        }
        
        for step_template in self.workflow_steps:
            step = step_template.copy()
            
            # æ³¨å…¥å‚æ•°
            tool_id = step["tool_id"]
            if tool_id == "local_qc":
                step["params"] = {
                    "min_genes": extracted_params.get("min_genes", "200"),
                    "max_mt": extracted_params.get("max_mt", "20")
                }
            elif tool_id == "local_hvg":
                step["params"] = {
                    "n_top_genes": extracted_params.get("n_top_genes", "2000")
                }
            elif tool_id == "local_cluster":
                step["params"] = {
                    "resolution": extracted_params.get("resolution", "0.5")
                }
            else:
                step["params"] = {}
            
            workflow_config["steps"].append(step)
        
        # å¦‚æœç”Ÿæˆäº†è¯Šæ–­æŠ¥å‘Šï¼Œå°†å…¶åŒ…å«åœ¨è¿”å›ç»“æœä¸­
        result = {
            "type": "workflow_config",
            "workflow_data": workflow_config,
            "file_paths": file_paths
        }
        
        if diagnosis_report:
            result["diagnosis_report"] = diagnosis_report
        
        return result
    
    async def _generate_diagnosis_and_recommendation(
        self,
        inspection_result: Dict[str, Any]
    ) -> str:
        """
        ç”Ÿæˆæ•°æ®è¯Šæ–­å’Œå‚æ•°æ¨èæŠ¥å‘Š
        
        Args:
            inspection_result: æ–‡ä»¶æ£€æŸ¥ç»“æœ
        
        Returns:
            Markdownæ ¼å¼çš„è¯Šæ–­å’Œæ¨èæŠ¥å‘Š
        """
        try:
            import json
            # æ ¼å¼åŒ–æ£€æŸ¥ç»“æœä¸ºJSONå­—ç¬¦ä¸²
            inspection_json = json.dumps(inspection_result, ensure_ascii=False, indent=2)
            
            # ä½¿ç”¨ PromptManager è·å–è¯Šæ–­æ¨¡æ¿
            try:
                prompt = self.prompt_manager.get_prompt(
                    "data_diagnosis",
                    {"inspection_data": inspection_json},
                    fallback=DATA_DIAGNOSIS_PROMPT.format(inspection_data=inspection_json)
                )
            except Exception as e:
                import logging
                logger = logging.getLogger(__name__)
                logger.warning(f"âš ï¸ è·å–è¯Šæ–­æ¨¡æ¿å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {e}")
                prompt = DATA_DIAGNOSIS_PROMPT.format(inspection_data=inspection_json)
            
            # è°ƒç”¨LLMç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
            messages = [
                {"role": "system", "content": "You are a Senior Bioinformatician. Generate data diagnosis and parameter recommendations in Simplified Chinese."},
                {"role": "user", "content": prompt}
            ]
            
            completion = await self.llm_client.achat(messages, temperature=0.3, max_tokens=1500)
            think_content, response = self.llm_client.extract_think_and_content(completion)
            
            import logging
            logger = logging.getLogger(__name__)
            logger.info("âœ… æ•°æ®è¯Šæ–­å’Œå‚æ•°æ¨èå·²ç”Ÿæˆ")
            return response
            
        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"âŒ ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šå¤±è´¥: {e}", exc_info=True)
            return f"è¯Šæ–­æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
    
    async def _extract_workflow_params(
        self,
        query: str,
        file_paths: List[str],
        inspection_result: Optional[Dict[str, Any]] = None,
        diagnosis_report: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM æå–å·¥ä½œæµå‚æ•°
        
        åŸºäºæ£€æŸ¥ç»“æœæ™ºèƒ½æ¨èå‚æ•°
        """
        # æ„å»ºåŒ…å«æ£€æŸ¥ç»“æœçš„æç¤º
        inspection_info = ""
        if inspection_result and "error" not in inspection_result:
            inspection_info = f"""
ã€Data Inspection Resultsã€‘
- Number of cells (n_obs): {inspection_result.get('n_obs', 'N/A')}
- Number of genes (n_vars): {inspection_result.get('n_vars', 'N/A')}
- Max value: {inspection_result.get('max_value', 'N/A')}
- Is normalized: {inspection_result.get('is_normalized', False)}
- Has QC metrics: {inspection_result.get('has_qc_metrics', False)}
- Has clusters: {inspection_result.get('has_clusters', False)}
- Has UMAP: {inspection_result.get('has_umap', False)}

ã€Recommendations Based on Inspectionã€‘
"""
            n_obs = inspection_result.get('n_obs', 0)
            is_normalized = inspection_result.get('is_normalized', False)
            has_qc = inspection_result.get('has_qc_metrics', False)
            
            if n_obs > 10000:
                inspection_info += "- Large dataset (>10k cells): Recommend min_genes=500, max_mt=5%\n"
            elif n_obs > 5000:
                inspection_info += "- Medium dataset (5k-10k cells): Recommend min_genes=300, max_mt=5%\n"
            else:
                inspection_info += "- Small dataset (<5k cells): Recommend min_genes=200, max_mt=10%\n"
            
            if is_normalized:
                inspection_info += "- Data appears normalized: Skip normalization step\n"
            else:
                inspection_info += "- Data appears to be raw counts: Need normalization\n"
            
            if has_qc:
                inspection_info += "- QC metrics already calculated: May skip QC calculation\n"
        
        prompt = f"""Extract workflow parameters from user query and inspection results:

Query: {query}
Files: {', '.join(file_paths) if file_paths else 'None'}
{inspection_info}

Extract these parameters (if mentioned in query, otherwise use recommendations):
- min_genes (default: 200, adjust based on dataset size)
- max_mt (default: 20, adjust based on dataset size)
- resolution (default: 0.5, for clustering)
- n_top_genes (default: 2000, for HVG selection)

Return JSON only:
{{"resolution": "0.8", "min_genes": "500", "max_mt": "5"}}
"""
        
        messages = [
            {"role": "system", "content": "You are a parameter extraction assistant. Return JSON only."},
            {"role": "user", "content": prompt}
        ]
        
        try:
            completion = await self.llm_client.achat(messages, temperature=0.1, max_tokens=256)
            # æå– think è¿‡ç¨‹å’Œå®é™…å†…å®¹
            think_content, response = self.llm_client.extract_think_and_content(completion)
            # å¦‚æœæœ‰ think å†…å®¹ï¼Œè®°å½•æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
            if think_content:
                import logging
                logger = logging.getLogger(__name__)
                logger.debug(f"RNA Agent think process: {think_content[:200]}...")
            
            # è§£æ JSON
            json_str = response.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            
            return json.loads(json_str)
        except:
            return {}
    
    async def _stream_chat_response(
        self,
        query: str,
        file_paths: List[str]
    ) -> AsyncIterator[str]:
        """
        æµå¼èŠå¤©å“åº”ï¼ˆæ”¯æŒ ReAct å¾ªç¯å’Œå·¥å…·è°ƒç”¨ï¼‰
        
        å®ç° ReAct å¾ªç¯ï¼š
        1. Thought: LLM æ€è€ƒ
        2. Action: è°ƒç”¨å·¥å…·ï¼ˆå¦‚ inspect_fileï¼‰
        3. Observation: å·¥å…·è¿”å›ç»“æœ
        4. Final Answer: æœ€ç»ˆå›ç­”
        """
        context = {
            "context": f"Uploaded files: {', '.join(file_paths) if file_paths else 'None'}",
            "available_tools": ["inspect_file", "run_cellranger", "convert_cellranger_to_h5ad"],
            "tool_descriptions": {
                "inspect_file": "æ£€æŸ¥æ•°æ®æ–‡ä»¶ï¼Œè¿”å›æ•°æ®æ‘˜è¦ï¼ˆn_obs, n_vars, obs_keys, var_keys, is_normalized, etc.ï¼‰",
                "run_cellranger": "è¿è¡Œ Cell Ranger count å¯¹ FASTQ æ–‡ä»¶è¿›è¡Œè®¡æ•°åˆ†æ",
                "convert_cellranger_to_h5ad": "å°† Cell Ranger è¾“å‡ºè½¬æ¢ä¸º Scanpy æ ¼å¼ (.h5ad)"
            }
        }
        
        # å¦‚æœæœ‰æ–‡ä»¶ï¼Œå¼ºåˆ¶å…ˆæ£€æŸ¥ï¼ˆç¬¦åˆ SOPï¼‰
        inspection_result = None
        if file_paths:
            input_path = file_paths[0]
            try:
                inspection_result = self.scanpy_tool.inspect_file(input_path)
                if "error" not in inspection_result:
                    # å°†æ£€æŸ¥ç»“æœæ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­
                    inspection_summary = f"""
ã€Data Inspection Completedã€‘
- Cells: {inspection_result.get('n_obs', 'N/A')}
- Genes: {inspection_result.get('n_vars', 'N/A')}
- Max value: {inspection_result.get('max_value', 'N/A')}
- Normalized: {inspection_result.get('is_normalized', False)}
- Has QC metrics: {inspection_result.get('has_qc_metrics', False)}
- Has clusters: {inspection_result.get('has_clusters', False)}
"""
                    # å…ˆè¾“å‡ºæ£€æŸ¥ç»“æœ
                    yield f"ğŸ” **Data Inspection Results:**\n{inspection_summary}\n\n"
                    # å°†æ£€æŸ¥ç»“æœæ·»åŠ åˆ°æŸ¥è¯¢ä¸­ï¼Œè®© LLM åŸºäºæ­¤åˆ†æ
                    query = f"""{query}

{inspection_summary}

Based on the inspection results above, please:
1. Analyze the data characteristics
2. Propose appropriate analysis parameters
3. Ask for confirmation before proceeding with analysis
"""
            except Exception as e:
                import logging
                logger = logging.getLogger(__name__)
                logger.error(f"Error inspecting file: {e}", exc_info=True)
                yield f"âš ï¸ Warning: Could not inspect file: {str(e)}\n\n"
        
        # æ„å»ºå¢å¼ºçš„ç”¨æˆ·æŸ¥è¯¢ï¼ŒåŒ…å«å·¥å…·è¯´æ˜
        enhanced_query = f"""{query}

ã€Available Toolsã€‘
You have access to:
- inspect_file(file_path): Check data file structure (already executed above if files were provided)
- run_cellranger(fastq_dir, sample_id, output_dir, reference, ...): Run Cell Ranger count on FASTQ files
- convert_cellranger_to_h5ad(matrix_dir, output_path): Convert Cell Ranger output to .h5ad format

ã€Workflow Ruleã€‘
- If user provides FASTQ files: First run Cell Ranger, then convert to .h5ad, then inspect
- If user provides .h5ad or 10x MTX files: Inspect first (already done above), then analyze and propose parameters
- Before running any analysis, you MUST have inspected the data first
- Now analyze the inspection results and propose parameters.
"""
        
        # æµå¼è¾“å‡º LLM å“åº”
        async for chunk in self.chat(enhanced_query, context, stream=True):
            yield chunk
    
    async def execute_workflow(
        self,
        workflow_config: Dict[str, Any],
        file_paths: List[str],
        output_dir: str
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå·¥ä½œæµ
        
        æ ¸å¿ƒï¼šç›´æ¥æ‰§è¡Œ scanpy åˆ†ææµç¨‹ï¼ˆå‚è€ƒæ—§ç‰ˆæœ¬å®ç°ï¼‰
        
        Args:
            workflow_config: å·¥ä½œæµé…ç½®
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
        
        Returns:
            åˆ†ææŠ¥å‘Š
        """
        # æ£€æµ‹è¾“å…¥æ–‡ä»¶ç±»å‹
        input_path = file_paths[0] if file_paths else None
        if not input_path:
            raise ValueError("No input files provided")
        
        file_type = self.detect_file_type(input_path)
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        # æ›´æ–° scanpy å·¥å…·çš„è¾“å‡ºç›®å½•
        self.scanpy_config["output_dir"] = output_dir
        # é‡æ–°åˆå§‹åŒ– scanpy å·¥å…·ä»¥ä½¿ç”¨æ–°çš„è¾“å‡ºç›®å½•ï¼ˆä¿ç•™ cellranger_toolï¼‰
        self.scanpy_tool = ScanpyTool(self.scanpy_config, cellranger_tool=self.cellranger_tool)
        
        # ç›´æ¥æ‰§è¡Œ Scanpy æµç¨‹
        convert_result = None
        if file_type == "fastq":
            # ä» FASTQ å¼€å§‹ï¼šå…ˆè¿è¡Œ Cell Rangerï¼Œç„¶åè½¬æ¢ï¼Œæœ€åæ‰§è¡Œ Scanpy åˆ†æ
            # æå–å‚æ•°
            fastq_dir = input_path
            sample_id = os.path.basename(fastq_dir).replace("_fastqs", "").replace("fastqs", "")
            if not sample_id:
                sample_id = "sample"
            
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
            temp_output_dir = os.path.join(output_dir, "cellranger_output")
            os.makedirs(temp_output_dir, exist_ok=True)
            
            # è¿è¡Œ Cell Ranger
            cellranger_result = self.scanpy_tool.run_cellranger(
                fastq_dir=fastq_dir,
                sample_id=sample_id,
                output_dir=temp_output_dir,
                localcores=self.cellranger_config.get("localcores", 8),
                localmem=self.cellranger_config.get("localmem", 32),
                create_bam=self.cellranger_config.get("create_bam", False)
            )
            
            if cellranger_result.get("status") != "success":
                return sanitize_for_json({
                    "status": "error",
                    "error": f"Cell Ranger failed: {cellranger_result.get('error', 'Unknown error')}",
                    "cellranger_result": cellranger_result
                })
            
            # è½¬æ¢ Cell Ranger è¾“å‡ºä¸º .h5ad
            matrix_dir = cellranger_result.get("matrix_dir")
            if not matrix_dir:
                return sanitize_for_json({
                    "status": "error",
                    "error": "Cell Ranger output matrix directory not found",
                    "cellranger_result": cellranger_result
                })
            
            h5ad_path = os.path.join(output_dir, f"{sample_id}_filtered.h5ad")
            convert_result = self.scanpy_tool.convert_cellranger_to_h5ad(
                cellranger_matrix_dir=matrix_dir,
                output_h5ad_path=h5ad_path
            )
            
            if convert_result.get("status") != "success":
                return sanitize_for_json({
                    "status": "error",
                    "error": f"Conversion failed: {convert_result.get('error', 'Unknown error')}",
                    "cellranger_result": cellranger_result,
                    "convert_result": convert_result
                })
            
            # ä½¿ç”¨è½¬æ¢åçš„ .h5ad æ–‡ä»¶ç»§ç»­æ‰§è¡Œ Scanpy åˆ†æ
            input_path = h5ad_path
        
        # æ‰§è¡Œ Scanpy åˆ†ææµç¨‹
        if file_type != "fastq" or (file_type == "fastq" and convert_result and convert_result.get("status") == "success"):
            # ç›´æ¥è¿è¡Œ Scanpy åˆ†æ
            steps = workflow_config.get("steps", [])
            
            # æ‰§è¡Œåˆ†ææµç¨‹
            report = self.scanpy_tool.run_pipeline(
                data_input=input_path,
                steps_config=steps
            )
            
            # å¦‚æœæ˜¯ä» FASTQ è½¬æ¢æ¥çš„ï¼Œæ·»åŠ è½¬æ¢ä¿¡æ¯åˆ°æŠ¥å‘Š
            if file_type == "fastq" and convert_result:
                report["cellranger_result"] = {
                    "status": "success",
                    "converted_file": convert_result.get("output_path"),
                    "n_obs": convert_result.get("n_obs"),
                    "n_vars": convert_result.get("n_vars")
                }
            
            # ğŸ”¥ ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Šï¼ˆå°†å·¥å…·ç»“æœåé¦ˆç»™LLMè¿›è¡Œè§£é‡Šï¼‰
            if report.get("status") == "success":
                try:
                    final_report = await self.generate_final_report(report)
                    report["final_report"] = final_report
                except Exception as e:
                    logger.warning(f"âš ï¸ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
                    report["final_report"] = None
            
            # ğŸ”¥ æ¸…ç†æ•°æ®ä»¥ç¡®ä¿ JSON åºåˆ—åŒ–å®‰å…¨ï¼ˆå¤„ç† Numpy ç±»å‹ã€NaN/Infinity ç­‰ï¼‰
            logger.info("âœ… Workflow finished. Sanitizing data for JSON serialization...")
            sanitized_report = sanitize_for_json(report)
            logger.info("âœ… Data sanitization completed. Returning result to frontend.")
            
            return sanitized_report
        else:
            # å¦‚æœ FASTQ å¤„ç†å¤±è´¥ï¼Œè¿”å›é”™è¯¯ï¼ˆä¹Ÿéœ€è¦æ¸…ç†ï¼‰
            error_result = {
                "status": "error",
                "error": "Failed to process FASTQ files",
                "convert_result": convert_result
            }
            return sanitize_for_json(error_result)
    
    async def generate_final_report(self, execution_results: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š
        
        å°†å·¥å…·æ‰§è¡Œç»“æœåé¦ˆç»™LLMï¼Œç”Ÿæˆç§‘å­¦è§£é‡ŠæŠ¥å‘Š
        
        Args:
            execution_results: æ‰§è¡Œç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
                - qc_metrics: è´¨é‡æŒ‡æ ‡
                - steps_details: æ­¥éª¤è¯¦æƒ…
                - final_plot: æœ€ç»ˆå›¾ç‰‡è·¯å¾„
                - marker_genes: MarkeråŸºå› ï¼ˆå¦‚æœæœ‰ï¼‰
        
        Returns:
            Markdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
        """
        try:
            # æ”¶é›†æ‰€æœ‰è¾“å‡ºæ•°æ®
            results_summary = {
                "qc_metrics": execution_results.get("qc_metrics", {}),
                "steps_completed": len(execution_results.get("steps_details", [])),
                "final_plot": execution_results.get("final_plot"),
                "output_file": execution_results.get("output_file"),
                "steps_summary": [
                    {
                        "name": step.get("name"),
                        "status": step.get("status"),
                        "summary": step.get("summary")
                    }
                    for step in execution_results.get("steps_details", [])
                ]
            }
            
            # æå–MarkeråŸºå› ï¼ˆå¦‚æœæœ‰ï¼‰
            marker_genes = []
            for step in execution_results.get("steps_details", []):
                if step.get("name") == "local_markers" and step.get("details"):
                    # å°è¯•ä»detailsä¸­æå–markeråŸºå› ä¿¡æ¯
                    marker_genes.append(step.get("details"))
            
            if marker_genes:
                results_summary["marker_genes"] = marker_genes
            
            # æ„å»ºæç¤ºè¯
            import json
            results_json = json.dumps(results_summary, ensure_ascii=False, indent=2)
            
            # ä½¿ç”¨ PromptManager è·å–æŠ¥å‘Šæ¨¡æ¿
            try:
                prompt = self.prompt_manager.get_prompt(
                    "rna_report",
                    {"results_summary": results_json},
                    fallback=RNA_REPORT_PROMPT.format(results_summary=results_json)
                )
            except Exception as e:
                logger.warning(f"âš ï¸ è·å–æŠ¥å‘Šæ¨¡æ¿å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {e}")
                prompt = RNA_REPORT_PROMPT.format(results_summary=results_json)
            
            # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š
            messages = [
                {"role": "system", "content": "You are a Senior Bioinformatician. Write analysis reports in Simplified Chinese."},
                {"role": "user", "content": prompt}
            ]
            
            completion = await self.llm_client.achat(messages, temperature=0.3, max_tokens=2000)
            think_content, response = self.llm_client.extract_think_and_content(completion)
            
            logger.info("âœ… æœ€ç»ˆåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")
            return response
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}", exc_info=True)
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"

