"""ä»£è°¢ç»„å­¦æ™ºèƒ½ä½“ï¼ˆMetabolomics Agentï¼‰"""
from typing import Dict, Any, List, AsyncIterator
from ..base_agent import BaseAgent
from ...core.llm_client import LLMClient
from ...core.prompt_manager import PromptManager
from ...tools.metabolomics_tool import MetabolomicsTool
import logging

logger = logging.getLogger(__name__)


class MetabolomicsAgent(BaseAgent):
    """ä»£è°¢ç»„å­¦æ™ºèƒ½ä½“"""
    
    def __init__(
        self,
        llm_client: LLMClient,
        prompt_manager: PromptManager,
        metabolomics_config: Dict[str, Any] = None
    ):
        super().__init__(llm_client, prompt_manager, "metabolomics_expert")
        self.metabolomics_config = metabolomics_config or {}
        self.metabolomics_tool = MetabolomicsTool(self.metabolomics_config)
    
    async def process_query(
        self,
        query: str,
        history: List[Dict[str, str]] = None,
        uploaded_files: List[Dict[str, str]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Returns:
            å¤„ç†ç»“æœå­—å…¸ï¼Œå¯èƒ½åŒ…å«ï¼š
            - chat: èŠå¤©å“åº”ï¼ˆæµå¼ï¼‰
        """
        query_lower = query.lower().strip()
        file_paths = self.get_file_paths(uploaded_files or [])
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯å·¥ä½œæµè¯·æ±‚
        is_workflow_request = self._is_workflow_request(query_lower, file_paths)
        
        if is_workflow_request:
            # å·¥ä½œæµè¯·æ±‚ï¼šå…ˆæ£€æŸ¥æ•°æ®ï¼Œç„¶åç”Ÿæˆå·¥ä½œæµé…ç½®
            return await self._generate_workflow_config(query, file_paths)
        else:
            # æ™®é€šèŠå¤©ï¼šæµå¼å“åº”
            return {
                "type": "chat",
                "response": self._stream_chat_response(query, file_paths)
            }
    
    def _is_workflow_request(self, query: str, file_paths: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯å·¥ä½œæµè¯·æ±‚"""
        workflow_keywords = [
            "è§„åˆ’", "æµç¨‹", "workflow", "pipeline", "åˆ†æ", "run",
            "æ‰§è¡Œ", "plan", "åšä¸€ä¸‹", "è·‘ä¸€ä¸‹", "åˆ†æä¸€ä¸‹", "å…¨æµç¨‹"
        ]
        
        if any(kw in query for kw in workflow_keywords):
            return True
        
        if file_paths and (not query or len(query) < 5):
            return True
        
        return False
    
    async def _generate_workflow_config(
        self,
        query: str,
        file_paths: List[str]
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå·¥ä½œæµé…ç½®
        
        æµç¨‹ï¼š
        1. å…ˆæ£€æŸ¥æ•°æ®ï¼ˆinspect_dataï¼‰
        2. åŸºäºæ£€æŸ¥ç»“æœæå–å‚æ•°
        3. ç”Ÿæˆå·¥ä½œæµé…ç½®
        """
        # å¼ºåˆ¶æ£€æŸ¥ï¼šå¦‚æœæœ‰æ–‡ä»¶ï¼Œå…ˆæ£€æŸ¥
        inspection_result = None
        if file_paths:
            input_path = file_paths[0]
            try:
                inspection_result = self.metabolomics_tool.inspect_data(input_path)
                if "error" in inspection_result:
                    logger.warning(f"File inspection failed: {inspection_result.get('error')}")
            except Exception as e:
                logger.error(f"Error inspecting file: {e}", exc_info=True)
        
        # ä½¿ç”¨ LLM æå–å‚æ•°ï¼ˆä¼ å…¥æ£€æŸ¥ç»“æœï¼‰
        extracted_params = await self._extract_workflow_params(query, file_paths, inspection_result)
        
        # æ„å»ºå·¥ä½œæµé…ç½®
        workflow_config = {
            "workflow_name": "Metabolomics Analysis Pipeline",
            "steps": [
                {
                    "step_id": "inspect_data",
                    "tool_id": "inspect_data",
                    "desc": "æ£€æŸ¥æ•°æ®æ–‡ä»¶",
                    "params": {"file_path": file_paths[0] if file_paths else ""}
                },
                {
                    "step_id": "preprocess_data",
                    "tool_id": "preprocess_data",
                    "desc": "æ•°æ®é¢„å¤„ç†",
                    "params": {
                        "file_path": file_paths[0] if file_paths else "",
                        "missing_threshold": extracted_params.get("missing_threshold", "0.5"),
                        "normalization": extracted_params.get("normalization", "log2"),
                        "scale": extracted_params.get("scale", "true")
                    }
                },
                {
                    "step_id": "pca_analysis",
                    "tool_id": "pca_analysis",
                    "desc": "ä¸»æˆåˆ†åˆ†æ",
                    "params": {
                        "n_components": extracted_params.get("n_components", "10")
                    }
                },
                {
                    "step_id": "differential_analysis",
                    "tool_id": "differential_analysis",
                    "desc": "å·®å¼‚ä»£è°¢ç‰©åˆ†æ",
                    "params": {
                        "group_column": extracted_params.get("group_column", "Muscle loss"),
                        "method": extracted_params.get("method", "t-test"),
                        "p_value_threshold": extracted_params.get("p_value_threshold", "0.05"),
                        "fold_change_threshold": extracted_params.get("fold_change_threshold", "1.5"),
                        "group1": extracted_params.get("group1"),  # å¦‚æœ >2 ä¸ªåˆ†ç»„ï¼Œéœ€è¦æŒ‡å®š
                        "group2": extracted_params.get("group2")   # å¦‚æœ >2 ä¸ªåˆ†ç»„ï¼Œéœ€è¦æŒ‡å®š
                    }
                },
                {
                    "step_id": "visualize_pca",
                    "tool_id": "visualize_pca",
                    "desc": "PCA å¯è§†åŒ–",
                    "params": {
                        "group_column": extracted_params.get("group_column", "Muscle loss"),
                        "pc1": "1",
                        "pc2": "2"
                    }
                },
                {
                    "step_id": "visualize_volcano",
                    "tool_id": "visualize_volcano",
                    "desc": "ç«å±±å›¾å¯è§†åŒ–",
                    "params": {
                        "p_value_threshold": extracted_params.get("p_value_threshold", "0.05"),
                        "fold_change_threshold": extracted_params.get("fold_change_threshold", "1.5")
                    }
                }
            ]
        }
        
        return {
            "type": "workflow_config",
            "workflow_data": workflow_config,
            "file_paths": file_paths
        }
    
    async def _extract_workflow_params(
        self,
        query: str,
        file_paths: List[str],
        inspection_result: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM æå–å·¥ä½œæµå‚æ•°
        
        åŸºäºæ£€æŸ¥ç»“æœæ™ºèƒ½æ¨èå‚æ•°
        """
        # æ„å»ºåŒ…å«æ£€æŸ¥ç»“æœçš„æç¤º
        inspection_info = ""
        if inspection_result and "error" not in inspection_result:
            inspection_info = f"""
ã€Data Inspection Resultsã€‘
- Number of samples: {inspection_result.get('n_samples', 'N/A')}
- Number of metabolites: {inspection_result.get('n_metabolites', 'N/A')}
- Missing values: {inspection_result.get('missing_values', {}).get('percentage', 'N/A')}%
- Group column: {inspection_result.get('group_info', {}).get('column', 'N/A')}
- Groups: {inspection_result.get('group_info', {}).get('groups', {})}
"""
        
        prompt = f"""
Extract workflow parameters for metabolomics analysis from the user query.

User Query: {query}
File Paths: {file_paths}

{inspection_info}

Based on the inspection results and user query, extract the following parameters:
- missing_threshold: Threshold for removing metabolites with high missing values (default: 0.5)
- normalization: Normalization method - "log2", "zscore", or "none" (default: "log2")
- scale: Whether to apply StandardScaler (default: true)
- n_components: Number of PCA components (default: 10)
- group_column: Column name for group comparison (default: "Muscle loss" or first metadata column)
- method: Statistical method for differential analysis - "t-test" or "mann-whitney" (default: "t-test")
- p_value_threshold: P-value threshold for significance (default: 0.05)
- fold_change_threshold: Fold change threshold (default: 1.5)

Return JSON only:
{{"missing_threshold": "0.5", "normalization": "log2", "scale": "true", "n_components": "10", "group_column": "Muscle loss", "method": "t-test", "p_value_threshold": "0.05", "fold_change_threshold": "1.5"}}
"""
        
        messages = [
            {"role": "system", "content": "You are a parameter extraction assistant. Return JSON only."},
            {"role": "user", "content": prompt}
        ]
        
        try:
            completion = await self.llm_client.achat(messages, temperature=0.1, max_tokens=256)
            think_content, response = self.llm_client.extract_think_and_content(completion)
            
            # è§£æ JSON
            import json
            json_str = response.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            
            return json.loads(json_str)
        except Exception as e:
            logger.error(f"Error extracting parameters: {e}")
            return {}
    
    async def _stream_chat_response(
        self,
        query: str,
        file_paths: List[str]
    ) -> AsyncIterator[str]:
        """
        æµå¼èŠå¤©å“åº”ï¼ˆæ”¯æŒ ReAct å¾ªç¯å’Œå·¥å…·è°ƒç”¨ï¼‰
        """
        context = {
            "context": f"Uploaded files: {', '.join(file_paths) if file_paths else 'None'}",
            "available_tools": list(self.metabolomics_tool.tool_map.keys()),
            "tool_descriptions": {
                "inspect_data": "æ£€æŸ¥ä»£è°¢ç»„å­¦æ•°æ®æ–‡ä»¶ï¼Œè¿”å›æ•°æ®æ‘˜è¦ï¼ˆæ ·æœ¬æ•°ã€ä»£è°¢ç‰©æ•°ã€ç¼ºå¤±å€¼ã€åˆ†ç»„ä¿¡æ¯ç­‰ï¼‰",
                "preprocess_data": "é¢„å¤„ç†æ•°æ®ï¼šå¤„ç†ç¼ºå¤±å€¼ã€æ ‡å‡†åŒ–ã€ç¼©æ”¾",
                "pca_analysis": "æ‰§è¡Œä¸»æˆåˆ†åˆ†æ (PCA)",
                "differential_analysis": "æ‰§è¡Œå·®å¼‚ä»£è°¢ç‰©åˆ†æï¼ˆä¸¤ç»„æ¯”è¾ƒï¼‰",
                "visualize_pca": "ç”Ÿæˆ PCA å¯è§†åŒ–å›¾",
                "visualize_volcano": "ç”Ÿæˆç«å±±å›¾ï¼ˆVolcano Plotï¼‰"
            }
        }
        
        # å¦‚æœæœ‰æ–‡ä»¶ï¼Œå¼ºåˆ¶å…ˆæ£€æŸ¥ï¼ˆç¬¦åˆ SOPï¼‰
        inspection_result = None
        if file_paths:
            input_path = file_paths[0]
            try:
                inspection_result = self.metabolomics_tool.inspect_data(input_path)
                if "error" not in inspection_result:
                    # å°†æ£€æŸ¥ç»“æœæ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­
                    inspection_summary = f"""
ã€Data Inspection Completedã€‘
- Samples: {inspection_result.get('n_samples', 'N/A')}
- Metabolites: {inspection_result.get('n_metabolites', 'N/A')}
- Missing values: {inspection_result.get('missing_values', {}).get('percentage', 'N/A')}%
- Group column: {inspection_result.get('group_info', {}).get('column', 'N/A')}
- Groups: {inspection_result.get('group_info', {}).get('groups', {})}
"""
                    # å…ˆè¾“å‡ºæ£€æŸ¥ç»“æœ
                    yield f"ğŸ” **Data Inspection Results:**\n{inspection_summary}\n\n"
                    # å°†æ£€æŸ¥ç»“æœæ·»åŠ åˆ°æŸ¥è¯¢ä¸­ï¼Œè®© LLM åŸºäºæ­¤åˆ†æ
                    query = f"""{query}

{inspection_summary}

Based on the inspection results above, please:
1. Analyze the data characteristics
2. Propose appropriate analysis parameters
3. Ask for confirmation before proceeding with analysis
"""
            except Exception as e:
                logger.error(f"Error inspecting file: {e}", exc_info=True)
                yield f"âš ï¸ Warning: Could not inspect file: {str(e)}\n\n"
        
        # æ„å»ºå¢å¼ºçš„ç”¨æˆ·æŸ¥è¯¢ï¼ŒåŒ…å«å·¥å…·è¯´æ˜
        enhanced_query = f"""{query}

ã€Available Toolsã€‘
You have access to:
- inspect_data(file_path): Check data file structure (already executed above if files were provided)
- preprocess_data(file_path, missing_threshold, normalization, scale): Preprocess metabolomics data
- pca_analysis(n_components, file_path): Perform PCA analysis
- differential_analysis(group_column, file_path, method, p_value_threshold, fold_change_threshold): Find differential metabolites
- visualize_pca(group_column, pca_file, pc1, pc2): Generate PCA plot
- visualize_volcano(diff_file, p_value_threshold, fold_change_threshold): Generate volcano plot

ã€Workflow Ruleã€‘
- If user provides CSV files: Inspect first (already done above), then analyze and propose parameters
- Before running any analysis, you MUST have inspected the data first
- Now analyze the inspection results and propose parameters.
"""
        
        # æµå¼è¾“å‡º LLM å“åº”
        async for chunk in self.chat(enhanced_query, context, stream=True):
            yield chunk
    
    async def execute_workflow(
        self,
        workflow_config: Dict[str, Any],
        file_paths: List[str],
        output_dir: str
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»£è°¢ç»„å­¦å·¥ä½œæµ
        
        Args:
            workflow_config: å·¥ä½œæµé…ç½®
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
        
        Returns:
            åˆ†ææŠ¥å‘Š
        """
        import os
        
        input_path = file_paths[0] if file_paths else None
        if not input_path:
            raise ValueError("No input files provided")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        # æ›´æ–°ä»£è°¢ç»„å·¥å…·çš„è¾“å‡ºç›®å½•
        from pathlib import Path
        self.metabolomics_config["output_dir"] = output_dir
        self.metabolomics_tool.output_dir = Path(output_dir)
        self.metabolomics_tool.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ‰§è¡Œå·¥ä½œæµæ­¥éª¤
        steps = workflow_config.get("steps", [])
        steps_details = []
        final_plot = None
        
        try:
            for step in steps:
                step_id = step.get("step_id")
                tool_id = step.get("tool_id")
                params = step.get("params", {})
                
                logger.info(f"ğŸ”§ æ‰§è¡Œæ­¥éª¤: {step_id} ({tool_id})")
                
                if tool_id == "inspect_data":
                    result = self.metabolomics_tool.inspect_data(params.get("file_path", input_path))
                    steps_details.append({
                        "step_id": step_id,
                        "tool_id": tool_id,
                        "name": step.get("desc", step_id),
                        "summary": f"æ£€æŸ¥å®Œæˆ: {result.get('n_samples', 'N/A')} ä¸ªæ ·æœ¬, {result.get('n_metabolites', 'N/A')} ä¸ªä»£è°¢ç‰©",
                        "status": result.get("status", "success")
                    })
                
                elif tool_id == "preprocess_data":
                    result = self.metabolomics_tool.preprocess_data(
                        file_path=params.get("file_path", input_path),
                        missing_threshold=float(params.get("missing_threshold", "0.5")),
                        normalization=params.get("normalization", "log2"),
                        scale=params.get("scale", "true").lower() == "true"
                    )
                    steps_details.append({
                        "step_id": step_id,
                        "tool_id": tool_id,
                        "name": step.get("desc", step_id),
                        "summary": result.get("message", "é¢„å¤„ç†å®Œæˆ"),
                        "status": result.get("status", "success")
                    })
                
                elif tool_id == "pca_analysis":
                    # å¦‚æœä¸Šä¸€æ­¥æ˜¯é¢„å¤„ç†ï¼Œä½¿ç”¨é¢„å¤„ç†åçš„æ–‡ä»¶
                    preprocessed_file = None
                    for prev_step in steps_details:
                        if prev_step.get("tool_id") == "preprocess_data":
                            # ä»é¢„å¤„ç†ç»“æœä¸­è·å–æ–‡ä»¶è·¯å¾„
                            preprocessed_file = os.path.join(output_dir, "preprocessed_data.csv")
                            break
                    
                    result = self.metabolomics_tool.pca_analysis(
                        n_components=int(params.get("n_components", "10")),
                        file_path=preprocessed_file or params.get("file_path", input_path)
                    )
                    steps_details.append({
                        "step_id": step_id,
                        "tool_id": tool_id,
                        "name": step.get("desc", step_id),
                        "summary": result.get("message", "PCA åˆ†æå®Œæˆ"),
                        "status": result.get("status", "success")
                    })
                
                elif tool_id == "differential_analysis":
                    # ä½¿ç”¨é¢„å¤„ç†åçš„æ–‡ä»¶
                    preprocessed_file = os.path.join(output_dir, "preprocessed_data.csv")
                    if not os.path.exists(preprocessed_file):
                        preprocessed_file = input_path
                    
                    result = self.metabolomics_tool.differential_analysis(
                        group_column=params.get("group_column", "Muscle loss"),
                        file_path=preprocessed_file,
                        method=params.get("method", "t-test"),
                        p_value_threshold=float(params.get("p_value_threshold", "0.05")),
                        fold_change_threshold=float(params.get("fold_change_threshold", "1.5")),
                        group1=params.get("group1"),
                        group2=params.get("group2")
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”¨æˆ·é€‰æ‹©åˆ†ç»„
                    if result.get("status") == "need_selection":
                        return {
                            "status": "need_selection",
                            "message": result.get("message", "éœ€è¦é€‰æ‹©æ¯”è¾ƒçš„åˆ†ç»„"),
                            "groups": result.get("groups", []),
                            "steps_details": steps_details
                        }
                    
                    steps_details.append({
                        "step_id": step_id,
                        "tool_id": tool_id,
                        "name": step.get("desc", step_id),
                        "summary": result.get("message", "å·®å¼‚åˆ†æå®Œæˆ"),
                        "status": result.get("status", "success"),
                        "details": result.get("summary", "")
                    })
                
                elif tool_id == "visualize_pca":
                    # ä½¿ç”¨ PCA åˆ†æç»“æœæ–‡ä»¶
                    pca_file = params.get("pca_file") or os.path.join(output_dir, "pca_results.csv")
                    if not os.path.exists(pca_file):
                        # å¦‚æœ PCA æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»æ­¥éª¤è¯¦æƒ…ä¸­è·å–
                        for prev_step in steps_details:
                            if prev_step.get("tool_id") == "pca_analysis":
                                pca_file = os.path.join(output_dir, "pca_results.csv")
                                break
                    
                    result = self.metabolomics_tool.visualize_pca(
                        group_column=params.get("group_column", "Muscle loss"),
                        pca_file=pca_file,
                        pc1=int(params.get("pc1", "1")),
                        pc2=int(params.get("pc2", "2"))
                    )
                    plot_path = result.get("plot_path") or result.get("plot_file")
                    if plot_path:
                        # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äº output_dirï¼‰
                        if os.path.isabs(plot_path):
                            plot_path = os.path.relpath(plot_path, output_dir)
                        # ç¡®ä¿è·¯å¾„ä½¿ç”¨æ­£æ–œæ ï¼ˆWeb å…¼å®¹ï¼‰
                        plot_path = plot_path.replace("\\", "/")
                        final_plot = plot_path
                    steps_details.append({
                        "step_id": step_id,
                        "tool_id": tool_id,
                        "name": step.get("desc", step_id),
                        "summary": "PCA å¯è§†åŒ–å®Œæˆ",
                        "status": result.get("status", "success"),
                        "plot": plot_path.replace("\\", "/") if plot_path else None
                    })
                
                elif tool_id == "visualize_volcano":
                    # ä½¿ç”¨å·®å¼‚åˆ†æç»“æœæ–‡ä»¶
                    diff_file = params.get("diff_file") or os.path.join(output_dir, "differential_results.csv")
                    if not os.path.exists(diff_file):
                        # å¦‚æœå·®å¼‚åˆ†ææ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»æ­¥éª¤è¯¦æƒ…ä¸­è·å–
                        for prev_step in steps_details:
                            if prev_step.get("tool_id") == "differential_analysis":
                                diff_file = os.path.join(output_dir, "differential_results.csv")
                                break
                    
                    result = self.metabolomics_tool.visualize_volcano(
                        diff_file=diff_file,
                        p_value_threshold=float(params.get("p_value_threshold", "0.05")),
                        fold_change_threshold=float(params.get("fold_change_threshold", "1.5"))
                    )
                    plot_path = result.get("plot_path") or result.get("plot_file")
                    if plot_path:
                        # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äº output_dirï¼‰
                        if os.path.isabs(plot_path):
                            plot_path = os.path.relpath(plot_path, output_dir)
                        # ç¡®ä¿è·¯å¾„ä½¿ç”¨æ­£æ–œæ ï¼ˆWeb å…¼å®¹ï¼‰
                        plot_path = plot_path.replace("\\", "/")
                        if not final_plot:
                            final_plot = plot_path
                    steps_details.append({
                        "step_id": step_id,
                        "tool_id": tool_id,
                        "name": step.get("desc", step_id),
                        "summary": "ç«å±±å›¾å¯è§†åŒ–å®Œæˆ",
                        "status": result.get("status", "success"),
                        "plot": plot_path.replace("\\", "/") if plot_path else None
                    })
            
            return {
                "status": "success",
                "workflow_name": workflow_config.get("workflow_name", "Metabolomics Analysis"),
                "steps_details": steps_details,
                "final_plot": final_plot,
                "output_dir": output_dir
            }
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return {
                "status": "error",
                "error": str(e),
                "steps_details": steps_details,
                "output_dir": output_dir
            }

