"""
åŸºç¡€æ™ºèƒ½ä½“æŠ½è±¡ç±»
æ‰€æœ‰é¢†åŸŸæ™ºèƒ½ä½“éƒ½ç»§æ‰¿æ­¤ç±»
"""
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List, AsyncIterator
import logging
from openai import AuthenticationError, APIError
from ..core.llm_client import LLMClient
from ..core.prompt_manager import PromptManager, DATA_DIAGNOSIS_PROMPT
from ..core.data_diagnostician import DataDiagnostician

logger = logging.getLogger(__name__)


class BaseAgent(ABC):
    """
    åŸºç¡€æ™ºèƒ½ä½“æŠ½è±¡ç±»
    
    æ‰€æœ‰é¢†åŸŸæ™ºèƒ½ä½“éƒ½åº”è¯¥ç»§æ‰¿æ­¤ç±»å¹¶å®ç°ï¼š
    - process_query: å¤„ç†ç”¨æˆ·æŸ¥è¯¢
    - generate_workflow: ç”Ÿæˆå·¥ä½œæµï¼ˆå¦‚æœéœ€è¦ï¼‰
    """
    
    def __init__(
        self,
        llm_client: LLMClient,
        prompt_manager: PromptManager,
        expert_role: str
    ):
        """
        åˆå§‹åŒ–åŸºç¡€æ™ºèƒ½ä½“
        
        Args:
            llm_client: LLM å®¢æˆ·ç«¯
            prompt_manager: æç¤ºç®¡ç†å™¨
            expert_role: ä¸“å®¶è§’è‰²åç§°ï¼ˆå¦‚ "rna_expert"ï¼‰
        """
        self.llm_client = llm_client
        self.prompt_manager = prompt_manager
        self.expert_role = expert_role
        self.diagnostician = DataDiagnostician()
        # ğŸ”¥ æ¶æ„é‡æ„ï¼šä¼šè¯çº§æ–‡ä»¶æ³¨å†Œè¡¨
        self.context: Dict[str, Any] = {
            "file_registry": {},  # Key: filename, Value: {path, metadata, timestamp}
            "active_file": None   # å½“å‰æ´»åŠ¨çš„æ–‡ä»¶å
        }
    
    def register_file(
        self,
        filename: str,
        file_path: str,
        file_metadata: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        æ³¨å†Œæ–‡ä»¶åˆ°ä¼šè¯æ³¨å†Œè¡¨
        
        ğŸ”¥ æ¶æ„é‡æ„ï¼šç»´æŠ¤æ–‡ä»¶å†å²ï¼Œè€Œä¸æ˜¯æ¸…é™¤
        
        Args:
            filename: æ–‡ä»¶åï¼ˆç”¨ä½œæ³¨å†Œè¡¨çš„ keyï¼‰
            file_path: æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
            file_metadata: æ–‡ä»¶å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼Œç¨åå¯ä»¥æ›´æ–°ï¼‰
        """
        import time
        if "file_registry" not in self.context:
            self.context["file_registry"] = {}
        
        self.context["file_registry"][filename] = {
            "path": file_path,
            "metadata": file_metadata,
            "timestamp": time.time(),
            "registered_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        logger.info(f"ğŸ“ [FileRegistry] Registered file: {filename} (Total: {len(self.context['file_registry'])} files)")
    
    def set_active_file(self, filename: str) -> None:
        """
        è®¾ç½®å½“å‰æ´»åŠ¨çš„æ–‡ä»¶
        
        Args:
            filename: æ–‡ä»¶åï¼ˆå¿…é¡»åœ¨æ³¨å†Œè¡¨ä¸­å­˜åœ¨ï¼‰
        """
        if filename not in self.context.get("file_registry", {}):
            logger.warning(f"âš ï¸ [FileRegistry] File {filename} not in registry. Registering...")
            # å¦‚æœæ–‡ä»¶ä¸åœ¨æ³¨å†Œè¡¨ä¸­ï¼Œå°è¯•æ³¨å†Œï¼ˆä½¿ç”¨è·¯å¾„ä½œä¸ºæ–‡ä»¶åï¼‰
            self.register_file(filename, filename)
        
        old_active = self.context.get("active_file")
        self.context["active_file"] = filename
        
        if old_active != filename:
            logger.info(f"ğŸ”„ [FileRegistry] Active file changed: {old_active} -> {filename}")
        else:
            logger.debug(f"âœ… [FileRegistry] Active file unchanged: {filename}")
    
    def get_active_file_info(self) -> Optional[Dict[str, Any]]:
        """
        è·å–å½“å‰æ´»åŠ¨æ–‡ä»¶çš„ä¿¡æ¯
        
        ğŸ”¥ æ¶æ„é‡æ„ï¼šç»Ÿä¸€æ¥å£è·å–æ´»åŠ¨æ–‡ä»¶ä¿¡æ¯
        
        Returns:
            åŒ…å« path å’Œ metadata çš„å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰æ´»åŠ¨æ–‡ä»¶è¿”å› None
        """
        active_file = self.context.get("active_file")
        if not active_file:
            logger.debug("âš ï¸ [FileRegistry] No active file set")
            return None
        
        registry = self.context.get("file_registry", {})
        if active_file not in registry:
            logger.warning(f"âš ï¸ [FileRegistry] Active file '{active_file}' not found in registry")
            return None
        
        file_info = registry[active_file]
        logger.debug(f"âœ… [FileRegistry] Retrieved active file info: {active_file}")
        return {
            "filename": active_file,
            "path": file_info.get("path"),
            "metadata": file_info.get("metadata"),
            "timestamp": file_info.get("timestamp")
        }
    
    def _refresh_context_for_new_files(self, uploaded_files: List[Dict[str, str]]) -> None:
        """
        åˆ·æ–°ä¸Šä¸‹æ–‡ä»¥å¤„ç†æ–°æ–‡ä»¶
        
        ğŸ”¥ ä¿®å¤ï¼šå½“æ–°æ–‡ä»¶ä¸Šä¼ æ—¶ï¼Œæ¸…é™¤æ—§çš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿ä½¿ç”¨æ–°æ–‡ä»¶ä½œä¸ºå•ä¸€æ•°æ®æº
        
        Args:
            uploaded_files: å½“å‰è¯·æ±‚ä¸­çš„æ–‡ä»¶åˆ—è¡¨
        """
        if uploaded_files and len(uploaded_files) > 0:
            # æå–æ–‡ä»¶åç”¨äºæ—¥å¿—
            file_names = []
            for file_info in uploaded_files:
                if isinstance(file_info, dict):
                    name = file_info.get("name") or file_info.get("path") or file_info.get("file_id", "unknown")
                else:
                    name = getattr(file_info, "name", None) or getattr(file_info, "path", None) or "unknown"
                file_names.append(name)
            
            # æ¸…é™¤æ—§çš„ä¸Šä¸‹æ–‡
            old_file_paths = self.context.get("file_paths", [])
            old_file_metadata = self.context.get("file_metadata")
            
            if old_file_paths or old_file_metadata:
                logger.info(f"ğŸ”„ [System] Context refreshed. Clearing old context:")
                logger.info(f"   Old files: {old_file_paths}")
                logger.info(f"   New active files: {file_names}")
            
            # æ¸…é™¤æ–‡ä»¶ç›¸å…³çš„ä¸Šä¸‹æ–‡
            self.context.pop("file_paths", None)
            self.context.pop("file_metadata", None)
            self.context.pop("diagnosis_report", None)
            self.context.pop("diagnosis_stats", None)
            
            logger.info(f"âœ… [System] Context refreshed. New active file: {file_names[0] if file_names else 'None'}")
    
    @abstractmethod
    async def process_query(
        self,
        query: str,
        history: List[Dict[str, str]] = None,
        uploaded_files: List[Dict[str, str]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼ˆæŠ½è±¡æ–¹æ³•ï¼‰
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            history: å¯¹è¯å†å²
            uploaded_files: ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        pass
    
    async def chat(
        self,
        query: str,
        context: Dict[str, Any] = None,
        stream: bool = False
    ) -> AsyncIterator[str]:
        """
        é€šç”¨èŠå¤©æ–¹æ³•
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            stream: æ˜¯å¦æµå¼è¾“å‡º
        
        Yields:
            å“åº”æ–‡æœ¬å—
        """
        context = context or {}
        
        # è·å–ç³»ç»Ÿæç¤ºè¯
        system_prompt = self.prompt_manager.get_system_prompt(
            self.expert_role,
            context
        )
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query}
        ]
        
        try:
            if stream:
                # æµå¼è¾“å‡ºï¼šç›´æ¥ä¼ é€’å†…å®¹ï¼Œè®©å‰ç«¯å¤„ç† think æ ‡ç­¾
                # DeepSeek-R1 çš„ think è¿‡ç¨‹ä¼šä»¥ <think>...</think> æ ‡ç­¾å½¢å¼è¿”å›
                # ä¹Ÿæ”¯æŒæ—§åè®®çš„ <think>...</think> æ ‡ç­¾
                has_yielded = False
                try:
                    async for chunk in self.llm_client.astream(messages):
                        if chunk.choices and chunk.choices[0].delta.content:
                            content = chunk.choices[0].delta.content
                            if content:
                                # ç›´æ¥ä¼ é€’å†…å®¹ï¼Œå‰ç«¯ä¼šæ£€æµ‹å’Œå¤„ç† think æ ‡ç­¾ï¼ˆ<think> æˆ– <think>ï¼‰
                                yield content
                                has_yielded = True
                except Exception as stream_error:
                    logger.error(f"âŒ æµå¼å“åº”é”™è¯¯: {stream_error}", exc_info=True)
                    if not has_yielded:
                        yield f"\n\nâŒ é”™è¯¯: {str(stream_error)}\n\nè¯·æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
                    else:
                        # å¦‚æœå·²ç»æœ‰ä¸€äº›è¾“å‡ºï¼Œåªè®°å½•é”™è¯¯ï¼Œä¸é‡å¤è¾“å‡ºé”™è¯¯ä¿¡æ¯
                        logger.warning(f"âš ï¸ æµå¼å“åº”ä¸­æ–­ï¼Œä½†å·²æœ‰éƒ¨åˆ†è¾“å‡º")
            else:
                completion = await self.llm_client.achat(messages)
                # æå– think è¿‡ç¨‹å’Œå®é™…å†…å®¹
                think_content, actual_content = self.llm_client.extract_think_and_content(completion)
                
                # å¦‚æœæœ‰ think å†…å®¹ï¼ŒåŒ…è£…åœ¨æ ‡ç­¾ä¸­
                if think_content:
                    yield f"<think>{think_content}</think>\n\n{actual_content}"
                else:
                    yield actual_content
        except AuthenticationError as e:
            error_msg = (
                f"\n\nâŒ è®¤è¯é”™è¯¯ (Error code: 401 - Invalid token)\n"
                f"è¯·æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æ­£ç¡®è®¾ç½®ã€‚\n"
                f"è®¾ç½®æ–¹æ³•: export SILICONFLOW_API_KEY='your_api_key_here'\n"
                f"è¯¦ç»†é”™è¯¯: {str(e)}"
            )
            logger.error(f"API è®¤è¯å¤±è´¥: {e}")
            yield error_msg
        except APIError as e:
            error_msg = (
                f"\n\nâŒ API é”™è¯¯ (Error code: {getattr(e, 'status_code', 'unknown')})\n"
                f"è¯¦ç»†é”™è¯¯: {str(e)}"
            )
            logger.error(f"API è°ƒç”¨å¤±è´¥: {e}")
            yield error_msg
        except Exception as e:
            error_msg = f"\n\nâŒ é”™è¯¯: {str(e)}"
            logger.error(f"èŠå¤©å¤„ç†å¤±è´¥: {e}", exc_info=True)
            yield error_msg
    
    def get_file_paths(self, uploaded_files: List[Dict[str, str]]) -> List[str]:
        """
        ä»ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨ä¸­æå–æ–‡ä»¶è·¯å¾„ï¼Œå¹¶è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        
        æ ¸å¿ƒåŸåˆ™ï¼šæ™ºèƒ½ä½“åªå¤„ç†æ–‡ä»¶è·¯å¾„ï¼ˆå­—ç¬¦ä¸²ï¼‰ï¼Œä¸å¤„ç†äºŒè¿›åˆ¶æ•°æ®
        **å…³é”®ä¿®å¤**ï¼šç¡®ä¿è¿”å›ç»å¯¹è·¯å¾„ï¼Œé¿å… "File Not Found" é”™è¯¯
        
        Args:
            uploaded_files: æ–‡ä»¶åˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«ç›¸å¯¹è·¯å¾„æˆ– file_idï¼‰
        
        Returns:
            ç»å¯¹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        import os
        from pathlib import Path
        
        # è·å–ä¸Šä¼ ç›®å½•ï¼ˆä¸ server.py ä¿æŒä¸€è‡´ï¼‰
        upload_dir = Path(os.getenv("UPLOAD_DIR", "/app/uploads"))
        
        paths = []
        for file_info in uploaded_files:
            if isinstance(file_info, dict):
                path = file_info.get("path") or file_info.get("name") or file_info.get("file_path") or file_info.get("file_id")
            else:
                path = getattr(file_info, "path", None) or getattr(file_info, "name", None) or getattr(file_info, "file_path", None) or getattr(file_info, "file_id", None)
            
            if not path:
                continue
            
            # ğŸ”¥ ä¿®å¤ï¼šè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            path_obj = Path(path)
            
            # å¦‚æœå·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
            if path_obj.is_absolute():
                absolute_path = str(path_obj.resolve())
            else:
                # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œæ‹¼æ¥ UPLOAD_DIR
                absolute_path = str((upload_dir / path_obj).resolve())
            
            # éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­å¤„ç†ï¼Œè®©è°ƒç”¨æ–¹å¤„ç†é”™è¯¯ï¼‰
            if not os.path.exists(absolute_path):
                logger.warning(f"âš ï¸ æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨: {absolute_path} (åŸå§‹è·¯å¾„: {path})")
                # ä»ç„¶æ·»åŠ åˆ°åˆ—è¡¨ï¼Œè®©è°ƒç”¨æ–¹å¤„ç†ï¼ˆå¯èƒ½æ–‡ä»¶ç¨åä¼šè¢«åˆ›å»ºï¼‰
            
            paths.append(absolute_path)
        
        return paths
    
    def detect_file_type(self, file_path: str) -> str:
        """
        æ£€æµ‹æ–‡ä»¶ç±»å‹
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„
        
        Returns:
            æ–‡ä»¶ç±»å‹ï¼ˆå¦‚ "fastq", "bam", "h5ad", "10x_mtx"ï¼‰
        """
        import os
        
        # å¦‚æœæ˜¯ç›®å½•ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯ FASTQ ç›®å½•æˆ– 10x MTX ç›®å½•
        if os.path.isdir(file_path):
            # æ£€æŸ¥æ˜¯å¦æ˜¯ FASTQ ç›®å½•ï¼ˆåŒ…å« .fastq æˆ– .fq æ–‡ä»¶ï¼‰
            fastq_files = [f for f in os.listdir(file_path) if f.endswith(('.fastq', '.fq', '.fastq.gz', '.fq.gz'))]
            if fastq_files:
                return "fastq"
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ 10x MTX ç›®å½•ï¼ˆåŒ…å« matrix.mtx æˆ– matrix.mtx.gzï¼‰
            mtx_files = [f for f in os.listdir(file_path) if 'matrix.mtx' in f.lower()]
            if mtx_files:
                return "10x_mtx"
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ Cell Ranger è¾“å‡ºç›®å½•ï¼ˆåŒ…å« filtered_feature_bc_matrixï¼‰
            if 'filtered_feature_bc_matrix' in os.listdir(file_path) or \
               any('filtered_feature_bc_matrix' in subdir for subdir in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, subdir))):
                return "10x_mtx"
            
            return "directory"
        
        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œæ£€æŸ¥æ‰©å±•å
        ext = file_path.split('.')[-1].lower()
        
        type_mapping = {
            "fastq": ["fastq", "fq"],
            "bam": ["bam"],
            "h5ad": ["h5ad"],
            "mtx": ["mtx"],
            "vcf": ["vcf"],
            "bed": ["bed"],
            "bw": ["bw", "bigwig"],
            "sam": ["sam"],
            "csv": ["csv"]  # ä»£è°¢ç»„å­¦æ•°æ®é€šå¸¸ä½¿ç”¨ CSV æ ¼å¼
        }
        
        for file_type, extensions in type_mapping.items():
            if ext in extensions:
                return file_type
        
        return "unknown"
    
    async def _perform_data_diagnosis(
        self,
        file_metadata: Dict[str, Any],
        omics_type: str,
        dataframe: Optional[Any] = None,
        system_instruction: Optional[str] = None
    ) -> Optional[str]:
        """
        æ‰§è¡Œæ•°æ®è¯Šæ–­å¹¶ç”Ÿæˆ Markdown æŠ¥å‘Š
        
        ğŸ”¥ æ¶æ„é‡æ„ï¼šä½¿ç”¨ç­–ç•¥æ¨¡å¼ï¼Œæ¥å— domain-specific system_instruction
        
        è¿™æ˜¯ç»Ÿä¸€çš„æ•°æ®è¯Šæ–­å…¥å£ï¼Œæ‰€æœ‰ Agent éƒ½åº”è¯¥è°ƒç”¨æ­¤æ–¹æ³•ã€‚
        
        Args:
            file_metadata: FileInspector è¿”å›çš„æ–‡ä»¶å…ƒæ•°æ®
            omics_type: ç»„å­¦ç±»å‹ï¼ˆ"scRNA", "Metabolomics", "BulkRNA", "default"ï¼‰
            dataframe: å¯é€‰çš„æ•°æ®é¢„è§ˆï¼ˆDataFrame æˆ– AnnDataï¼‰
            system_instruction: é¢†åŸŸç‰¹å®šçš„ç³»ç»ŸæŒ‡ä»¤ï¼ˆç”±å„ä¸ª Agent æä¾›ï¼‰
        
        Returns:
            Markdown æ ¼å¼çš„è¯Šæ–­æŠ¥å‘Šï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        try:
            logger.info(f"ğŸ” [DataDiagnostician] å¼€å§‹æ•°æ®è¯Šæ–­ - ç»„å­¦ç±»å‹: {omics_type}")
            
            # Step 1: ä½¿ç”¨ DataDiagnostician è®¡ç®—ç»Ÿè®¡äº‹å®
            diagnosis_result = self.diagnostician.analyze(
                file_metadata=file_metadata,
                omics_type=omics_type,
                dataframe=dataframe
            )
            
            if diagnosis_result.get("status") != "success":
                logger.warning(f"âš ï¸ æ•°æ®è¯Šæ–­å¤±è´¥: {diagnosis_result.get('error')}")
                return None
            
            stats = diagnosis_result.get("stats", {})
            logger.info(f"âœ… [DataDiagnostician] ç»Ÿè®¡è®¡ç®—å®Œæˆ: {len(stats)} ä¸ªæŒ‡æ ‡")
            
            # Step 2: æ„å»º LLM Prompt
            # å°†ç»Ÿè®¡äº‹å®æ ¼å¼åŒ–ä¸º JSON å­—ç¬¦ä¸²
            import json
            try:
                stats_json = json.dumps(stats, ensure_ascii=False, indent=2)
                logger.debug(f"ğŸ“ [DEBUG] Stats JSON length: {len(stats_json)}")
            except Exception as json_err:
                logger.error(f"âŒ [DataDiagnostician] JSON åºåˆ—åŒ–å¤±è´¥: {json_err}")
                stats_json = json.dumps({"error": "æ— æ³•åºåˆ—åŒ–ç»Ÿè®¡ä¿¡æ¯"}, ensure_ascii=False)
            
            # ğŸ”¥ ä¿®å¤ï¼šå®‰å…¨åœ°æˆªæ–­ JSON å­—ç¬¦ä¸²ï¼ˆè€Œä¸æ˜¯å­—å…¸ï¼‰
            # å¦‚æœ JSON å¤ªé•¿ï¼Œæˆªæ–­å®ƒï¼ˆä½†ä¿ç•™å®Œæ•´çš„ç»“æ„ï¼‰
            max_json_length = 2000  # é™åˆ¶ JSON é•¿åº¦
            if len(stats_json) > max_json_length:
                logger.warning(f"âš ï¸ Stats JSON å¤ªé•¿ ({len(stats_json)} å­—ç¬¦)ï¼Œæˆªæ–­åˆ° {max_json_length} å­—ç¬¦")
                # æˆªæ–­å­—ç¬¦ä¸²ï¼Œä½†ç¡®ä¿ JSON ç»“æ„å®Œæ•´
                truncated_json = stats_json[:max_json_length]
                # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡/æ•°ç»„è¾¹ç•Œ
                last_brace = truncated_json.rfind('}')
                last_bracket = truncated_json.rfind(']')
                last_comma = max(truncated_json.rfind(','), truncated_json.rfind('\n'))
                # é€‰æ‹©æœ€æ¥è¿‘æœ«å°¾çš„è¾¹ç•Œ
                cut_point = max(last_brace, last_bracket, last_comma)
                if cut_point > max_json_length * 0.8:  # å¦‚æœæˆªæ–­ç‚¹ä¸å¤ªæ—©
                    stats_json = truncated_json[:cut_point + 1] + "\n  ... (truncated)"
                else:
                    stats_json = truncated_json + "\n  ... (truncated)"
            
            # ğŸ”¥ å®‰å…¨åœ°æå–æ–‡ä»¶é¢„è§ˆä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            # æ³¨æ„ï¼šfile_metadata æ˜¯å­—å…¸ï¼Œä¸èƒ½ç›´æ¥åˆ‡ç‰‡
            head_preview = ""
            try:
                head_data = file_metadata.get("head", {})
                if isinstance(head_data, dict):
                    # head_data æ˜¯å­—å…¸ï¼ŒåŒ…å« "markdown" æˆ– "json" é”®
                    if "markdown" in head_data:
                        head_preview = head_data["markdown"]
                    elif "json" in head_data:
                        # å¦‚æœæ˜¯ JSON æ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        head_preview = json.dumps(head_data["json"], ensure_ascii=False, indent=2)
                    else:
                        head_preview = str(head_data)
                elif isinstance(head_data, str):
                    # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                    head_preview = head_data
                else:
                    head_preview = str(head_data)
                
                # ğŸ”¥ å®‰å…¨åœ°æˆªæ–­å­—ç¬¦ä¸²é¢„è§ˆï¼ˆä¸æ˜¯å­—å…¸ï¼‰
                if len(head_preview) > 1000:
                    head_preview = head_preview[:1000] + "\n... (truncated)"
            except Exception as head_err:
                logger.warning(f"âš ï¸ æå–æ–‡ä»¶é¢„è§ˆå¤±è´¥: {head_err}")
                head_preview = "æ— æ³•æå–æ•°æ®é¢„è§ˆ"
            
            # ä½¿ç”¨ PromptManager è·å–è¯Šæ–­æ¨¡æ¿
            try:
                # ğŸ”¥ ç¡®ä¿åªä¼ é€’å­—ç¬¦ä¸²ç»™æ¨¡æ¿ï¼Œä¸ä¼ é€’å­—å…¸
                prompt = self.prompt_manager.get_prompt(
                    "data_diagnosis",
                    {
                        "inspection_data": stats_json,  # å­—ç¬¦ä¸²
                        "head_preview": head_preview[:500] if head_preview else ""  # å­—ç¬¦ä¸²ï¼Œæˆªæ–­åˆ° 500 å­—ç¬¦
                    },
                    fallback=DATA_DIAGNOSIS_PROMPT.format(inspection_data=stats_json)
                )
                logger.debug(f"ğŸ“ [DEBUG] Prompt length: {len(prompt)}")
            except Exception as prompt_err:
                logger.warning(f"âš ï¸ è·å–è¯Šæ–­æ¨¡æ¿å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {prompt_err}")
                try:
                    # ğŸ”¥ å®‰å…¨åœ°æ ¼å¼åŒ– promptï¼Œé¿å… format é”™è¯¯
                    # ç¡®ä¿ stats_json æ˜¯å­—ç¬¦ä¸²
                    if not isinstance(stats_json, str):
                        stats_json = json.dumps(stats_json, ensure_ascii=False)
                    prompt = DATA_DIAGNOSIS_PROMPT.format(inspection_data=stats_json)
                except Exception as format_err:
                    logger.error(f"âŒ [DataDiagnostician] Prompt æ ¼å¼åŒ–å¤±è´¥: {format_err}")
                    # ä½¿ç”¨ç®€å•çš„ prompt
                    # ğŸ”¥ ç¡®ä¿ stats_json æ˜¯å­—ç¬¦ä¸²
                    if not isinstance(stats_json, str):
                        stats_json = json.dumps(stats_json, ensure_ascii=False)
                    prompt = f"""You are a Senior Bioinformatician specializing in {omics_type}.

Based on the following data statistics:
{stats_json}

Please generate a data diagnosis and parameter recommendation report in Simplified Chinese (ç®€ä½“ä¸­æ–‡).

Format:
### ğŸ” æ•°æ®ä½“æ£€æŠ¥å‘Š
- **æ•°æ®è§„æ¨¡**: [æ ·æœ¬æ•°ã€ä»£è°¢ç‰©æ•°]
- **æ•°æ®ç‰¹å¾**: [ç¼ºå¤±å€¼ç‡ã€æ•°æ®èŒƒå›´ç­‰]
- **æ•°æ®è´¨é‡**: [è´¨é‡è¯„ä¼°]

### ğŸ’¡ å‚æ•°æ¨è
Create a Markdown table with parameter recommendations.

Use Simplified Chinese for all content."""
            
            # Step 3: è°ƒç”¨ LLM ç”Ÿæˆ Markdown æŠ¥å‘Š
            # ğŸ”¥ æ¶æ„é‡æ„ï¼šä½¿ç”¨ç­–ç•¥æ¨¡å¼ï¼Œä» Agent ä¼ å…¥ system_instruction
            if system_instruction:
                # ä½¿ç”¨ Agent æä¾›çš„é¢†åŸŸç‰¹å®šæŒ‡ä»¤
                system_prompt = system_instruction
                logger.debug(f"âœ… [DataDiagnostician] Using domain-specific system instruction (length: {len(system_instruction)})")
            else:
                # å›é€€åˆ°é€šç”¨æŒ‡ä»¤ï¼ˆå‘åå…¼å®¹ï¼‰
                logger.warning(f"âš ï¸ [DataDiagnostician] No system_instruction provided, using generic prompt")
                system_prompt = "You are a Senior Bioinformatician. Generate data diagnosis and parameter recommendations in Simplified Chinese."
            
            # ğŸ”¥ æ¶æ„é‡æ„ï¼šå°† system_instruction å‰ç½®åˆ°ç”¨æˆ· promptï¼ˆç¡®ä¿ä¸Šä¸‹æ–‡éš”ç¦»ï¼‰
            if system_instruction:
                # åœ¨ç”¨æˆ· prompt å‰æ·»åŠ ç³»ç»ŸæŒ‡ä»¤ï¼Œç¡®ä¿ LLM ç†è§£é¢†åŸŸçº¦æŸ
                prompt = f"""{system_instruction}

{prompt}"""
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ]
            
            # ğŸ”¥ Step 3: è°ƒç”¨ LLM ç”Ÿæˆ Markdown æŠ¥å‘Š
            # ğŸ”¥ CRITICAL DEBUGGING: åŒ…è£…åœ¨è¯¦ç»†çš„ try-except ä¸­
            try:
                logger.info(f"ğŸ“ [DataDiagnostician] è°ƒç”¨ LLM ç”ŸæˆæŠ¥å‘Š...")
                logger.debug(f"ğŸ“ [DEBUG] LLM Client type: {type(self.llm_client)}")
                logger.debug(f"ğŸ“ [DEBUG] LLM Client methods: {dir(self.llm_client)}")
                
                completion = await self.llm_client.achat(messages, temperature=0.3, max_tokens=1500)
                
                logger.debug(f"ğŸ“ [DEBUG] LLM completion type: {type(completion)}")
                logger.debug(f"ğŸ“ [DEBUG] LLM completion: {completion}")
                
                think_content, response = self.llm_client.extract_think_and_content(completion)
                
                # ğŸ”¥ DEBUG: æ‰“å°è¯Šæ–­æŠ¥å‘Šä¿¡æ¯
                if response:
                    logger.info(f"âœ… [DataDiagnostician] è¯Šæ–­æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(response)}")
                    logger.debug(f"ğŸ“ [DEBUG] Diagnosis report preview: {response[:200]}...")
                else:
                    logger.warning(f"âš ï¸ [DataDiagnostician] è¯Šæ–­æŠ¥å‘Šä¸ºç©º")
                    logger.warning(f"âš ï¸ [DEBUG] Think content: {think_content[:200] if think_content else 'None'}")
                
                # Step 4: ä¿å­˜åˆ°ä¸Šä¸‹æ–‡ï¼ˆä¾› UI å’Œåç»­æ­¥éª¤ä½¿ç”¨ï¼‰
                self.context["diagnosis_report"] = response
                self.context["diagnosis_stats"] = stats
                
                return response
                
            except AttributeError as attr_err:
                # LLM å®¢æˆ·ç«¯æ–¹æ³•ä¸å­˜åœ¨
                import traceback
                error_msg = (
                    f"LLM å®¢æˆ·ç«¯æ–¹æ³•è°ƒç”¨å¤±è´¥: {str(attr_err)}\n"
                    f"LLM Client type: {type(self.llm_client)}\n"
                    f"Available methods: {[m for m in dir(self.llm_client) if not m.startswith('_')]}\n"
                    f"Stack trace:\n{traceback.format_exc()}"
                )
                logger.error(f"âŒ [DataDiagnostician] {error_msg}")
                return f"âš ï¸ **è¯Šæ–­æŠ¥å‘Šç”Ÿæˆå¤±è´¥**\n\nLLM å®¢æˆ·ç«¯é”™è¯¯: {str(attr_err)}\n\nè¯·æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
                
            except Exception as llm_err:
                # LLM è°ƒç”¨å¤±è´¥
                import traceback
                error_msg = (
                    f"LLM è°ƒç”¨å¤±è´¥: {str(llm_err)}\n"
                    f"Error type: {type(llm_err).__name__}\n"
                    f"Stack trace:\n{traceback.format_exc()}"
                )
                logger.error(f"âŒ [DataDiagnostician] {error_msg}")
                return f"âš ï¸ **è¯Šæ–­æŠ¥å‘Šç”Ÿæˆå¤±è´¥**\n\né”™è¯¯: {str(llm_err)}\n\nè¯·æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"
            
        except Exception as e:
            # æ•´ä½“å¼‚å¸¸å¤„ç†
            import traceback
            error_msg = (
                f"æ•°æ®è¯Šæ–­è¿‡ç¨‹å¤±è´¥: {str(e)}\n"
                f"Error type: {type(e).__name__}\n"
                f"Stack trace:\n{traceback.format_exc()}"
            )
            logger.error(f"âŒ [DataDiagnostician] {error_msg}")
            # ğŸ”¥ è¿”å›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ Noneï¼Œè¿™æ ·ç”¨æˆ·å¯ä»¥åœ¨ UI ä¸­çœ‹åˆ°
            return f"âš ï¸ **è¯Šæ–­æŠ¥å‘Šç”Ÿæˆå¤±è´¥**\n\né”™è¯¯: {str(e)}\n\nè¯·æ£€æŸ¥æœåŠ¡å™¨æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚"

