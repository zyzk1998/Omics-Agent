"""
è·¯ç”±æ™ºèƒ½ä½“
åˆ†æç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œè¯†åˆ«æ„å›¾å’Œç»„å­¦ç±»å‹ï¼Œè·¯ç”±åˆ°å¯¹åº”çš„é¢†åŸŸæ™ºèƒ½ä½“
"""
import json
from typing import Dict, Any, List, Optional
from .base_agent import BaseAgent
from ..core.llm_client import LLMClient
from ..core.prompt_manager import PromptManager


class RouterAgent(BaseAgent):
    """
    è·¯ç”±æ™ºèƒ½ä½“
    
    èŒè´£ï¼š
    1. åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œè¯†åˆ«ç»„å­¦ç±»å‹
    2. è¯†åˆ«ç”¨æˆ·æ„å›¾ï¼ˆåˆ†æã€å¯è§†åŒ–ã€è§£é‡Šç­‰ï¼‰
    3. è·¯ç”±åˆ°å¯¹åº”çš„é¢†åŸŸæ™ºèƒ½ä½“
    """
    
    # ç»„å­¦ç±»å‹å…³é”®è¯æ˜ å°„
    MODALITY_KEYWORDS = {
        "transcriptomics": [
            "rna", "transcript", "expression", "gene", "scRNA", "scrna",
            "single cell", "bulk rna", "rna-seq", "è½¬å½•ç»„", "å•ç»†èƒ", "åŸºå› è¡¨è¾¾"
        ],
        "genomics": [
            "genome", "wgs", "wes", "variant", "snp", "indel",
            "gatk", "bwa", "åŸºå› ç»„", "å˜å¼‚", "çªå˜"
        ],
        "epigenomics": [
            "chip", "atac", "methylation", "epigenetic", "histone",
            "ChIP-seq", "ATAC-seq", "è¡¨è§‚é—ä¼ "
        ],
        "metabolomics": [
            "metabolite", "metabolism", "lc-ms", "gc-ms", "xcms",
            "ä»£è°¢ç»„", "ä»£è°¢ç‰©", "ä»£è°¢ç»„å­¦", "ä»£è°¢ç»„åˆ†æ", "ä»£è°¢åˆ†æ",
            "metabolomics", "metabolomic", "metabonomics"
        ],
        "proteomics": [
            "protein", "proteome", "mass spec", "maxquant",
            "è›‹ç™½è´¨ç»„", "è´¨è°±"
        ],
        "spatial_omics": [
            "spatial", "visium", "st", "spatial transcriptomics",
            "ç©ºé—´è½¬å½•ç»„"
        ],
        "imaging": [
            "image", "microscopy", "histology", "ç—…ç†", "å½±åƒ"
        ]
    }
    
    # è·¯ç”±æ˜ å°„
    ROUTING_MAP = {
        "transcriptomics": "rna_agent",
        "genomics": "dna_agent",
        "epigenomics": "epigenomics_agent",
        "metabolomics": "metabolomics_agent",
        "proteomics": "proteomics_agent",
        "spatial_omics": "spatial_agent",
        "imaging": "imaging_agent"
    }
    
    def __init__(self, llm_client: LLMClient, prompt_manager: PromptManager):
        """åˆå§‹åŒ–è·¯ç”±æ™ºèƒ½ä½“"""
        super().__init__(llm_client, prompt_manager, "router")
    
    async def process_query(
        self,
        query: str,
        history: List[Dict[str, str]] = None,
        uploaded_files: List[Dict[str, str]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        å¤„ç†æŸ¥è¯¢å¹¶è¿”å›è·¯ç”±å†³ç­–
        
        Returns:
            {
                "modality": "transcriptomics",
                "intent": "single_cell_analysis",
                "confidence": 0.95,
                "routing": "rna_agent",
                "reasoning": "..."
            }
        """
        import logging
        logger = logging.getLogger(__name__)
        
        logger.info(f"ğŸ”€ RouterAgent: å¼€å§‹è·¯ç”±å†³ç­– - æŸ¥è¯¢: {query[:50]}...")
        
        # æ–¹æ³•1ï¼šåŸºäºå…³é”®è¯çš„å¿«é€Ÿè·¯ç”±
        quick_route = self._quick_route(query, uploaded_files)
        # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œè®©æ›´å¤šæƒ…å†µèƒ½å¿«é€Ÿè·¯ç”±ï¼ˆé¿å… LLM è°ƒç”¨å»¶è¿Ÿï¼‰
        if quick_route and quick_route.get("confidence", 0) > 0.7:  # ä» 0.8 é™ä½åˆ° 0.7
            logger.info(f"âœ… RouterAgent: å¿«é€Ÿè·¯ç”±æˆåŠŸ - {quick_route.get('routing')} (confidence: {quick_route.get('confidence', 0):.2f})")
            return quick_route
        
        logger.info(f"âš ï¸ RouterAgent: å¿«é€Ÿè·¯ç”±å¤±è´¥æˆ–ç½®ä¿¡åº¦ä½ï¼Œä½¿ç”¨ LLM è·¯ç”±...")
        
        # æ–¹æ³•2ï¼šä½¿ç”¨ LLM è¿›è¡Œæ·±åº¦åˆ†æï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
        try:
            import asyncio
            # è®¾ç½® 10 ç§’è¶…æ—¶ï¼Œé¿å… LLM è°ƒç”¨å¡ä½
            llm_route = await asyncio.wait_for(
                self._llm_route(query, uploaded_files),
                timeout=10.0
            )
            if llm_route:
                logger.info(f"âœ… RouterAgent: LLM è·¯ç”±æˆåŠŸ - {llm_route.get('routing')} (confidence: {llm_route.get('confidence', 0):.2f})")
                return llm_route
        except asyncio.TimeoutError:
            logger.warning(f"â±ï¸ RouterAgent: LLM è·¯ç”±è¶…æ—¶ï¼ˆ10ç§’ï¼‰ï¼Œä½¿ç”¨é»˜è®¤è·¯ç”±")
        except Exception as e:
            logger.error(f"âŒ RouterAgent: LLM è·¯ç”±å¤±è´¥: {e}", exc_info=True)
        
        # é»˜è®¤è·¯ç”±åˆ°è½¬å½•ç»„ï¼ˆå‘åå…¼å®¹ï¼‰
        logger.warning(f"âš ï¸ RouterAgent: ä½¿ç”¨é»˜è®¤è·¯ç”± (rna_agent)")
        return {
            "modality": "transcriptomics",
            "intent": "analysis",
            "confidence": 0.5,
            "routing": "rna_agent",
            "reasoning": "Default routing to transcriptomics"
        }
    
    def _quick_route(
        self,
        query: str,
        uploaded_files: List[Dict[str, str]] = None
    ) -> Optional[Dict[str, Any]]:
        """åŸºäºå…³é”®è¯çš„å¿«é€Ÿè·¯ç”±"""
        import logging
        import os
        logger = logging.getLogger(__name__)
        
        query_lower = query.lower()
        file_paths = self.get_file_paths(uploaded_files or [])
        
        logger.debug(f"ğŸ” å¿«é€Ÿè·¯ç”±: æŸ¥è¯¢='{query_lower[:50]}...', æ–‡ä»¶æ•°={len(file_paths)}")
        
        # ğŸ”¥ æ–‡ä»¶ä¼˜å…ˆå¯å‘å¼ï¼šåœ¨è°ƒç”¨ LLM ä¹‹å‰ï¼Œæ ¹æ®æ–‡ä»¶æ‰©å±•åå¼ºåˆ¶è·¯ç”±
        if file_paths:
            # æå–æ‰€æœ‰æ–‡ä»¶æ‰©å±•å
            file_extensions = set()
            for path in file_paths:
                # å¤„ç†ç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
                if os.path.isabs(path):
                    ext = os.path.splitext(path)[1].lower()
                else:
                    ext = os.path.splitext(path)[1].lower()
                if ext:
                    file_extensions.add(ext)
            
            logger.info(f"ğŸ“ æ£€æµ‹åˆ°çš„æ–‡ä»¶æ‰©å±•å: {file_extensions}")
            
            # RNA/è½¬å½•ç»„æ–‡ä»¶æ‰©å±•å
            rna_extensions = {'.h5ad', '.mtx', '.fastq', '.fq', '.bam', '.sam'}
            # ä»£è°¢ç»„æ–‡ä»¶æ‰©å±•å
            metabolomics_extensions = {'.csv', '.txt', '.xlsx', '.xls', '.tsv'}
            
            # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨æœ€æ–°ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆåˆ—è¡¨æœ€åä¸€ä¸ªï¼‰
            # æ£€æŸ¥æ˜¯å¦æœ‰ RNA æ–‡ä»¶
            if file_extensions & rna_extensions:
                # å¦‚æœåŒæ—¶æœ‰ RNA å’Œä»£è°¢ç»„æ–‡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨æœ€æ–°ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæœ€åä¸€ä¸ªï¼‰
                if file_extensions & metabolomics_extensions:
                    # æ£€æŸ¥æœ€åä¸€ä¸ªæ–‡ä»¶çš„æ‰©å±•å
                    last_file_path = file_paths[-1] if file_paths else ""
                    last_ext = os.path.splitext(last_file_path)[1].lower()
                    if last_ext in metabolomics_extensions:
                        logger.info(f"âœ… æ–‡ä»¶ä¼˜å…ˆè·¯ç”±: æ£€æµ‹åˆ°æœ€æ–°æ–‡ä»¶æ˜¯ä»£è°¢ç»„æ–‡ä»¶ {last_ext} â†’ metabolomics_agent")
                        return {
                            "modality": "metabolomics",
                            "intent": self._detect_intent(query) if query else "analysis",
                            "confidence": 0.95,
                            "routing": "metabolomics_agent",
                            "reasoning": f"Latest file extension-based routing: {last_ext}"
                        }
                
                logger.info(f"âœ… æ–‡ä»¶ä¼˜å…ˆè·¯ç”±: æ£€æµ‹åˆ° RNA æ–‡ä»¶æ‰©å±•å {file_extensions & rna_extensions} â†’ rna_agent")
                return {
                    "modality": "transcriptomics",
                    "intent": self._detect_intent(query) if query else "analysis",
                    "confidence": 0.95,
                    "routing": "rna_agent",
                    "reasoning": f"File extension-based routing: {file_extensions & rna_extensions}"
                }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»£è°¢ç»„æ–‡ä»¶
            if file_extensions & metabolomics_extensions:
                logger.info(f"âœ… æ–‡ä»¶ä¼˜å…ˆè·¯ç”±: æ£€æµ‹åˆ°ä»£è°¢ç»„æ–‡ä»¶æ‰©å±•å {file_extensions & metabolomics_extensions} â†’ metabolomics_agent")
                return {
                    "modality": "metabolomics",
                    "intent": self._detect_intent(query) if query else "analysis",
                    "confidence": 0.95,
                    "routing": "metabolomics_agent",
                    "reasoning": f"File extension-based routing: {file_extensions & metabolomics_extensions}"
                }
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åï¼ˆä½¿ç”¨ detect_file_typeï¼‰
        file_types = set()
        for path in file_paths:
            file_type = self.detect_file_type(path)
            if file_type != "unknown":
                file_types.add(file_type)
        
        logger.debug(f"ğŸ“ æ£€æµ‹åˆ°çš„æ–‡ä»¶ç±»å‹: {file_types}")
        
        # ğŸ”§ ä¿®å¤ï¼šä¼˜å…ˆæ£€æŸ¥æŸ¥è¯¢ä¸­çš„ä»£è°¢ç»„å…³é”®è¯ï¼ˆå³ä½¿æ²¡æœ‰æ–‡ä»¶ï¼‰
        metabolomics_keywords = [
            "ä»£è°¢ç»„", "ä»£è°¢ç‰©", "ä»£è°¢ç»„å­¦", "ä»£è°¢ç»„åˆ†æ", "ä»£è°¢åˆ†æ",
            "metabolite", "metabolism", "metabolomics", "metabolomic", "metabonomics",
            "lc-ms", "gc-ms", "xcms"
        ]
        if any(kw in query_lower for kw in metabolomics_keywords):
            logger.info(f"âœ… å¿«é€Ÿè·¯ç”±: æŸ¥è¯¢åŒ…å«ä»£è°¢ç»„å…³é”®è¯ â†’ metabolomics_agent")
            return {
                "modality": "metabolomics",
                "intent": self._detect_intent(query),
                "confidence": 0.95,  # é«˜ç½®ä¿¡åº¦
                "routing": "metabolomics_agent",
                "reasoning": "Query contains metabolomics keywords"
            }
        
        # ç‰¹æ®Šè§„åˆ™ï¼šCSV æ–‡ä»¶ + ä»£è°¢ç»„å…³é”®è¯ = é«˜ç½®ä¿¡åº¦å¿«é€Ÿè·¯ç”±
        if "csv" in file_types:
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»£è°¢ç»„ç›¸å…³å…³é”®è¯
            if any(kw in query_lower for kw in metabolomics_keywords):
                logger.info(f"âœ… å¿«é€Ÿè·¯ç”±: CSV æ–‡ä»¶ + ä»£è°¢ç»„å…³é”®è¯ â†’ metabolomics_agent")
                return {
                    "modality": "metabolomics",
                    "intent": self._detect_intent(query),
                    "confidence": 0.98,  # æé«˜ç½®ä¿¡åº¦
                    "routing": "metabolomics_agent",
                    "reasoning": "CSV file with metabolomics keywords"
                }
            # å³ä½¿æ²¡æœ‰æ˜ç¡®å…³é”®è¯ï¼ŒCSV æ–‡ä»¶ä¹Ÿä¼˜å…ˆè€ƒè™‘ä»£è°¢ç»„ï¼ˆé™¤éæœ‰æ˜ç¡®çš„å…¶ä»–å…³é”®è¯ï¼‰
            elif not any(kw in query_lower for kw in ["rna", "è½¬å½•", "å•ç»†èƒ", "scrna", "gene", "è¡¨è¾¾", "transcript"]):
                logger.info(f"âœ… å¿«é€Ÿè·¯ç”±: CSV æ–‡ä»¶ï¼ˆæ— å…¶ä»–å…³é”®è¯ï¼‰â†’ metabolomics_agent")
                return {
                    "modality": "metabolomics",
                    "intent": self._detect_intent(query),
                    "confidence": 0.85,  # è¾ƒé«˜ç½®ä¿¡åº¦
                    "routing": "metabolomics_agent",
                    "reasoning": "CSV file (likely metabolomics data)"
                }
        
        # åŒ¹é…ç»„å­¦ç±»å‹
        scores = {}
        for modality, keywords in self.MODALITY_KEYWORDS.items():
            score = 0
            # æŸ¥è¯¢æ–‡æœ¬åŒ¹é…
            matched_keywords = []
            for keyword in keywords:
                if keyword in query_lower:
                    score += 1
                    matched_keywords.append(keyword)
            
            # ğŸ”§ ä¿®å¤ï¼šæé«˜ä»£è°¢ç»„å…³é”®è¯çš„æƒé‡
            if modality == "metabolomics" and matched_keywords:
                # ä»£è°¢ç»„å…³é”®è¯åŒ¹é…ç»™äºˆæ›´é«˜æƒé‡ï¼ˆæ¯ä¸ªåŒ¹é…çš„å…³é”®è¯é¢å¤– +2 åˆ†ï¼‰
                score += len(matched_keywords) * 2
            
            # æ–‡ä»¶ç±»å‹åŒ¹é…ï¼ˆç»™äºˆæ›´é«˜æƒé‡ï¼‰
            if modality == "transcriptomics" and ("fastq" in file_types or "h5ad" in file_types):
                score += 3  # æé«˜æƒé‡
            elif modality == "genomics" and ("bam" in file_types or "vcf" in file_types):
                score += 3
            elif modality == "metabolomics" and "csv" in file_types:
                score += 5  # ğŸ”§ ä¿®å¤ï¼šCSV æ–‡ä»¶å¼ºçƒˆæš—ç¤ºä»£è°¢ç»„æ•°æ®ï¼Œæé«˜æƒé‡
            
            if score > 0:
                scores[modality] = score
                logger.debug(f"  {modality}: score={score} (matched: {matched_keywords[:3]})")
        
        if scores:
            best_modality = max(scores.items(), key=lambda x: x[1])
            modality, score = best_modality
            
            # å¦‚æœåˆ†æ•°è¶³å¤Ÿé«˜ï¼Œç›´æ¥è¿”å›ï¼ˆä¸éœ€è¦ LLMï¼‰
            # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œè®©æ›´å¤šæƒ…å†µèƒ½å¿«é€Ÿè·¯ç”±
            confidence = min(0.95, 0.5 + score * 0.15)  # è°ƒæ•´å…¬å¼ï¼Œè®©ç½®ä¿¡åº¦æ›´å®¹æ˜“è¾¾åˆ° 0.8
            
            result = {
                "modality": modality,
                "intent": self._detect_intent(query),
                "confidence": confidence,
                "routing": self.ROUTING_MAP.get(modality, "rna_agent"),
                "reasoning": f"Matched keywords and file types (score: {score})"
            }
            
            logger.debug(f"âœ… å¿«é€Ÿè·¯ç”±ç»“æœ: {result}")
            return result
        
        logger.debug("âŒ å¿«é€Ÿè·¯ç”±: æ— åŒ¹é…")
        return None
    
    async def _llm_route(
        self,
        query: str,
        uploaded_files: List[Dict[str, str]] = None
    ) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨ LLM è¿›è¡Œè·¯ç”±å†³ç­–"""
        file_paths = self.get_file_paths(uploaded_files or [])
        
        routing_prompt = self.prompt_manager.get_prompt(
            "router",
            {
                "user_query": query,
                "uploaded_files": ", ".join(file_paths) if file_paths else "None"
            },
            fallback=f"""Analyze this query and determine routing:

Query: {query}
Files: {', '.join(file_paths) if file_paths else 'None'}

Return JSON:
{{
    "modality": "transcriptomics|genomics|epigenomics|metabolomics|proteomics|spatial_omics|imaging",
    "intent": "analysis|visualization|interpretation|workflow",
    "confidence": 0.0-1.0,
    "routing": "rna_agent|dna_agent|...",
    "reasoning": "brief explanation"
}}"""
        )
        
        messages = [
            {"role": "system", "content": routing_prompt},
            {"role": "user", "content": query}
        ]
        
        try:
            completion = await self.llm_client.achat(messages, temperature=0.1, max_tokens=256)
            # æå– think è¿‡ç¨‹å’Œå®é™…å†…å®¹
            think_content, response = self.llm_client.extract_think_and_content(completion)
            # å¦‚æœæœ‰ think å†…å®¹ï¼Œè®°å½•æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
            if think_content:
                import logging
                logger = logging.getLogger(__name__)
                logger.debug(f"Router think process: {think_content[:200]}...")
            
            # è§£æ JSON
            json_str = response.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0].strip()
            elif "```" in json_str:
                json_str = json_str.split("```")[1].split("```")[0].strip()
            
            route_result = json.loads(json_str)
            
            # ç¡®ä¿è·¯ç”±å­—æ®µå­˜åœ¨
            if "routing" not in route_result:
                modality = route_result.get("modality", "transcriptomics")
                route_result["routing"] = self.ROUTING_MAP.get(modality, "rna_agent")
            
            return route_result
        except json.JSONDecodeError as e:
            # JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è·¯ç”±
            import logging
            logger = logging.getLogger(__name__)
            logger.warning(f"LLM routing JSON parse failed: {e}, response: {response[:200]}")
            return None
        except Exception as e:
            # å…¶ä»–é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤è·¯ç”±
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"LLM routing failed: {e}", exc_info=True)
            return None
    
    def _detect_intent(self, query: str) -> str:
        """æ£€æµ‹ç”¨æˆ·æ„å›¾"""
        query_lower = query.lower()
        
        if any(kw in query_lower for kw in ["å¯è§†åŒ–", "visualize", "plot", "å›¾", "ç”»"]):
            return "visualization"
        elif any(kw in query_lower for kw in ["è§£é‡Š", "interpret", "è¯´æ˜", "å«ä¹‰"]):
            return "interpretation"
        elif any(kw in query_lower for kw in ["æµç¨‹", "workflow", "pipeline", "åˆ†æ", "run"]):
            return "workflow"
        else:
            return "analysis"

